{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYl9_BR6X-5J"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRs5NRVjixfu"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDFuCcbfGwB8"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from google.colab import output\n",
        "\n",
        "from pandas import DatetimeIndex as dt\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "# from google.colab import files\n",
        "import IPython\n",
        "from IPython.display import HTML, display, clear_output \n",
        "# from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# hyper-parameters optimisation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import matthews_corrcoef as mcc\n",
        "from sklearn.metrics import f1_score as f1\n",
        "from sklearn.metrics import accuracy_score as accuracy\n",
        "from sklearn.metrics import precision_score as TP_rate                          \n",
        "from sklearn.metrics import roc_auc_score as roc_auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import recall_score as recall\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import make_scorer,fbeta_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "# classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostRegressor, RandomForestRegressor, GradientBoostingClassifier, StackingClassifier, VotingClassifier #\n",
        "from sklearn.tree import DecisionTreeClassifier     #\n",
        "from sklearn.svm import SVC                                    # both linear and radial classification\n",
        "from sklearn.neighbors import KNeighborsClassifier             # k=3\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "import catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "# statistics\n",
        "from scipy.stats import shapiro\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# imputations\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "# now you can import normally from sklearn.impute\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.base import clone\n",
        "\n",
        "# feature selection\n",
        "from sklearn.feature_selection import chi2, mutual_info_classif, f_classif, SelectKBest, RFE, RFECV, SequentialFeatureSelector\n",
        "from scipy.stats import kendalltau, spearmanr\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from mrmr import mrmr_classif\n",
        "\n",
        "# to conver string to dict\n",
        "import ast\n",
        "\n",
        "# Interpretability\n",
        " # !pip install interpret\n",
        "from interpret.blackbox import LimeTabular\n",
        "from interpret import set_visualize_provider\n",
        "from interpret.provider import InlineProvider\n",
        "set_visualize_provider(InlineProvider())\n",
        "from interpret import show\n",
        "\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from __future__ import print_function\n",
        "\n",
        "# ignore warnings when graphs are plotted\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data import"
      ],
      "metadata": {
        "id": "h4F2kAoHJH9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# links to datasets\n",
        "\n",
        "# lancet\n",
        "link_train_lancet = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/lancet%20dataset/train_abc_lancet.xlsx?raw=true'\n",
        "link_test_lancet  = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/lancet%20dataset/test_abc_lancet.xlsx?raw=true'\n",
        "\n",
        "# death\n",
        "link_train_death_a   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/cardiovascular%20death/train_a.xlsx?raw=true'\n",
        "link_test_death_a    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/cardiovascular%20death/test_a.xlsx?raw=true'\n",
        "link_train_death_b   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/cardiovascular%20death/train_b.xlsx?raw=true'\n",
        "link_test_death_b    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/cardiovascular%20death/test_b.xlsx?raw=true'\n",
        "link_train_death_c   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/cardiovascular%20death/train_c.xlsx?raw=true'\n",
        "link_test_death_c    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/cardiovascular%20death/test_c.xlsx?raw=true'\n",
        "link_train_death_abc = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/cardiovascular%20death/train_abc.xlsx?raw=true'\n",
        "link_test_death_abc  = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/cardiovascular%20death/test_abc.xlsx?raw=true'\n",
        "\n",
        "# combined\n",
        "link_train_combined_a   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/combined/train_a.xlsx?raw=true'\n",
        "link_test_combined_a    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/combined/test_a.xlsx?raw=true'\n",
        "link_train_combined_b   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/combined/train_b.xlsx?raw=true'\n",
        "link_test_combined_b    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/combined/test_b.xlsx?raw=true'\n",
        "link_train_combined_c   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/combined/train_c.xlsx?raw=true'\n",
        "link_test_combined_c    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/combined/test_c.xlsx?raw=true'\n",
        "link_train_combined_abc = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/combined/train_abc.xlsx?raw=true'\n",
        "link_test_combined_abc  = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/combined/test_abc.xlsx?raw=true'\n",
        "\n",
        "# revascularization\n",
        "link_train_revascularization_a   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/revascularization/train_a.xlsx?raw=true'\n",
        "link_test_revascularization_a    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/revascularization/test_a.xlsx?raw=true'\n",
        "link_train_revascularization_b   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/revascularization/train_b.xlsx?raw=true'\n",
        "link_test_revascularization_b    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/revascularization/test_b.xlsx?raw=true'\n",
        "link_train_revascularization_c   = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/revascularization/train_c.xlsx?raw=true'\n",
        "link_test_revascularization_c    = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/revascularization/test_c.xlsx?raw=true'\n",
        "link_train_revascularization_abc = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/revascularization/train_abc.xlsx?raw=true'\n",
        "link_test_revascularization_abc  = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Preprocessed%20Data/revascularization/test_abc.xlsx?raw=true'"
      ],
      "metadata": {
        "id": "G4lX_SQPJQr0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZrQzUijWZH2"
      },
      "source": [
        "### Tuning of hyper-parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grids of hyper-parameters"
      ],
      "metadata": {
        "id": "-92bxcziIACL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A8pNQc9cWYqr"
      },
      "outputs": [],
      "source": [
        "# hyper-parameters for gridsearchCV\n",
        "\n",
        "# 1. Logistic regression\n",
        "parameters_LR_model = dict(\n",
        "                          C = [0.001, 0.01, 0.1, 1.],  # defeult\n",
        "                          tol = [1.e-4],\n",
        "                          penalty = ['elasticnet', 'l1', 'l2', 'none'],\n",
        "                          # njobs = [-1],\n",
        "                          dual = [False],\n",
        "                          fit_intercept = [False],\n",
        "                          # intercept_scaling =\n",
        "                          class_weight = ['balanced', None],\n",
        "                          random_state = [10],\n",
        "                          solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "                          max_iter = [10000],\n",
        "                          multi_class = ['auto'],\n",
        "                          verbose = [0],\n",
        "                          warm_start = [True]\n",
        "                          # l1_ratio\n",
        "                          )\n",
        "\n",
        "# 2. Random Forest\n",
        "parameters_random_forest_model = dict(\n",
        "                  n_estimators = [int(x) for x in np.linspace(start = 50, stop = 400, num = 25)],\n",
        "                  criterion = ['gini'],\n",
        "                  max_depth = [*[int(x) for x in np.linspace(2, 10, num = 5)]],\n",
        "                  min_samples_split = [2,4],  \n",
        "                  # min_samples_leaf = [1,2],  \n",
        "                  min_weight_fraction_leaf = [0.0],\n",
        "                  max_features = ['sqrt'],  \n",
        "                  max_leaf_nodes = [None],\n",
        "                  min_impurity_decrease = [0.],\n",
        "                  bootstrap = [True],\n",
        "                  oob_score = [False],\n",
        "                  n_jobs = [-1],\n",
        "                  random_state = [10],\n",
        "                  verbose = [0],\n",
        "                  warm_start = [True],\n",
        "                  class_weight = ['balanced', 'balanced_subsample', None],\n",
        "                  # ccp_alpha = \n",
        "                  max_samples = [None]  # maybe =0.1 here for getting almost independent samples for trees\n",
        "                  )\n",
        "\n",
        "# 3. k-NN\n",
        "parameters_knn = dict(\n",
        "                      n_neighbors = [int(x) for x in np.linspace(start = 1, stop = 7, num = 7)],\n",
        "                      weights = ['uniform', 'distance'],\n",
        "                      algorithm = ['ball_tree', 'kd_tree', 'brute'], \n",
        "                      leaf_size = [15, 30, 60],\n",
        "                      p = [3], \n",
        "                      metric = ['chebyshev', 'minkowski', 'euclidean', 'manhattan'],\n",
        "                      # metric_params = \n",
        "                      n_jobs = [-1]\n",
        "                      )\n",
        "\n",
        "# 4. SVM\n",
        "parameters_svm = dict(\n",
        "                  C = [int(x) for x in np.linspace(start = 1, stop = 25, num = 20)],\n",
        "                  kernel = ['rbf', 'linear', 'poly', 'sigmoid'],\n",
        "                  degree = [3, 4, 5],\n",
        "                  gamma = ['scale', 'auto'],\n",
        "                  coef0 = [0.0],\n",
        "                  shrinking = [True, False],\n",
        "                  probability = [True],\n",
        "                  tol = [1.e-3], \n",
        "                  cache_size = [200],\n",
        "                  class_weight = ['balanced', None],\n",
        "                  verbose = [False],\n",
        "                  max_iter = [1.e6],  # мб поставить конечные итерации, как в Logistic Regression\n",
        "                  # decision_function_shape = [],\n",
        "                  # break_ties = [],\n",
        "                  random_state = [10]\n",
        "                  )\n",
        "\n",
        "# 5. CatBoost\n",
        "catboost_parameters = {'depth': [4,6,8,10],  # larger depth is preferable\n",
        "              'learning_rate': [0.1,0.2,0.3],\n",
        "              'l2_leaf_reg': [0,3,6,1],\n",
        "              }\n",
        "c_boost_params = {'eval_metric' : 'F1', # 'F1' my_f2_scorer, 'F'\n",
        "                  # 'beta' : 2,\n",
        "                  'verbose' : False,\n",
        "                  'early_stopping_rounds' : 100,\n",
        "                  #cat_features=cat_features,\n",
        "                  'task_type' : \"CPU\",\n",
        "                  'iterations' : 500,\n",
        "                  'random_seed' : 10}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tuning functions"
      ],
      "metadata": {
        "id": "V9nyREL7-Zr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tuning(score, catboost_score, cross_validation, path, logistic_regression, knn, random_forest, svm, catboost):\n",
        "    # score = my_f2_scorer(), 'f1', 'accuracy', 'precision', 'recall', 'roc_auc'\n",
        "    # catboost_score = 'F1' 'F:beta=2'\n",
        "    if logistic_regression:\n",
        "        logistic_regression_tuning(score, cross_validation, path)     \n",
        "\n",
        "    if knn:\n",
        "        knn_tuning(score, cross_validation, path)     \n",
        "    if random_forest:\n",
        "        random_forest_tuning(score, cross_validation, path)     \n",
        "    if svm:\n",
        "        svm_tuning(score, cross_validation, path)     \n",
        "    if catboost:\n",
        "        catboost_tuning(catboost_score, cross_validation, path)     "
      ],
      "metadata": {
        "id": "al-jBVyw_C_W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_tuning(score, cross_validation, path):\n",
        "\n",
        "    # LogisticRegression: \n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "    LR_model = LogisticRegression(random_state=10)\n",
        "\n",
        "    # calibrate hyper-parameters: perform gridsearch with cross-validation\n",
        "    clf = GridSearchCV(\n",
        "                      estimator = LR_model, \n",
        "                      param_grid = parameters_LR_model,\n",
        "                      scoring = score,    \n",
        "                      #  refit = my_f2_scorer,\n",
        "                      cv = cross_validation,\n",
        "                      n_jobs = -1\n",
        "                      )              \n",
        "    %time clf.fit(X_train, y_train)\n",
        "    LR_model = clf.best_estimator_\n",
        "\n",
        "    # save optimisation parameters\n",
        "    optimisation_table = pd.DataFrame(clf.cv_results_)\n",
        "\n",
        "    # add roc_auc fCV values\n",
        "    optimisation_table['roc_auc'] = str(cross_val_score(LR_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table['roc_auc_mean'] = np.mean(cross_val_score(LR_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table['roc_auc_std'] = np.std(cross_val_score(LR_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table.to_excel(f'{path}LogisticRegression_optimisation.xlsx')"
      ],
      "metadata": {
        "id": "NYbh9_xQ-foC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_tuning(score, cross_validation, path):\n",
        "\n",
        "    # KNeighborsClassifier: \n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "    knn_model = KNeighborsClassifier()\n",
        "\n",
        "    # calibrate hyper-parameters: perform gridsearch with cross-validation = 5 \n",
        "    clf = GridSearchCV(\n",
        "                      estimator=knn_model, \n",
        "                      param_grid=parameters_knn,\n",
        "                      scoring=score,\n",
        "                      #  refit=my_f2_scorer,\n",
        "                      cv=cross_validation,\n",
        "                      n_jobs=-1\n",
        "                      )              \n",
        "    %time clf.fit(X_train, y_train)\n",
        "    knn_model = clf.best_estimator_\n",
        "\n",
        "    # save optimisation parameters\n",
        "    optimisation_table = pd.DataFrame(clf.cv_results_)\n",
        "\n",
        "    # add roc_auc fCV values\n",
        "    optimisation_table['roc_auc'] = str(cross_val_score(knn_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table['roc_auc_mean'] = np.mean(cross_val_score(knn_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table['roc_auc_std'] = np.std(cross_val_score(knn_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table.to_excel(f'{path}knn_optimisation.xlsx')"
      ],
      "metadata": {
        "id": "4Rjah-pFB6Tf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_tuning(score, cross_validation, path):\n",
        "      \n",
        "    # RandomForestClassifier: \n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "    random_forest_model = RandomForestClassifier(random_state=10)\n",
        "\n",
        "    # calibrate hyper-parameters: perform gridsearch with cross-validation = 5 \n",
        "    clf = GridSearchCV(\n",
        "                      estimator=random_forest_model, \n",
        "                      param_grid=parameters_random_forest_model,\n",
        "                      scoring=score,  \n",
        "                      #  refit=my_f2_scorer,\n",
        "                      cv=cross_validation,\n",
        "                      n_jobs=-1\n",
        "                      )              \n",
        "    %time clf.fit(X_train, y_train)\n",
        "    random_forest_model = clf.best_estimator_\n",
        "\n",
        "    # save optimisation parameters\n",
        "    optimisation_table = pd.DataFrame(clf.cv_results_)\n",
        "\n",
        "    # add roc_auc fCV values\n",
        "    optimisation_table['roc_auc'] = str(cross_val_score(random_forest_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table['roc_auc_mean'] = np.mean(cross_val_score(random_forest_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table['roc_auc_std'] = np.std(cross_val_score(random_forest_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table.to_excel(f'{path}randomforest_optimisation.xlsx')"
      ],
      "metadata": {
        "id": "aEpsgMkgCVkT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_tuning(score, cross_validation, path):\n",
        "      \n",
        "    # SVM_model\n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC \n",
        "\n",
        "    SVM_model = SVC()\n",
        "\n",
        "    # calibrate hyper-parameters: perform gridsearch with cross-validation = 5 \n",
        "    clf = GridSearchCV(\n",
        "                      estimator=SVM_model, \n",
        "                      param_grid=parameters_svm,\n",
        "                      scoring=score,  \n",
        "                      # refit=score[0],\n",
        "                      cv=cross_validation,\n",
        "                      n_jobs=-1\n",
        "                      )              \n",
        "    %time clf.fit(X_train, y_train)\n",
        "    SVM_model = clf.best_estimator_\n",
        "\n",
        "    # save optimisation parameters\n",
        "    optimisation_table = pd.DataFrame(clf.cv_results_)\n",
        "\n",
        "    # add roc_auc fCV values\n",
        "    optimisation_table['roc_auc'] = str(cross_val_score(SVM_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table['roc_auc_mean'] = np.mean(cross_val_score(SVM_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table['roc_auc_std'] = np.std(cross_val_score(SVM_model, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    optimisation_table.to_excel(f'{path}svm_optimisation.xlsx')\n",
        "    # files.download(\"/content/svm_optimisation.xlsx\")"
      ],
      "metadata": {
        "id": "OkPvwopuC2-l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def catboost_tuning(catboost_score, cross_validation, path):\n",
        "    # Catboost\n",
        "    # tuning: https://catboost.ai/en/docs/concepts/parameter-tuning\n",
        "\n",
        "\n",
        "    # calibrate hyper-parameters: perform gridsearch with cross-validation = 5 \n",
        "\n",
        "    np.random.seed(10)\n",
        "    catboost = CatBoostClassifier(\n",
        "                                eval_metric=catboost_score,\n",
        "                                verbose=False,\n",
        "                                early_stopping_rounds=100,\n",
        "                                #cat_features=cat_features,\n",
        "                                task_type=\"CPU\",\n",
        "                                iterations = 500,\n",
        "                                random_seed=10)\n",
        "\n",
        "\n",
        "    grid_res = catboost.grid_search(catboost_parameters,\n",
        "                                    X_train,\n",
        "                                    y_train,\n",
        "                                    cv=cross_validation,\n",
        "                                    search_by_train_test_split=True,\n",
        "                                    calc_cv_statistics=True,\n",
        "                                    refit=True,\n",
        "                                    shuffle=True,\n",
        "                                    partition_random_seed=10,\n",
        "                                    verbose=True,\n",
        "                                    stratified=True)\n",
        "\n",
        "    # save optimisation parameters\n",
        "    cv_results = pd.DataFrame(grid_res['cv_results'])\n",
        "    cv_results['params'] = 0\n",
        "    cv_results['params'][0:3] = grid_res['params']\n",
        "\n",
        "\n",
        "    # add roc_auc fCV values\n",
        "    cv_results['roc_auc'] = str(cross_val_score(catboost, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    cv_results['roc_auc_mean'] = np.mean(cross_val_score(catboost, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "    cv_results['roc_auc_std'] = np.std(cross_val_score(catboost, X_train, y_train, cv=StratifiedKFold(5), scoring='roc_auc'))\n",
        "\n",
        "    cv_results.to_excel(f'{path}catboost_optimisation.xlsx')"
      ],
      "metadata": {
        "id": "oaVLrPgDDH3A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPU8e9CAXz9J"
      },
      "source": [
        "#### Function: Optimised table of metrics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yCXIL_H3X-4d"
      },
      "outputs": [],
      "source": [
        "def optimised_metrics_table(model_name):\n",
        "    optimised_metrics = []\n",
        "    # optimised_metrics.append(mcc(y_test, forecast))        #.round(3)                          # MCC\n",
        "    optimised_metrics.append(f1(y_test, forecast).round(3))                                    # F1\n",
        "    optimised_metrics.append(f2_func(y_test, forecast).round(3))                               # F2\n",
        "    optimised_metrics.append(accuracy(y_test, forecast).round(3))                              # Accuracy\n",
        "    optimised_metrics.append(TP_rate(y_test, forecast).round(3))                               # TP rate\n",
        "    optimised_metrics.append(recall(y_test, forecast).round(3))                                # TN rate\n",
        "    precision, recall_, thresholds = precision_recall_curve(y_test, forecast_proba)                  # ------\n",
        "    optimised_metrics.append(auc(recall_, precision).round(3))                                 # PR AUC\n",
        "    optimised_metrics.append(roc_auc(y_test, forecast_proba).round(3))                               # ROC AUC\n",
        "    optimised_metrics.append(confusion_matrix(y_test, forecast).ravel()[0])                    # number of true negative\n",
        "    optimised_metrics.append(confusion_matrix(y_test, forecast).ravel()[1])                    # number of false positive\n",
        "    optimised_metrics.append(confusion_matrix(y_test, forecast).ravel()[2])                    # number of false negative\n",
        "    optimised_metrics.append(confusion_matrix(y_test, forecast).ravel()[3])                    # number of true positive\n",
        "\n",
        "    optimised_metrics = pd.DataFrame(optimised_metrics, columns=[model_name])\n",
        "    # add rows names\n",
        "    optimised_metrics.index = [\n",
        "                              #  \"MCC\",\n",
        "                               \"F1\", \"F2\",\n",
        "                               \"Accuracy\",\n",
        "                               \"Precision\",\n",
        "                               \"Recall\",\n",
        "                               \"PR_AUC\",\n",
        "                               \"ROC_AUC\",\n",
        "                               \"TN\", \"FP\", \"FN\", \"TP\"\n",
        "                                ]\n",
        "    optimised_metrics = optimised_metrics.T\n",
        "    \n",
        "    return optimised_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTdcAmUi_tnD"
      },
      "source": [
        "#### Function metric_table - visualise model scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z_joejjI_sXW"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function provides scores for gridsearch F1-score and metrics for test dataset\n",
        "'''\n",
        "\n",
        "def metric_table(path):  #, X_train=X_train, y_train=y_train\n",
        "\n",
        "    # read gridsearch tables\n",
        "    randomforest_optimisation = pd.read_excel(f'{path}randomforest_optimisation.xlsx', header=[0]) #/content/  ./imp_feat\n",
        "    svm_optimisation = pd.read_excel(f'{path}svm_optimisation.xlsx', header=[0])\n",
        "    knn_optimisation = pd.read_excel(f'{path}knn_optimisation.xlsx', header=[0])\n",
        "    LogisticRegression_optimisation = pd.read_excel(f'{path}LogisticRegression_optimisation.xlsx', header=[0])\n",
        "    catboost_optimisation = pd.read_excel(f'{path}catboost_optimisation.xlsx', header=[0])\n",
        "\n",
        "    params = randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "    params = ast.literal_eval(params[0])\n",
        "    random_forest_model = RandomForestClassifier(**params)\n",
        "    # \n",
        "    params = svm_optimisation[svm_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "    params = ast.literal_eval(params[0])\n",
        "    SVM_model = SVC(**params)\n",
        "    # \n",
        "    # params = nn_optimisation[nn_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "    # params = ast.literal_eval(params[0])\n",
        "    # newral_network_model = MLPClassifier(**params)\n",
        "    # \n",
        "    params = knn_optimisation[knn_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "    params = ast.literal_eval(params[0])\n",
        "    knn_model = KNeighborsClassifier(**params)\n",
        "    # \n",
        "    params = LogisticRegression_optimisation[LogisticRegression_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "    params = ast.literal_eval(params[0])\n",
        "    LR_model = LogisticRegression(**params)\n",
        "    # \n",
        "    params = catboost_optimisation['params'][0]\n",
        "    params = ast.literal_eval(params)\n",
        "    catboost_model = CatBoostClassifier(**c_boost_params, **params)\n",
        "\n",
        "    models = [\n",
        "    random_forest_model,\n",
        "    SVM_model,\n",
        "    # newral_network_model,\n",
        "    LR_model,\n",
        "    knn_model,\n",
        "    catboost_model\n",
        "    ]\n",
        "\n",
        "    mcc_score, f1_score,f2_score, accuracy_score, TP_rate_score, recall_score, auc_precision_recall, roc_auc_score= [], [], [], [], [], [], [], []\n",
        "    tn, fp, fn, tp = [], [], [], []\n",
        "\n",
        "    for model in models:\n",
        "        model.fit(X_train, y_train)\n",
        "        forecast = model.predict(X_test)\n",
        "        forecast_proba = model.predict_proba(X_test)\n",
        "\n",
        "        # mcc_score.append(mcc(y_test, forecast))                                   # MCC\n",
        "        f1_score.append(f1(y_test, forecast))                                       # F1\n",
        "        f2_score.append(f2_func(y_test, forecast))                                  # F1\n",
        "        accuracy_score.append(accuracy(y_test, forecast))                           # Accuracy  \n",
        "        TP_rate_score.append(TP_rate(y_test, forecast))                             # TP rate   tp / (tp + fp)\n",
        "        recall_score.append(recall(y_test, forecast))                               # TN rate\n",
        "        auc_precision_recall.append(average_precision_score(y_test, forecast_proba[:,1]))      # PR AUC\n",
        "        roc_auc_score.append(roc_auc(y_test, forecast_proba[:,1]))                       # ROC AUC\n",
        "        tn.append(confusion_matrix(y_test, forecast).ravel()[0])                  # number of true negative\n",
        "        fp.append(confusion_matrix(y_test, forecast).ravel()[1])                  # number of false positive\n",
        "        fn.append(confusion_matrix(y_test, forecast).ravel()[2])                  # number of false negative\n",
        "        tp.append(confusion_matrix(y_test, forecast).ravel()[3])                  # number of true positive\n",
        "\n",
        "    # create matrix table \n",
        "    metrics_table = pd.DataFrame(columns=pd.MultiIndex.from_product([[\"F2, train set, cv=5\"],[\"mean\", 'std']]))\n",
        "    # metrics_table[(\"Scores on the test set\",\"MCC\")] = mcc_score\n",
        "    metrics_table[(\"Scores on the test set\",\"F1\")] = f1_score\n",
        "    metrics_table[(\"Scores on the test set\",\"F2\")] = f2_score\n",
        "    metrics_table[(\"Scores on the test set\",\"Accuracy\")] = accuracy_score\n",
        "    metrics_table[(\"Scores on the test set\",\"Precision\")] = TP_rate_score\n",
        "    metrics_table[(\"Scores on the test set\",\"Recall\")] = recall_score\n",
        "    metrics_table[(\"Scores on the test set\",\"PR_AUC\")] = auc_precision_recall\n",
        "    metrics_table[(\"Scores on the test set\",\"ROC_AUC\")] = roc_auc_score\n",
        "    metrics_table[(\"Confusion matrix\",\"TN\")] = tn\n",
        "    metrics_table[(\"Confusion matrix\",\"FP\")] = fp\n",
        "    metrics_table[(\"Confusion matrix\",\"FN\")] = fn\n",
        "    metrics_table[(\"Confusion matrix\",\"TP\")] = tp\n",
        "\n",
        "    # modify the rows names\n",
        "    metrics_table.index = [\n",
        "                \"Random Forest\",\n",
        "                \"SVM\",\n",
        "                # \"Multi-layer Perceptron\",\n",
        "                \"Logistic Regression\",\n",
        "                \"KNN\",\n",
        "                \"CatBoost\"\n",
        "                ]\n",
        "\n",
        "\n",
        "\n",
        "    # add cross validated F2 scores on the train set\n",
        "    mean = []\n",
        "    std = []\n",
        "    mean_test_f1,std_test_f1 = randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"mean_test_score\",\"std_test_score\"]].iloc[0]\n",
        "    randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"mean_test_score\",\"std_test_score\"]].iloc[0]\n",
        "    mean.append(mean_test_f1); std.append(std_test_f1)\n",
        "    mean_test_f1,std_test_f1 = svm_optimisation[svm_optimisation['rank_test_score']==1][[\"mean_test_score\",\"std_test_score\"]].iloc[0]\n",
        "    mean.append(mean_test_f1); std.append(std_test_f1)\n",
        "    # mean_test_f1,std_test_f1 = nn_optimisation[nn_optimisation['rank_test_score']==1][[\"mean_test_score\",\"std_test_score\"]].iloc[0]\n",
        "    # mean.append(mean_test_f1); std.append(std_test_f1)\n",
        "    mean_test_f1,std_test_f1 = LogisticRegression_optimisation[LogisticRegression_optimisation['rank_test_score']==1][[\"mean_test_score\",\"std_test_score\"]].iloc[0]\n",
        "    mean.append(mean_test_f1); std.append(std_test_f1)\n",
        "    mean_test_f1,std_test_f1 = knn_optimisation[knn_optimisation['rank_test_score']==1][[\"mean_test_score\",\"std_test_score\"]].iloc[0]\n",
        "    mean.append(mean_test_f1); std.append(std_test_f1)\n",
        "    mean_test_f1,std_test_f1 = catboost_optimisation[['test-F:beta=2-mean', 'test-F:beta=2-std']].iloc[catboost_optimisation.shape[0]-1]\n",
        "    mean.append(mean_test_f1); std.append(std_test_f1)\n",
        "    \n",
        "\n",
        "    metrics_table[(\"F2, train set, cv=5\",\"mean\")] = mean\n",
        "    metrics_table[(\"F2, train set, cv=5\",\"std\")] = std\n",
        "\n",
        "    # add cross validated F2 scores on the train set\n",
        "    mean_roc_auc = []\n",
        "    std_roc_auc = []\n",
        "    mean_test_roc_auc,std_test_roc_auc = randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"roc_auc_mean\",\"roc_auc_std\"]].iloc[0]\n",
        "    randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"roc_auc_mean\",\"roc_auc_std\"]].iloc[0]\n",
        "    mean_roc_auc.append(mean_test_roc_auc); std_roc_auc.append(std_test_roc_auc)\n",
        "    mean_test_roc_auc,std_test_roc_auc = svm_optimisation[svm_optimisation['rank_test_score']==1][[\"roc_auc_mean\",\"roc_auc_std\"]].iloc[0]\n",
        "    mean_roc_auc.append(mean_test_roc_auc); std_roc_auc.append(std_test_roc_auc)\n",
        "    # mean_test_roc_auc,std_test_roc_auc = nn_optimisation[nn_optimisation['rank_test_score']==1][[\"roc_auc_mean\",\"roc_auc_std\"]].iloc[0]\n",
        "    # mean_roc_auc.append(mean_test_roc_auc); std_roc_auc.append(std_test_roc_auc)\n",
        "    mean_test_roc_auc,std_test_roc_auc = LogisticRegression_optimisation[LogisticRegression_optimisation['rank_test_score']==1][[\"roc_auc_mean\",\"roc_auc_std\"]].iloc[0]\n",
        "    mean_roc_auc.append(mean_test_roc_auc); std_roc_auc.append(std_test_roc_auc)\n",
        "    mean_test_roc_auc,std_test_roc_auc = knn_optimisation[knn_optimisation['rank_test_score']==1][[\"roc_auc_mean\",\"roc_auc_std\"]].iloc[0]\n",
        "    mean_roc_auc.append(mean_test_roc_auc); std_roc_auc.append(std_test_roc_auc)\n",
        "    mean_test_roc_auc,std_test_roc_auc = catboost_optimisation[['test-F:beta=2-mean', 'test-F:beta=2-std']].iloc[catboost_optimisation.shape[0]-1]\n",
        "    mean_roc_auc.append(mean_test_roc_auc); std_roc_auc.append(std_test_roc_auc)\n",
        "\n",
        "    metrics_table[(\"ROC_AUC, train set, cv=5\",\"mean\")] = mean_roc_auc\n",
        "    metrics_table[(\"ROC_AUC, train set, cv=5\",\"std\")] = std_roc_auc\n",
        "\n",
        "    return metrics_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JVY3GdXH9uP"
      },
      "source": [
        "#### Define $F_2$ metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UG4s-9AxIAr2"
      },
      "outputs": [],
      "source": [
        "def f2_func(y_true, y_pred):\n",
        "    f2_score = fbeta_score(y_true, y_pred, beta=2.)\n",
        "    return f2_score\n",
        "\n",
        "def my_f2_scorer():\n",
        "    return make_scorer(f2_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "pjVVWxp_4xga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "# clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# sfs1 = SFS(clf, \n",
        "#            k_features=10, \n",
        "#            forward=True, \n",
        "#            floating=False, \n",
        "#            verbose=2,\n",
        "#            scoring='roc_auc',\n",
        "#            cv=5,\n",
        "#            n_jobs=-1)\n",
        "\n",
        "# sfs1 = sfs1.fit(X_train, y_train)\n",
        "# sfs1.subsets_"
      ],
      "metadata": {
        "id": "BfzRSXcGoXjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### random_forest_importances"
      ],
      "metadata": {
        "id": "4Nh1Ta98A_Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_importances(path, n_features = 10, biomarkers=False):\n",
        "    feature_importances = pd.DataFrame()\n",
        "\n",
        "    randomforest_optimisation = pd.read_excel(f'{path}randomforest_optimisation.xlsx', header=[0])\n",
        "\n",
        "\n",
        "    # feature_importances.columns = ['Feature']\n",
        "    params = randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "    params = ast.literal_eval(params[0])\n",
        "    random_forest_model = RandomForestClassifier(**params)\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    feature_importances[\"RandomForest\"] = pd.Series(random_forest_model.feature_importances_)\n",
        "\n",
        "    if biomarkers:\n",
        "        feats = list(map(lambda x: x, list(X_train.columns)))\n",
        "    else:\n",
        "        feats = list(map(lambda x: x[1], list(X_train.columns)))\n",
        "\n",
        "    feature_importances.index = feats\n",
        "\n",
        "    feature_importances = feature_importances.sort_values(\"RandomForest\", ascending=False)\n",
        "    feature_importances['RandomForest'] = feature_importances['RandomForest']/feature_importances['RandomForest'][0]\n",
        "    print()\n",
        "    plt.barh(feature_importances.index[:n_features][::-1], feature_importances['RandomForest'][:n_features][::-1])\n",
        "    plt.show()\n",
        "\n",
        "    return feature_importances"
      ],
      "metadata": {
        "id": "XGXpBZ2fA_rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function: upload_models(x_data, y_data, path, model_list)"
      ],
      "metadata": {
        "id": "S0OXRcJ_7cKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_models(x_data, y_data, path, model_list):\n",
        "    'Return list of trained models'\n",
        "\n",
        "    models = []\n",
        "    model_names = []\n",
        "\n",
        "    if model_list['SVM']:\n",
        "        svm_optimisation = pd.read_excel(f'{path}svm_optimisation.xlsx', header=[0])\n",
        "        params = svm_optimisation[svm_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "        params = ast.literal_eval(params[0])\n",
        "        SVM_model = SVC(**params)\n",
        "        SVM_model.fit(X_train, y_train)\n",
        "        models.append(SVM_model)\n",
        "        model_names.append('SVM')\n",
        "\n",
        "    if model_list['Logistic']:\n",
        "        LogisticRegression_optimisation = pd.read_excel(f'{path}LogisticRegression_optimisation.xlsx', header=[0])\n",
        "        params = LogisticRegression_optimisation[LogisticRegression_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "        params = ast.literal_eval(params[0])\n",
        "        LR_model = LogisticRegression(**params)\n",
        "        LR_model.fit(X_train, y_train)\n",
        "        models.append(LR_model)\n",
        "        model_names.append('Logistic')\n",
        "\n",
        "    if model_list['RandomForest']:\n",
        "        randomforest_optimisation = pd.read_excel(f'{path}randomforest_optimisation.xlsx', header=[0])\n",
        "        params = randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "        params = ast.literal_eval(params[0])\n",
        "        random_forest_model = RandomForestClassifier(**params)\n",
        "        random_forest_model.fit(X_train, y_train)\n",
        "        models.append(random_forest_model)\n",
        "        model_names.append('RandomForest')\n",
        "\n",
        "    if model_list['KNN']:\n",
        "        knn_optimisation = pd.read_excel(f'{path}knn_optimisation.xlsx', header=[0])\n",
        "        params = knn_optimisation[knn_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "        params = ast.literal_eval(params[0])\n",
        "        knn_model = KNeighborsClassifier(**params)\n",
        "        knn_model.fit(X_train, y_train)\n",
        "        models.append(knn_model)\n",
        "        model_names.append('KNN')\n",
        "        # https://catboost.ai/en/docs/concepts/fstr\n",
        "    \n",
        "    if model_list['Catboost']:\n",
        "        catboost_optimisation = pd.read_excel(f'{path}catboost_optimisation.xlsx', header=[0])\n",
        "        params = catboost_optimisation['params'][0]\n",
        "        params = ast.literal_eval(params)\n",
        "        catboost_model = CatBoostClassifier(**c_boost_params, **params)\n",
        "        catboost_model.fit(X_train, y_train)\n",
        "        models.append(catboost_model)\n",
        "        model_names.append('Catboost')\n",
        "        # https://catboost.ai/en/docs/concepts/fstr\n",
        "\n",
        "\n",
        "\n",
        "    return models, model_names"
      ],
      "metadata": {
        "id": "GH3QvYvC4zxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function: feature_selection(dataset, x_data, y_data, path)"
      ],
      "metadata": {
        "id": "_BlCpf3p7stQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(x_data, y_data, path):\n",
        "    'Return dataset with ranged selected features'\n",
        "\n",
        "    # get list of all column names and continuous column names\n",
        "    '___________________________________________________________________________'\n",
        "    all_cols = list(x_data.columns)\n",
        "    continuous_cols = [col for col in x_data.columns if (len((x_data[col].unique())) >= 7)]\n",
        "    feature_selection_dataset = pd.DataFrame(columns=pd.MultiIndex.from_product([[\"LASSO\"],[\"coef\"]]))\n",
        "\n",
        "\n",
        "    # LASSO\n",
        "    '___________________________________________________________________________'\n",
        "    search = GridSearchCV(Lasso(),\n",
        "                          {'alpha':np.linspace(0.1, 1, num=10)**2}, #  np.linspace(0.1, 1, num=10)**2 np.arange(0.1,10,0.1)\n",
        "                          cv = 5, \n",
        "                          scoring=my_f2_scorer(),  #\"neg_mean_squared_error\" my_f2_scorer() 'f1'\n",
        "                          verbose=0\n",
        "                          )\n",
        "\n",
        "    search.fit(X_train, y_train)\n",
        "    feature_selection_dataset['LASSO', 'coef'] = np.abs(search.best_estimator_.coef_)\n",
        "    # feature_selection_dataset['LASSO', 'coef'][feature_selection_dataset['LASSO', 'coef']>0] = 1\n",
        "    print(\"Calculated LASSO\")\n",
        "\n",
        "\n",
        "    # get all trained models\n",
        "    '___________________________________________________________________________'\n",
        "    models, model_names = upload_models(x_data = x_data,\n",
        "                                        y_data = y_data,\n",
        "                                        path = path, \n",
        "                                        model_list = {'SVM': True, \n",
        "                                                      'Logistic': True, \n",
        "                                                      'RandomForest': True, \n",
        "                                                      'KNN': True, \n",
        "                                                      'Catboost': True})\n",
        "\n",
        "\n",
        "    # Sequencial feature selection\n",
        "    '___________________________________________________________________________'\n",
        "    \n",
        "    sfs1 = SFS_xtend(knn, \n",
        "                  k_features=20, \n",
        "                  forward=True, \n",
        "                  floating=True, \n",
        "                  verbose=2,\n",
        "                  direction = 'forward',\n",
        "                  cv = StratifiedKFold(5),\n",
        "                  scoring=my_f2_scorer(),\n",
        "                  n_jobs=-1)\n",
        "\n",
        "    sfs1 = sfs1.fit(X, y)\n",
        "\n",
        "    for number in [0,1]:\n",
        "        sfs = SequentialFeatureSelector(estimator = models[number],\n",
        "                                        n_features_to_select=None,\n",
        "                                        cv = StratifiedKFold(5),\n",
        "                                        scoring = my_f2_scorer(), \n",
        "                                        direction = 'backward',\n",
        "                                        n_jobs=-1\n",
        "                                        )\n",
        "        sfs.fit(X_train, y_train)\n",
        "        feature_selection_dataset['SFS', model_names[number]] = sfs.get_support()*1\n",
        "    print(\"Calculated SFS\")\n",
        "    # # Recursive feature elimination with cross validation  - плохо отбирает для RandomForest, Catboost\n",
        "    # '___________________________________________________________________________'\n",
        "    # # models with feature importance do not have to perform SFS.    \n",
        "    # for number in [1,2,4]:\n",
        "    #     rfecv = RFECV(estimator = models[number],\n",
        "    #                                     # n_features_to_select=None,\n",
        "    #                                     cv = StratifiedKFold(5),\n",
        "    #                                     scoring = my_f2_scorer(),\n",
        "    #                                     n_jobs=-1\n",
        "    #                                     )\n",
        "    #     rfecv.fit(X_train, y_train)\n",
        "    #     feature_selection_dataset['RFECV', model_names[number]] = rfecv.get_support()*1\n",
        "    # print(\"Calculated RFECV\")\n",
        "\n",
        "    # model importances\n",
        "    '___________________________________________________________________________'\n",
        "    feature_selection_dataset['Importances', 'RandomForest'] = models[2].feature_importances_\n",
        "    feature_selection_dataset['Importances', 'CatBoost'] = models[4].feature_importances_\n",
        "    feature_selection_dataset['Importances', 'Logistic'] = np.abs(models[1].coef_[0])\n",
        "\n",
        "    # # Drop-Column Importance\n",
        "    # '___________________________________________________________________________'\n",
        "    # \"\"\"get score via Drop-Column Importance for models\"\"\"\n",
        "    # for number in range(5):\n",
        "    #     # clone the model to have the exact same specification as the one initially trained\n",
        "    #     model_clone = clone(models[number])\n",
        "    #     # set random_state for comparability\n",
        "    #     model_clone.random_state = 37\n",
        "    #     # training and scoring the benchmark model\n",
        "    #     model_clone.fit(X_train, y_train)\n",
        "\n",
        "    #     # benchmark_score = model_clone.score(X_train, y_train)\n",
        "    #     y_pred = model_clone.predict(X_test)\n",
        "    #     benchmark_score = f2_func(y_test, y_pred)\n",
        "\n",
        "    #     # list for storing feature importances\n",
        "    #     importances = []\n",
        "        \n",
        "    #     # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
        "    #     for col in X_train.columns:\n",
        "    #         model_clone = clone(models[number])\n",
        "    #         model_clone.random_state = random_state\n",
        "    #         model_clone.fit(X_train.drop(col, axis = 1), y_train)\n",
        "    #         # drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)\n",
        "    #         y_pred = model_clone.predict(X_test.drop(col, axis = 1))\n",
        "    #         drop_col_score = f2_func(y_test, y_pred)\n",
        "    #         importances.append(benchmark_score - drop_col_score)\n",
        "        \n",
        "    #     feature_selection_dataset[('Drop-Column Importance', model_names[number])] = importances\n",
        "    \n",
        "\n",
        "    # Set column names as index\n",
        "    '___________________________________________________________________________'\n",
        "    feature_selection_dataset.index = all_cols\n",
        "\n",
        "    # # MRMR\n",
        "    # '___________________________________________________________________________'\n",
        "    # feature_selection_dataset[('MRMR', '')] = 0\n",
        "    # selected_features = mrmr_classif(X=X_train, y=y_train, K=40)\n",
        "    # feature_selection_dataset.loc[selected_features][('MRMR', '')] = 1\n",
        "\n",
        "\n",
        "    # Unsupervised selection with Pearson correlation coefs\n",
        "    '___________________________________________________________________________'\n",
        "    # correlation_matrix = dataset[continuous_cols].corr( method='pearson').abs()\n",
        "    # correlation_matrix  = pd.DataFrame(correlation_matrix)\n",
        "    # # iteratively remove features that have correlation > 0.95\n",
        "    # i=0\n",
        "    # j=0\n",
        "    # cols = correlation_matrix.shape[1]\n",
        "    # rows = correlation_matrix.shape[0]\n",
        "\n",
        "    # while i < cols: \n",
        "    #     while j < rows:\n",
        "    #         if correlation_matrix.iloc[j,i]>0.95 and correlation_matrix.iloc[j,i]!=1:\n",
        "    #             correlation_matrix.drop(index=correlation_matrix.index[j], inplace=True)\n",
        "    #             correlation_matrix.drop(columns=correlation_matrix.columns[j], inplace=True)\n",
        "    #         else:\n",
        "    #             j+=1\n",
        "    #         rows = correlation_matrix.shape[0]\n",
        "    #     i+=1\n",
        "    #     j=0\n",
        "    #     cols = correlation_matrix.shape[1]\n",
        "\n",
        "    # removed_after_unsupervised = list(set(continuous_cols) - set(correlation_matrix.columns))\n",
        "\n",
        "\n",
        "    # Process data and download dataset\n",
        "    '___________________________________________________________________________'\n",
        "    # drop columns from unsupervised selection\n",
        "    # feature_selection_dataset.drop(index = removed_after_unsupervised, inplace=True)\n",
        "\n",
        "    # rank columns\n",
        "    feature_selection_dataset['sum'] = feature_selection_dataset.apply((lambda x: x.iloc[:6].sum()), axis=1)\n",
        "    feature_selection_dataset.sort_values('sum', inplace=True, ascending=True)\n",
        "\n",
        "    feature_selection_dataset.to_excel(f'{path}feature_selection_dataset.xlsx')\n",
        "\n",
        "    return feature_selection_dataset"
      ],
      "metadata": {
        "id": "S3JU3dMc707H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lancet paper"
      ],
      "metadata": {
        "id": "6bATJ4DDKaKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset ABC - all-cause death"
      ],
      "metadata": {
        "id": "WptxVaPIf6Rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Subset"
      ],
      "metadata": {
        "id": "qSYGBNL4f6Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_lancet, header=[0], index_col=0, usecols=list(range(15)))\n",
        "y_train = pd.read_excel(link_train_lancet, header=[0], index_col=0, usecols=[0,15])\n",
        "X_test = pd.read_excel(link_test_lancet, header=[0], index_col=0, usecols=list(range(15)))\n",
        "y_test = pd.read_excel(link_test_lancet, header=[0], index_col=0, usecols=[0,15])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = './HSE project/Optimisation data/lancet/ABC death/'\n",
        "results_path = './HSE project/Graphics/lancet/'\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "id": "2xL1weQEghiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07911184-4904-4195-caa9-096e17cefd3f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (450, 14)\n",
            "y_train shape:\t (450, 1)\n",
            "X_test shape:\t (105, 14)\n",
            "y_test shape:\t (105, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3SyRKrLf6Rw"
      },
      "source": [
        "##### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "TdfgIobJf6Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnhVbxEIf6Rw"
      },
      "source": [
        "##### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_dbeHjNFf6Rx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "4d84388f-b80e-4a4b-c5c0-b84273751fe5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x10633a4f0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_3078b th {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_3078b_row0_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #c7d7f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_3078b_row0_col1, #T_3078b_row0_col4, #T_3078b_row0_col5, #T_3078b_row0_col6, #T_3078b_row0_col7, #T_3078b_row0_col9, #T_3078b_row0_col10, #T_3078b_row0_col11, #T_3078b_row0_col12, #T_3078b_row0_col14, #T_3078b_row1_col1, #T_3078b_row1_col4, #T_3078b_row1_col5, #T_3078b_row1_col6, #T_3078b_row1_col7, #T_3078b_row1_col9, #T_3078b_row1_col10, #T_3078b_row1_col11, #T_3078b_row1_col12, #T_3078b_row1_col14, #T_3078b_row2_col1, #T_3078b_row2_col4, #T_3078b_row2_col5, #T_3078b_row2_col6, #T_3078b_row2_col7, #T_3078b_row2_col9, #T_3078b_row2_col10, #T_3078b_row2_col11, #T_3078b_row2_col12, #T_3078b_row2_col14, #T_3078b_row3_col1, #T_3078b_row3_col4, #T_3078b_row3_col5, #T_3078b_row3_col6, #T_3078b_row3_col7, #T_3078b_row3_col9, #T_3078b_row3_col10, #T_3078b_row3_col11, #T_3078b_row3_col12, #T_3078b_row3_col14, #T_3078b_row4_col1, #T_3078b_row4_col4, #T_3078b_row4_col5, #T_3078b_row4_col6, #T_3078b_row4_col7, #T_3078b_row4_col9, #T_3078b_row4_col10, #T_3078b_row4_col11, #T_3078b_row4_col12, #T_3078b_row4_col14 {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_3078b_row0_col2, #T_3078b_row1_col8, #T_3078b_row1_col13, #T_3078b_row2_col0, #T_3078b_row4_col3 {\n",
              "  text-align: center;\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_3078b_row0_col3 {\n",
              "  text-align: center;\n",
              "  background-color: #81a4fb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_3078b_row0_col8 {\n",
              "  text-align: center;\n",
              "  background-color: #9abbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_3078b_row0_col13 {\n",
              "  text-align: center;\n",
              "  background-color: #e36c55;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_3078b_row1_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #f6bea4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_3078b_row1_col2 {\n",
              "  text-align: center;\n",
              "  background-color: #7295f4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_3078b_row1_col3, #T_3078b_row3_col0, #T_3078b_row3_col2, #T_3078b_row3_col13, #T_3078b_row4_col8 {\n",
              "  text-align: center;\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_3078b_row2_col2 {\n",
              "  text-align: center;\n",
              "  background-color: #536edd;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_3078b_row2_col3 {\n",
              "  text-align: center;\n",
              "  background-color: #6788ee;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_3078b_row2_col8 {\n",
              "  text-align: center;\n",
              "  background-color: #c73635;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_3078b_row2_col13 {\n",
              "  text-align: center;\n",
              "  background-color: #c9d7f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_3078b_row3_col3 {\n",
              "  text-align: center;\n",
              "  background-color: #efcfbf;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_3078b_row3_col8 {\n",
              "  text-align: center;\n",
              "  background-color: #adc9fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_3078b_row4_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #abc8fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_3078b_row4_col2 {\n",
              "  text-align: center;\n",
              "  background-color: #c1d4f4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_3078b_row4_col13 {\n",
              "  text-align: center;\n",
              "  background-color: #8db0fe;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_3078b\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_3078b_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">F2, train set, cv=5</th>\n",
              "      <th id=\"T_3078b_level0_col2\" class=\"col_heading level0 col2\" colspan=\"7\">Scores on the test set</th>\n",
              "      <th id=\"T_3078b_level0_col9\" class=\"col_heading level0 col9\" colspan=\"4\">Confusion matrix</th>\n",
              "      <th id=\"T_3078b_level0_col13\" class=\"col_heading level0 col13\" colspan=\"2\">ROC_AUC, train set, cv=5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"blank level1\" >&nbsp;</th>\n",
              "      <th id=\"T_3078b_level1_col0\" class=\"col_heading level1 col0\" >mean</th>\n",
              "      <th id=\"T_3078b_level1_col1\" class=\"col_heading level1 col1\" >std</th>\n",
              "      <th id=\"T_3078b_level1_col2\" class=\"col_heading level1 col2\" >F1</th>\n",
              "      <th id=\"T_3078b_level1_col3\" class=\"col_heading level1 col3\" >F2</th>\n",
              "      <th id=\"T_3078b_level1_col4\" class=\"col_heading level1 col4\" >Accuracy</th>\n",
              "      <th id=\"T_3078b_level1_col5\" class=\"col_heading level1 col5\" >Precision</th>\n",
              "      <th id=\"T_3078b_level1_col6\" class=\"col_heading level1 col6\" >Recall</th>\n",
              "      <th id=\"T_3078b_level1_col7\" class=\"col_heading level1 col7\" >PR_AUC</th>\n",
              "      <th id=\"T_3078b_level1_col8\" class=\"col_heading level1 col8\" >ROC_AUC</th>\n",
              "      <th id=\"T_3078b_level1_col9\" class=\"col_heading level1 col9\" >TN</th>\n",
              "      <th id=\"T_3078b_level1_col10\" class=\"col_heading level1 col10\" >FP</th>\n",
              "      <th id=\"T_3078b_level1_col11\" class=\"col_heading level1 col11\" >FN</th>\n",
              "      <th id=\"T_3078b_level1_col12\" class=\"col_heading level1 col12\" >TP</th>\n",
              "      <th id=\"T_3078b_level1_col13\" class=\"col_heading level1 col13\" >mean</th>\n",
              "      <th id=\"T_3078b_level1_col14\" class=\"col_heading level1 col14\" >std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_3078b_level0_row0\" class=\"row_heading level0 row0\" >Random Forest</th>\n",
              "      <td id=\"T_3078b_row0_col0\" class=\"data row0 col0\" >0.806</td>\n",
              "      <td id=\"T_3078b_row0_col1\" class=\"data row0 col1\" >0.098</td>\n",
              "      <td id=\"T_3078b_row0_col2\" class=\"data row0 col2\" >0.486</td>\n",
              "      <td id=\"T_3078b_row0_col3\" class=\"data row0 col3\" >0.541</td>\n",
              "      <td id=\"T_3078b_row0_col4\" class=\"data row0 col4\" >0.657</td>\n",
              "      <td id=\"T_3078b_row0_col5\" class=\"data row0 col5\" >0.415</td>\n",
              "      <td id=\"T_3078b_row0_col6\" class=\"data row0 col6\" >0.586</td>\n",
              "      <td id=\"T_3078b_row0_col7\" class=\"data row0 col7\" >0.585</td>\n",
              "      <td id=\"T_3078b_row0_col8\" class=\"data row0 col8\" >0.747</td>\n",
              "      <td id=\"T_3078b_row0_col9\" class=\"data row0 col9\" >52</td>\n",
              "      <td id=\"T_3078b_row0_col10\" class=\"data row0 col10\" >24</td>\n",
              "      <td id=\"T_3078b_row0_col11\" class=\"data row0 col11\" >12</td>\n",
              "      <td id=\"T_3078b_row0_col12\" class=\"data row0 col12\" >17</td>\n",
              "      <td id=\"T_3078b_row0_col13\" class=\"data row0 col13\" >0.852</td>\n",
              "      <td id=\"T_3078b_row0_col14\" class=\"data row0 col14\" >0.073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3078b_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
              "      <td id=\"T_3078b_row1_col0\" class=\"data row1 col0\" >0.830</td>\n",
              "      <td id=\"T_3078b_row1_col1\" class=\"data row1 col1\" >0.027</td>\n",
              "      <td id=\"T_3078b_row1_col2\" class=\"data row1 col2\" >0.500</td>\n",
              "      <td id=\"T_3078b_row1_col3\" class=\"data row1 col3\" >0.704</td>\n",
              "      <td id=\"T_3078b_row1_col4\" class=\"data row1 col4\" >0.467</td>\n",
              "      <td id=\"T_3078b_row1_col5\" class=\"data row1 col5\" >0.337</td>\n",
              "      <td id=\"T_3078b_row1_col6\" class=\"data row1 col6\" >0.966</td>\n",
              "      <td id=\"T_3078b_row1_col7\" class=\"data row1 col7\" >0.506</td>\n",
              "      <td id=\"T_3078b_row1_col8\" class=\"data row1 col8\" >0.734</td>\n",
              "      <td id=\"T_3078b_row1_col9\" class=\"data row1 col9\" >21</td>\n",
              "      <td id=\"T_3078b_row1_col10\" class=\"data row1 col10\" >55</td>\n",
              "      <td id=\"T_3078b_row1_col11\" class=\"data row1 col11\" >1</td>\n",
              "      <td id=\"T_3078b_row1_col12\" class=\"data row1 col12\" >28</td>\n",
              "      <td id=\"T_3078b_row1_col13\" class=\"data row1 col13\" >0.774</td>\n",
              "      <td id=\"T_3078b_row1_col14\" class=\"data row1 col14\" >0.079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3078b_level0_row2\" class=\"row_heading level0 row2\" >Logistic Regression</th>\n",
              "      <td id=\"T_3078b_row2_col0\" class=\"data row2 col0\" >0.762</td>\n",
              "      <td id=\"T_3078b_row2_col1\" class=\"data row2 col1\" >0.104</td>\n",
              "      <td id=\"T_3078b_row2_col2\" class=\"data row2 col2\" >0.492</td>\n",
              "      <td id=\"T_3078b_row2_col3\" class=\"data row2 col3\" >0.526</td>\n",
              "      <td id=\"T_3078b_row2_col4\" class=\"data row2 col4\" >0.686</td>\n",
              "      <td id=\"T_3078b_row2_col5\" class=\"data row2 col5\" >0.444</td>\n",
              "      <td id=\"T_3078b_row2_col6\" class=\"data row2 col6\" >0.552</td>\n",
              "      <td id=\"T_3078b_row2_col7\" class=\"data row2 col7\" >0.643</td>\n",
              "      <td id=\"T_3078b_row2_col8\" class=\"data row2 col8\" >0.776</td>\n",
              "      <td id=\"T_3078b_row2_col9\" class=\"data row2 col9\" >56</td>\n",
              "      <td id=\"T_3078b_row2_col10\" class=\"data row2 col10\" >20</td>\n",
              "      <td id=\"T_3078b_row2_col11\" class=\"data row2 col11\" >13</td>\n",
              "      <td id=\"T_3078b_row2_col12\" class=\"data row2 col12\" >16</td>\n",
              "      <td id=\"T_3078b_row2_col13\" class=\"data row2 col13\" >0.814</td>\n",
              "      <td id=\"T_3078b_row2_col14\" class=\"data row2 col14\" >0.086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3078b_level0_row3\" class=\"row_heading level0 row3\" >KNN</th>\n",
              "      <td id=\"T_3078b_row3_col0\" class=\"data row3 col0\" >0.867</td>\n",
              "      <td id=\"T_3078b_row3_col1\" class=\"data row3 col1\" >0.055</td>\n",
              "      <td id=\"T_3078b_row3_col2\" class=\"data row3 col2\" >0.567</td>\n",
              "      <td id=\"T_3078b_row3_col3\" class=\"data row3 col3\" >0.617</td>\n",
              "      <td id=\"T_3078b_row3_col4\" class=\"data row3 col4\" >0.724</td>\n",
              "      <td id=\"T_3078b_row3_col5\" class=\"data row3 col5\" >0.500</td>\n",
              "      <td id=\"T_3078b_row3_col6\" class=\"data row3 col6\" >0.655</td>\n",
              "      <td id=\"T_3078b_row3_col7\" class=\"data row3 col7\" >0.517</td>\n",
              "      <td id=\"T_3078b_row3_col8\" class=\"data row3 col8\" >0.749</td>\n",
              "      <td id=\"T_3078b_row3_col9\" class=\"data row3 col9\" >57</td>\n",
              "      <td id=\"T_3078b_row3_col10\" class=\"data row3 col10\" >19</td>\n",
              "      <td id=\"T_3078b_row3_col11\" class=\"data row3 col11\" >10</td>\n",
              "      <td id=\"T_3078b_row3_col12\" class=\"data row3 col12\" >19</td>\n",
              "      <td id=\"T_3078b_row3_col13\" class=\"data row3 col13\" >0.866</td>\n",
              "      <td id=\"T_3078b_row3_col14\" class=\"data row3 col14\" >0.070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3078b_level0_row4\" class=\"row_heading level0 row4\" >CatBoost</th>\n",
              "      <td id=\"T_3078b_row4_col0\" class=\"data row4 col0\" >0.797</td>\n",
              "      <td id=\"T_3078b_row4_col1\" class=\"data row4 col1\" >0.150</td>\n",
              "      <td id=\"T_3078b_row4_col2\" class=\"data row4 col2\" >0.519</td>\n",
              "      <td id=\"T_3078b_row4_col3\" class=\"data row4 col3\" >0.496</td>\n",
              "      <td id=\"T_3078b_row4_col4\" class=\"data row4 col4\" >0.752</td>\n",
              "      <td id=\"T_3078b_row4_col5\" class=\"data row4 col5\" >0.560</td>\n",
              "      <td id=\"T_3078b_row4_col6\" class=\"data row4 col6\" >0.483</td>\n",
              "      <td id=\"T_3078b_row4_col7\" class=\"data row4 col7\" >0.657</td>\n",
              "      <td id=\"T_3078b_row4_col8\" class=\"data row4 col8\" >0.778</td>\n",
              "      <td id=\"T_3078b_row4_col9\" class=\"data row4 col9\" >65</td>\n",
              "      <td id=\"T_3078b_row4_col10\" class=\"data row4 col10\" >11</td>\n",
              "      <td id=\"T_3078b_row4_col11\" class=\"data row4 col11\" >15</td>\n",
              "      <td id=\"T_3078b_row4_col12\" class=\"data row4 col12\" >14</td>\n",
              "      <td id=\"T_3078b_row4_col13\" class=\"data row4 col13\" >0.797</td>\n",
              "      <td id=\"T_3078b_row4_col14\" class=\"data row4 col14\" >0.150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2, train set, cv=5\",\"mean\"), (\"ROC_AUC, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "metric = ['F2','Precision','Recall','ROC_AUC']\n",
        "\n",
        "table = pd.read_excel(f'{optimisation_path}metrics_table.xlsx', header=[0,1], index_col=[0]) \n",
        "datasets = pd.DataFrame(table.loc[:, ('Scores on the test set', metric)].values.round(3),columns=['F2','Precision','Recall','ROC AUC'])\n",
        "\n",
        "models=['RandomForest', 'SVM', 'Logistic Regression', 'KNN', 'CatBoost']\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=column, x=models, y=datasets[column]) for column in datasets.columns ])\n",
        "\n",
        "# add error whiskers from gridsearchCV\n",
        "# if 1:\n",
        "#     # if metric == 'F2':\n",
        "#     datasets_mean = pd.DataFrame()\n",
        "#     datasets_mean[('F2, train set, cv=5', 'mean')] = list(table.loc[:, ('F2, train set, cv=5', 'mean')].values.round(3)) \n",
        "#     datasets_mean[('F2, train set, cv=5', 'std')] = list(table.loc[:, ('F2, train set, cv=5', 'std')].values.round(3)) \n",
        "#     # datasets_std[datasets_std.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3)) \n",
        "#     fig.add_traces([go.Box(name=column, x=models, \n",
        "#                            y=datasets_mean.iloc[column, ('F2, train set, cv=5', 'mean')], \n",
        "#                            marker=dict(color=\"black\"), \n",
        "#                            showlegend = False) for column in table.index])\n",
        "#     fig.update_traces(\n",
        "#     selector=dict(type=\"box\"), # update only boxes\n",
        "#     boxpoints=\"all\", # show points\n",
        "#     pointpos=0, # centered\n",
        "#     jitter=0, # no jitter\n",
        "#     line_color=\"rgba(255,255,255,0)\", # hide box lines\n",
        "#     fillcolor=\"rgba(255,255,255,0)\", # hide box fill\n",
        "    \n",
        "#     )\n",
        "    # fig.update_layout(boxmode=\"group\",)\n",
        "\n",
        "    # fig.add_traces([go.Bar(name=column, x=models, \n",
        "    #                        y=datasets_mean[column], \n",
        "    #                        xaxis=\"x2\",  \n",
        "    #                        error_y=dict(type='data',  \n",
        "    #                                     array=datasets_std[column], \n",
        "    #                                     color=\"rgba(0,0,0,1)\",\n",
        "    #                                     thickness=1), \n",
        "    #                        marker=dict(opacity=0,\n",
        "    #                                   #  color=\"rgba(255,255,255,0)\"\n",
        "    #                                    ), \n",
        "    #                        showlegend = False) for column in datasets.columns])  \n",
        "    \n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Models')\n",
        "fig.update_yaxes(title='Metric values', range=[0., 1.0])\n",
        "fig.update_layout(xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False})\n",
        "fig.update_layout(barmode='group', \n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Metrics', y=0.5), \n",
        "                  title=dict(text=f'Test metrics: \"lancet\" subset (ABC)', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "if 1:\n",
        "    fig.add_shape(type='line',\n",
        "                  x0=-0.5,\n",
        "                  y0=0.5,\n",
        "                  x1=4.5,\n",
        "                  y1=0.5,\n",
        "                  line=dict(color='black',  width=2, dash='dot'),\n",
        "                  xref='x',\n",
        "                  yref='y',\n",
        "                  layer='below')   \n",
        "    \n",
        "# figure size\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1300,\n",
        "    height=450,)\n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "qjSufoVvYzDT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "0e845bb1-710f-4a68-c227-3dbce62e5c7e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.9.0.min.js\"></script>                <div id=\"947c94cd-6184-4d87-8611-8c09469f158d\" class=\"plotly-graph-div\" style=\"height:450px; width:1300px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"947c94cd-6184-4d87-8611-8c09469f158d\")) {                    Plotly.newPlot(                        \"947c94cd-6184-4d87-8611-8c09469f158d\",                        [{\"name\":\"F2\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.541,0.704,0.526,0.617,0.496],\"type\":\"bar\"},{\"name\":\"Precision\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.415,0.337,0.444,0.5,0.56],\"type\":\"bar\"},{\"name\":\"Recall\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.586,0.966,0.552,0.655,0.483],\"type\":\"bar\"},{\"name\":\"ROC AUC\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.747,0.734,0.776,0.749,0.778],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"title\":{\"text\":\"Metric values\"},\"range\":[0.0,1.0]},\"xaxis2\":{\"overlaying\":\"x\",\"range\":[-0.515,4.515],\"showticklabels\":false},\"legend\":{\"orientation\":\"v\",\"title\":{\"text\":\"Metrics\"},\"y\":0.5},\"title\":{\"text\":\"Test metrics: \\\"lancet\\\" subset (ABC)\",\"x\":0.5},\"margin\":{\"l\":60,\"r\":20,\"t\":60,\"b\":40},\"barmode\":\"group\",\"bargap\":0.3,\"bargroupgap\":0.3,\"shapes\":[{\"layer\":\"below\",\"line\":{\"color\":\"black\",\"dash\":\"dot\",\"width\":2},\"type\":\"line\",\"x0\":-0.5,\"x1\":4.5,\"xref\":\"x\",\"y0\":0.5,\"y1\":0.5,\"yref\":\"y\"}],\"autosize\":false,\"width\":1300,\"height\":450},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('947c94cd-6184-4d87-8611-8c09469f158d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig.write_image(f\"{results_path}metrics.pdf\", engine=\"kaleido\")\n",
        "fig.write_image(f\"{results_path}/metrics.jpeg\", engine=\"kaleido\")"
      ],
      "metadata": {
        "id": "x23aAjIzKX7l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature selection"
      ],
      "metadata": {
        "id": "FPC8slHFf6Rx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MabTa0kqf6Rx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "a76848bb-8f52-4452-a762-9b9572a4632c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x161b002b0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_9d3b1 th {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_9d3b1_row0_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9d3b1_row1_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #d44e41;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9d3b1_row2_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #f08a6c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9d3b1_row3_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #c5d6f2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9d3b1_row4_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #b6cefa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9d3b1_row5_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #8caffe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9d3b1_row6_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #86a9fc;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9d3b1_row7_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #7b9ff9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9d3b1_row8_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #4257c9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9d3b1_row9_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #3e51c5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9d3b1_row10_col0, #T_9d3b1_row11_col0, #T_9d3b1_row12_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #3d50c3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9d3b1_row13_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_9d3b1\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_9d3b1_level0_col0\" class=\"col_heading level0 col0\" >RandomForest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row0\" class=\"row_heading level0 row0\" >МФА</th>\n",
              "      <td id=\"T_9d3b1_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row1\" class=\"row_heading level0 row1\" >Возраст</th>\n",
              "      <td id=\"T_9d3b1_row1_col0\" class=\"data row1 col0\" >0.909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row2\" class=\"row_heading level0 row2\" >Гемоглобин, г/л</th>\n",
              "      <td id=\"T_9d3b1_row2_col0\" class=\"data row2 col0\" >0.786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row3\" class=\"row_heading level0 row3\" >СКФ EPI</th>\n",
              "      <td id=\"T_9d3b1_row3_col0\" class=\"data row3 col0\" >0.415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row4\" class=\"row_heading level0 row4\" >ГБ</th>\n",
              "      <td id=\"T_9d3b1_row4_col0\" class=\"data row4 col0\" >0.370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row5\" class=\"row_heading level0 row5\" >Хсобщ, ммоль/л</th>\n",
              "      <td id=\"T_9d3b1_row5_col0\" class=\"data row5 col0\" >0.249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row6\" class=\"row_heading level0 row6\" >Cегмент ST</th>\n",
              "      <td id=\"T_9d3b1_row6_col0\" class=\"data row6 col0\" >0.232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row7\" class=\"row_heading level0 row7\" >ФВ ЛЖ</th>\n",
              "      <td id=\"T_9d3b1_row7_col0\" class=\"data row7 col0\" >0.203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row8\" class=\"row_heading level0 row8\" >СД</th>\n",
              "      <td id=\"T_9d3b1_row8_col0\" class=\"data row8 col0\" >0.025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row9\" class=\"row_heading level0 row9\" >Пол</th>\n",
              "      <td id=\"T_9d3b1_row9_col0\" class=\"data row9 col0\" >0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row10\" class=\"row_heading level0 row10\" >пост-ИМ</th>\n",
              "      <td id=\"T_9d3b1_row10_col0\" class=\"data row10 col0\" >0.010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row11\" class=\"row_heading level0 row11\" >пост-стент</th>\n",
              "      <td id=\"T_9d3b1_row11_col0\" class=\"data row11 col0\" >0.009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row12\" class=\"row_heading level0 row12\" >пост-ОНМК</th>\n",
              "      <td id=\"T_9d3b1_row12_col0\" class=\"data row12 col0\" >0.009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d3b1_level0_row13\" class=\"row_heading level0 row13\" >пост-ВЧ-кровоизлияние</th>\n",
              "      <td id=\"T_9d3b1_row13_col0\" class=\"data row13 col0\" >0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Random Forest feature importances\n",
        "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
        "feature_importances = pd.DataFrame()\n",
        "\n",
        "randomforest_optimisation = pd.read_excel(f'{optimisation_path}randomforest_optimisation.xlsx', header=[0])\n",
        "\n",
        "\n",
        "# feature_importances.columns = ['Feature']\n",
        "params = randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "params = ast.literal_eval(params[0])\n",
        "random_forest_model = RandomForestClassifier(**params)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "feature_importances[\"RandomForest\"] = pd.Series(random_forest_model.feature_importances_)\n",
        "\n",
        "feats = list(map(lambda x: eval(x)[1], list(X_train.columns)))\n",
        "feature_importances.index = feats\n",
        "\n",
        "feature_importances = feature_importances.sort_values(\"RandomForest\", ascending=False)\n",
        "feature_importances['RandomForest'] = feature_importances['RandomForest']/feature_importances['RandomForest'][0]\n",
        "\n",
        "feature_importances.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[\"RandomForest\"])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_from_paper = pd.DataFrame()\n",
        "# https://ars.els-cdn.com/content/image/1-s2.0-S0140673620325198-mmc1.pdf\n",
        "data_from_paper['Paper']= [0.77, 0.49, 1, 0.22, 0.1, 0.7, 0.1, 0.22, 0.09,  0.24, 0.09, 0.12, 0.11, 0.28]\n",
        "data_from_paper.index = ['Возраст', 'СКФ EPI', 'ФВ ЛЖ', 'МФА', 'Хсобщ, ммоль/л', 'Гемоглобин, г/л', 'пост-ИМ','пост-стент','ГБ',  'СД', 'пост-ОНМК',  'Cегмент ST','Пол', 'пост-ВЧ-кровоизлияние']"
      ],
      "metadata": {
        "id": "2eKevM7P0Q-W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.concat([feature_importances, data_from_paper], axis=1) \n",
        "result"
      ],
      "metadata": {
        "id": "nWTV0npH38OA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "333c6455-8ec0-4c1c-f819-a05c4f5be9c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       RandomForest  Paper\n",
              "МФА                        1.000000   0.22\n",
              "Возраст                    0.909144   0.77\n",
              "Гемоглобин, г/л            0.785624   0.70\n",
              "СКФ EPI                    0.414865   0.49\n",
              "ГБ                         0.369983   0.09\n",
              "Хсобщ, ммоль/л             0.249126   0.10\n",
              "Cегмент ST                 0.232120   0.12\n",
              "ФВ ЛЖ                      0.202931   1.00\n",
              "СД                         0.025074   0.24\n",
              "Пол                        0.013807   0.11\n",
              "пост-ИМ                    0.010111   0.10\n",
              "пост-стент                 0.009495   0.22\n",
              "пост-ОНМК                  0.008874   0.09\n",
              "пост-ВЧ-кровоизлияние      0.000000   0.28"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>МФА</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Возраст</th>\n",
              "      <td>0.909144</td>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Гемоглобин, г/л</th>\n",
              "      <td>0.785624</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>СКФ EPI</th>\n",
              "      <td>0.414865</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ГБ</th>\n",
              "      <td>0.369983</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Хсобщ, ммоль/л</th>\n",
              "      <td>0.249126</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cегмент ST</th>\n",
              "      <td>0.232120</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ФВ ЛЖ</th>\n",
              "      <td>0.202931</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>СД</th>\n",
              "      <td>0.025074</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Пол</th>\n",
              "      <td>0.013807</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>пост-ИМ</th>\n",
              "      <td>0.010111</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>пост-стент</th>\n",
              "      <td>0.009495</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>пост-ОНМК</th>\n",
              "      <td>0.008874</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>пост-ВЧ-кровоизлияние</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result['RandomForest'] = result['RandomForest']/result['RandomForest'][0]\n",
        "result.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[\"RandomForest\", \"Paper\"])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "4chSn20Z0uIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "2e7d640f-2821-41e8-c828-c8e7a78aa2f1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x162a94460>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_521b9 th {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_521b9_row0_col0, #T_521b9_row7_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row0_col1, #T_521b9_row11_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #6788ee;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row1_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #d44e41;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row1_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #f49a7b;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_521b9_row2_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #f08a6c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row2_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #f7b79b;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_521b9_row3_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #c5d6f2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_521b9_row3_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #ccd9ed;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_521b9_row4_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #b6cefa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_521b9_row4_col1, #T_521b9_row12_col1, #T_521b9_row13_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row5_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #8caffe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_521b9_row5_col1, #T_521b9_row10_col0, #T_521b9_row10_col1, #T_521b9_row11_col0, #T_521b9_row12_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #3d50c3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row6_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #86a9fc;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row6_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #445acc;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row7_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #7b9ff9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row8_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #4257c9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row8_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #6f92f3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row9_col0 {\n",
              "  text-align: center;\n",
              "  background-color: #3e51c5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row9_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #4055c8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_521b9_row13_col1 {\n",
              "  text-align: center;\n",
              "  background-color: #7ea1fa;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_521b9\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_521b9_level0_col0\" class=\"col_heading level0 col0\" >RandomForest</th>\n",
              "      <th id=\"T_521b9_level0_col1\" class=\"col_heading level0 col1\" >Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row0\" class=\"row_heading level0 row0\" >МФА</th>\n",
              "      <td id=\"T_521b9_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
              "      <td id=\"T_521b9_row0_col1\" class=\"data row0 col1\" >0.220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row1\" class=\"row_heading level0 row1\" >Возраст</th>\n",
              "      <td id=\"T_521b9_row1_col0\" class=\"data row1 col0\" >0.909</td>\n",
              "      <td id=\"T_521b9_row1_col1\" class=\"data row1 col1\" >0.770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row2\" class=\"row_heading level0 row2\" >Гемоглобин, г/л</th>\n",
              "      <td id=\"T_521b9_row2_col0\" class=\"data row2 col0\" >0.786</td>\n",
              "      <td id=\"T_521b9_row2_col1\" class=\"data row2 col1\" >0.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row3\" class=\"row_heading level0 row3\" >СКФ EPI</th>\n",
              "      <td id=\"T_521b9_row3_col0\" class=\"data row3 col0\" >0.415</td>\n",
              "      <td id=\"T_521b9_row3_col1\" class=\"data row3 col1\" >0.490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row4\" class=\"row_heading level0 row4\" >ГБ</th>\n",
              "      <td id=\"T_521b9_row4_col0\" class=\"data row4 col0\" >0.370</td>\n",
              "      <td id=\"T_521b9_row4_col1\" class=\"data row4 col1\" >0.090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row5\" class=\"row_heading level0 row5\" >Хсобщ, ммоль/л</th>\n",
              "      <td id=\"T_521b9_row5_col0\" class=\"data row5 col0\" >0.249</td>\n",
              "      <td id=\"T_521b9_row5_col1\" class=\"data row5 col1\" >0.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row6\" class=\"row_heading level0 row6\" >Cегмент ST</th>\n",
              "      <td id=\"T_521b9_row6_col0\" class=\"data row6 col0\" >0.232</td>\n",
              "      <td id=\"T_521b9_row6_col1\" class=\"data row6 col1\" >0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row7\" class=\"row_heading level0 row7\" >ФВ ЛЖ</th>\n",
              "      <td id=\"T_521b9_row7_col0\" class=\"data row7 col0\" >0.203</td>\n",
              "      <td id=\"T_521b9_row7_col1\" class=\"data row7 col1\" >1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row8\" class=\"row_heading level0 row8\" >СД</th>\n",
              "      <td id=\"T_521b9_row8_col0\" class=\"data row8 col0\" >0.025</td>\n",
              "      <td id=\"T_521b9_row8_col1\" class=\"data row8 col1\" >0.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row9\" class=\"row_heading level0 row9\" >Пол</th>\n",
              "      <td id=\"T_521b9_row9_col0\" class=\"data row9 col0\" >0.014</td>\n",
              "      <td id=\"T_521b9_row9_col1\" class=\"data row9 col1\" >0.110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row10\" class=\"row_heading level0 row10\" >пост-ИМ</th>\n",
              "      <td id=\"T_521b9_row10_col0\" class=\"data row10 col0\" >0.010</td>\n",
              "      <td id=\"T_521b9_row10_col1\" class=\"data row10 col1\" >0.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row11\" class=\"row_heading level0 row11\" >пост-стент</th>\n",
              "      <td id=\"T_521b9_row11_col0\" class=\"data row11 col0\" >0.009</td>\n",
              "      <td id=\"T_521b9_row11_col1\" class=\"data row11 col1\" >0.220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row12\" class=\"row_heading level0 row12\" >пост-ОНМК</th>\n",
              "      <td id=\"T_521b9_row12_col0\" class=\"data row12 col0\" >0.009</td>\n",
              "      <td id=\"T_521b9_row12_col1\" class=\"data row12 col1\" >0.090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_521b9_level0_row13\" class=\"row_heading level0 row13\" >пост-ВЧ-кровоизлияние</th>\n",
              "      <td id=\"T_521b9_row13_col0\" class=\"data row13 col0\" >0.000</td>\n",
              "      <td id=\"T_521b9_row13_col1\" class=\"data row13 col1\" >0.280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "# metric = ['Эксперимент','Статья']\n",
        "\n",
        "result.columns = ['RandomForest', 'Published paper']\n",
        "\n",
        "features=result.index\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=i, x=list(result.index), \n",
        "                             y=result[i]) for i in result.columns ])\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Features')\n",
        "fig.update_yaxes(title='Relative importance', range=[0., 1.0])\n",
        "fig.update_layout(xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False})\n",
        "fig.update_layout(barmode='group', \n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Data', y=0.5), \n",
        "                  title=dict(text=f'Feature importance: comparison with lancet paper', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# figure size\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1300,\n",
        "    height=450,)\n",
        "  \n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "LdxueO7Xh30z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "a6ee81a9-6b40-4ca8-a22c-d64d0cfc0049"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.9.0.min.js\"></script>                <div id=\"bf71415e-b2f2-41a6-a24c-87a5966b85d7\" class=\"plotly-graph-div\" style=\"height:450px; width:1300px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bf71415e-b2f2-41a6-a24c-87a5966b85d7\")) {                    Plotly.newPlot(                        \"bf71415e-b2f2-41a6-a24c-87a5966b85d7\",                        [{\"name\":\"RandomForest\",\"x\":[\"\\u041c\\u0424\\u0410\",\"\\u0412\\u043e\\u0437\\u0440\\u0430\\u0441\\u0442\",\"\\u0413\\u0435\\u043c\\u043e\\u0433\\u043b\\u043e\\u0431\\u0438\\u043d, \\u0433/\\u043b\",\"\\u0421\\u041a\\u0424 EPI\",\"\\u0413\\u0411\",\"\\u0425\\u0441\\u043e\\u0431\\u0449, \\u043c\\u043c\\u043e\\u043b\\u044c/\\u043b\",\"C\\u0435\\u0433\\u043c\\u0435\\u043d\\u0442 ST\",\"\\u0424\\u0412 \\u041b\\u0416\",\"\\u0421\\u0414\",\"\\u041f\\u043e\\u043b\",\"\\u043f\\u043e\\u0441\\u0442-\\u0418\\u041c\",\"\\u043f\\u043e\\u0441\\u0442-\\u0441\\u0442\\u0435\\u043d\\u0442\",\"\\u043f\\u043e\\u0441\\u0442-\\u041e\\u041d\\u041c\\u041a\",\"\\u043f\\u043e\\u0441\\u0442-\\u0412\\u0427-\\u043a\\u0440\\u043e\\u0432\\u043e\\u0438\\u0437\\u043b\\u0438\\u044f\\u043d\\u0438\\u0435\"],\"y\":[1.0,0.9091444490707686,0.7856240568315078,0.4148647477673179,0.3699829674564469,0.2491264669455325,0.2321199085200141,0.20293098985624602,0.025074459029649204,0.013807448517240773,0.010110536726192434,0.009494672836715557,0.008874262996620134,0.0],\"type\":\"bar\"},{\"name\":\"Published paper\",\"x\":[\"\\u041c\\u0424\\u0410\",\"\\u0412\\u043e\\u0437\\u0440\\u0430\\u0441\\u0442\",\"\\u0413\\u0435\\u043c\\u043e\\u0433\\u043b\\u043e\\u0431\\u0438\\u043d, \\u0433/\\u043b\",\"\\u0421\\u041a\\u0424 EPI\",\"\\u0413\\u0411\",\"\\u0425\\u0441\\u043e\\u0431\\u0449, \\u043c\\u043c\\u043e\\u043b\\u044c/\\u043b\",\"C\\u0435\\u0433\\u043c\\u0435\\u043d\\u0442 ST\",\"\\u0424\\u0412 \\u041b\\u0416\",\"\\u0421\\u0414\",\"\\u041f\\u043e\\u043b\",\"\\u043f\\u043e\\u0441\\u0442-\\u0418\\u041c\",\"\\u043f\\u043e\\u0441\\u0442-\\u0441\\u0442\\u0435\\u043d\\u0442\",\"\\u043f\\u043e\\u0441\\u0442-\\u041e\\u041d\\u041c\\u041a\",\"\\u043f\\u043e\\u0441\\u0442-\\u0412\\u0427-\\u043a\\u0440\\u043e\\u0432\\u043e\\u0438\\u0437\\u043b\\u0438\\u044f\\u043d\\u0438\\u0435\"],\"y\":[0.22,0.77,0.7,0.49,0.09,0.1,0.12,1.0,0.24,0.11,0.1,0.22,0.09,0.28],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"Features\"}},\"yaxis\":{\"title\":{\"text\":\"Relative importance\"},\"range\":[0.0,1.0]},\"xaxis2\":{\"overlaying\":\"x\",\"range\":[-0.515,4.515],\"showticklabels\":false},\"legend\":{\"orientation\":\"v\",\"title\":{\"text\":\"Data\"},\"y\":0.5},\"title\":{\"text\":\"Feature importance: comparison with lancet paper\",\"x\":0.5},\"margin\":{\"l\":60,\"r\":20,\"t\":60,\"b\":40},\"barmode\":\"group\",\"bargap\":0.3,\"bargroupgap\":0.3,\"autosize\":false,\"width\":1300,\"height\":450},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bf71415e-b2f2-41a6-a24c-87a5966b85d7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig.write_image(f\"{results_path}importance.pdf\", engine=\"kaleido\")\n",
        "fig.write_image(f\"{results_path}importance.jpeg\", engine=\"kaleido\")"
      ],
      "metadata": {
        "id": "1b7KpNIhhqgf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Top features"
      ],
      "metadata": {
        "id": "KAMMIzVij6Yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Subset"
      ],
      "metadata": {
        "id": "2092R4RxkAgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = './HSE project/f2 optimised models/Lancet features/ABC death top features/'"
      ],
      "metadata": {
        "id": "Z7VVxBjSj_MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "P5saNmmJ1HO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide into taget and features\n",
        "dataset = data_12_columns.copy()\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "target = data_12_columns.target\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ],
      "metadata": {
        "id": "NWQOBxSg03DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rat4FoRJkdvR"
      },
      "source": [
        "##### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True )\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "1zOD0BbkkdvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqFM--obkdvR"
      },
      "source": [
        "##### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQXgyaa9kdvR"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8lC-Qi_zExR"
      },
      "source": [
        "# Canadian paper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset ABC"
      ],
      "metadata": {
        "id": "VWKX2fh28Osa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Subset"
      ],
      "metadata": {
        "id": "I3gPu4fCATm5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hay8hbn4zExR"
      },
      "source": [
        "Features from [paper](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XW-_2xrHBHf0"
      },
      "outputs": [],
      "source": [
        "# choose the same columns as in reference table\n",
        "\n",
        "canadian_features = [\n",
        "    # 1. Target\n",
        "      # - in reference: \"if the patient died or survived before the end of the follow-up period, that was 130 days on average\"\n",
        "      # - in our case: Heart-desease-death, follow-up period - 4-155 months\n",
        "    # ('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Сердечно-сосудистая смерть'),\n",
        "    # 2. Serum creatinine, mg/dL\n",
        "    ('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Креатинин, мкмоль/л'),\n",
        "    # 3. Ejection fraction\n",
        "    ('ИСХОДНАЯ ЭХОКГ', 'ФВ ЛЖ'),\n",
        "    # 4. Age\n",
        "    ('АНТРОПОФИЗИОМЕТРИЯ', 'Возраст'),\n",
        "    # 7. Sex\n",
        "    ('АНТРОПОФИЗИОМЕТРИЯ', 'Пол'),\n",
        "    # 8. Anaemia\n",
        "    ('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Анемия, степень'),\n",
        "    # 9. High blood pressure\n",
        "    ('АНТРОПОФИЗИОМЕТРИЯ', 'систол. АД'),\n",
        "    # 10. Smoking\n",
        "    # ('ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ','Курение')\n",
        "    # 12. Diabetes\n",
        "    ('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'СД'),\n",
        "    # (),\n",
        "    # 5. Creatinine phosphokinase\n",
        "    # data_12_columns['Creatinine phosphokinase'] = \n",
        "    # 6. Serum sodium\n",
        "    # data_12_columns['Serum sodium']\n",
        "    # 8. Platelets\n",
        "    # data_12_columns['Platelets'] = \n",
        "]\n",
        "\n",
        "canadian_2_features = [('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Креатинин, мкмоль/л'), ('ИСХОДНАЯ ЭХОКГ', 'ФВ ЛЖ')]\n",
        "\n",
        "canadian_target = ('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Сердечно-сосудистая смерть')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_abc, header=[0], index_col=0, usecols=list(range(57)))\n",
        "y_train = pd.read_excel(link_train_death_abc, header=[0], index_col=0, usecols=[0, 57])\n",
        "X_test =  pd.read_excel(link_test_death_abc,  header=[0], index_col=0, usecols=list(range(57)))\n",
        "y_test =  pd.read_excel(link_test_death_abc,  header=[0], index_col=0, usecols=[0, 57])\n",
        "X_train.columns = [eval(col) for col in X_train.columns]\n",
        "X_test.columns =  [eval(col) for col in X_test.columns]\n",
        "X_train = X_train[canadian_features]\n",
        "X_test =  X_test[canadian_features]\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = './HSE project/Optimisation data/canadian/ABC dataset/8 features/'\n",
        "results_path =      './HSE project/Graphics/canadian/'\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "id": "-GiGZpoWAdsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445432a3-7abe-4bfa-9cc9-07afeea9f2ba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (438, 7)\n",
            "y_train shape:\t (438, 1)\n",
            "X_test shape:\t (104, 7)\n",
            "y_test shape:\t (104, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMCjdLZW8YFb"
      },
      "source": [
        "##### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "z-TMGGt38YFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLnKvVCF8YFb"
      },
      "source": [
        "##### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU44idEc8YFc"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "metric = ['F2','Precision','Recall','ROC_AUC']\n",
        "\n",
        "\n",
        "table = pd.read_excel(f'{optimisation_path}metrics_table.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "# datasets[list(datasets.columns)] = \n",
        "datasets = pd.DataFrame(table.loc[:, ('Scores on the test set', metric)].values.round(3),columns=['F2','Precision','Recall','ROC AUC'])\n",
        "# if metric == 'F2':\n",
        "#     datasets_mean[datasets_mean.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3)) \n",
        "#     datasets_std[datasets_std.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3)) \n",
        "\n",
        "# list of models\n",
        "# standart models\n",
        "models=['RandomForest', 'SVM', 'Logistic Regression', 'KNN', 'CatBoost']\n",
        "# ensemble models\n",
        "# models=['Hard voting', 'Soft voting', 'Stacking', 'Bagging', 'adaBoosting']\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=column, x=models, y=datasets[column]) for column in datasets.columns ])\n",
        "\n",
        "# add error whiskers from gridsearchCV\n",
        "if metric == 'F2':\n",
        "    fig.add_traces([go.Box(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                          #  xaxis=\"x1\",  \n",
        "                           \n",
        "                           marker=dict(color=\"black\"), \n",
        "                           showlegend = False) for column in datasets.columns])\n",
        "    fig.update_traces(\n",
        "    selector=dict(type=\"box\"), # update only boxes\n",
        "    boxpoints=\"all\", # show points\n",
        "    pointpos=0, # centered\n",
        "    jitter=0, # no jitter\n",
        "    line_color=\"rgba(255,255,255,0)\", # hide box lines\n",
        "    fillcolor=\"rgba(255,255,255,0)\", # hide box fill\n",
        "    \n",
        "    )\n",
        "    fig.update_layout(boxmode=\"group\",)\n",
        "\n",
        "    fig.add_traces([go.Bar(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                           xaxis=\"x2\",  \n",
        "                           error_y=dict(type='data',  \n",
        "                                        array=datasets_std[column], \n",
        "                                        color=\"rgba(0,0,0,1)\",\n",
        "                                        thickness=1), \n",
        "                           marker=dict(opacity=0,\n",
        "                                      #  color=\"rgba(255,255,255,0)\"\n",
        "                                       ), \n",
        "                           showlegend = False) for column in datasets.columns])  \n",
        "    \n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Models')\n",
        "fig.update_yaxes(title='Metric values', range=[0., 1.0])\n",
        "fig.update_layout(xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False})\n",
        "fig.update_layout(barmode='group', \n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Metrics', y=0.5), \n",
        "                  title=dict(text=f'Test metrics: \"canadian\" subset (ABC)', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "if 1:\n",
        "    fig.add_shape(type='line',\n",
        "                  x0=-0.5,\n",
        "                  y0=0.5,\n",
        "                  x1=4.5,\n",
        "                  y1=0.5,\n",
        "                  line=dict(color='black',  width=2, dash='dot'),\n",
        "                  xref='x',\n",
        "                  yref='y',\n",
        "                  layer='below')   \n",
        "    \n",
        "# figure size\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1300,\n",
        "    height=450,)\n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "t488GfgKrEKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "b255490f-a15f-4555-e1f0-7f3e77aefbb0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.9.0.min.js\"></script>                <div id=\"bc7ac919-9931-446a-973f-3d63a56c2e9b\" class=\"plotly-graph-div\" style=\"height:450px; width:1300px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bc7ac919-9931-446a-973f-3d63a56c2e9b\")) {                    Plotly.newPlot(                        \"bc7ac919-9931-446a-973f-3d63a56c2e9b\",                        [{\"name\":\"F2\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.58,0.56,0.781,0.409,0.392],\"type\":\"bar\"},{\"name\":\"Precision\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.542,0.464,0.5,0.409,0.571],\"type\":\"bar\"},{\"name\":\"Recall\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.591,0.591,0.909,0.409,0.364],\"type\":\"bar\"},{\"name\":\"ROC AUC\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.766,0.77,0.798,0.598,0.707],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"title\":{\"text\":\"Metric values\"},\"range\":[0.0,1.0]},\"xaxis2\":{\"overlaying\":\"x\",\"range\":[-0.515,4.515],\"showticklabels\":false},\"legend\":{\"orientation\":\"v\",\"title\":{\"text\":\"Metrics\"},\"y\":0.5},\"title\":{\"text\":\"Test metrics: \\\"canadian\\\" subset (ABC)\",\"x\":0.5},\"margin\":{\"l\":60,\"r\":20,\"t\":60,\"b\":40},\"barmode\":\"group\",\"bargap\":0.3,\"bargroupgap\":0.3,\"shapes\":[{\"layer\":\"below\",\"line\":{\"color\":\"black\",\"dash\":\"dot\",\"width\":2},\"type\":\"line\",\"x0\":-0.5,\"x1\":4.5,\"xref\":\"x\",\"y0\":0.5,\"y1\":0.5,\"yref\":\"y\"}],\"autosize\":false,\"width\":1300,\"height\":450},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bc7ac919-9931-446a-973f-3d63a56c2e9b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig.write_image(f\"{results_path}metrics.pdf\", engine=\"kaleido\")\n",
        "fig.write_image(f\"{results_path}metrics.jpeg\", engine=\"kaleido\")"
      ],
      "metadata": {
        "id": "sVaQfkN9kSiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature selection"
      ],
      "metadata": {
        "id": "EkTDZHjB1gjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhERMqPx8YFc"
      },
      "outputs": [],
      "source": [
        "# Эксперимент feature importances\n",
        "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
        "feature_importances = pd.DataFrame()\n",
        "\n",
        "randomforest_optimisation = pd.read_excel(f'{optimisation_path}randomforest_optimisation.xlsx', header=[0])\n",
        "\n",
        "params = randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "params = ast.literal_eval(params[0])\n",
        "random_forest_model = RandomForestClassifier(**params)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "feature_importances[\"Эксперимент\"] = pd.Series(random_forest_model.feature_importances_)\n",
        "# Перепечатал из статьи\n",
        "feature_importances['Эксперимент'] = feature_importances['Эксперимент']/feature_importances['Эксперимент'][0]\n",
        "# feature_importances[\"Logistic regression\"] = pd.Series(LR_model.coef_[0]).abs()\n",
        "# feature_importances[\"SVM\"] = pd.Series(SVM_model.coef_[0]).abs()\n",
        "\n",
        "\n",
        "feats = list(map(lambda x: x[1], list(X_train.columns)))\n",
        "feature_importances.index = feats\n",
        "\n",
        "feature_importances = feature_importances.sort_values(\"Эксперимент\", ascending=False)\n",
        "feature_importances['Эксперимент'] = feature_importances['Эксперимент']/feature_importances['Эксперимент'][0]\n",
        "\n",
        "feature_importances.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[\"Эксперимент\"], axis=0)\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_from_paper = pd.DataFrame()\n",
        "data_from_paper['Статья'] = [11.84,  10.71, 8.58,  1.06, 1.13, 1.02, 1.12] # \n",
        "data_from_paper['Статья'] = data_from_paper['Статья']/data_from_paper['Статья'][0]\n",
        "data_from_paper.index = ['Креатинин, мкмоль/л', 'ФВ ЛЖ', 'Возраст', 'Анемия, степень',   'систол. АД', 'СД', 'Пол']"
      ],
      "metadata": {
        "id": "UKyKRXZA6PZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = pd.concat([feature_importances, data_from_paper], axis=1) \n",
        "feature_importances.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[\"Эксперимент\", \"Статья\"], axis=0)\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "Jj4V188869zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "metric = ['Эксперимент','Статья']\n",
        "feature_importances.columns = ['RandomForest', 'Published paper']\n",
        "\n",
        "feats = [str(feature[1]) for feature in feature_importances.index]\n",
        "features=feature_importances.index\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=i, x=list(feature_importances.index), \n",
        "                             y=feature_importances[i]) for i in feature_importances.columns ])\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Features')\n",
        "fig.update_yaxes(title='Relative importance', range=[0., 1.0])\n",
        "fig.update_layout(xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False})\n",
        "fig.update_layout(barmode='group', \n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Data', y=0.5), \n",
        "                  title=dict(text=f'Feature importance: comparison with canadian paper', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)  \n",
        "\n",
        "# figure size\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1300,\n",
        "    height=450,)\n",
        "  \n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "bnCJcY8Ztw-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig.write_image(f\"{results_path}importance.pdf\", engine=\"kaleido\")\n",
        "fig.write_image(f\"{results_path}importance.jpeg\", engine=\"kaleido\")"
      ],
      "metadata": {
        "id": "3YfTFdVXkPuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpHRlEF-8YFc"
      },
      "source": [
        "##### Two features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRU5ofWf8YFc"
      },
      "source": [
        "##### Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY2T-iM28YFc"
      },
      "outputs": [],
      "source": [
        "# choose the same columns as in reference table\n",
        "data_2_columns = pd.DataFrame(data_abc[clinical_abc_columns][canadian_2_features])\n",
        "data_2_columns['target', 'target'] = data_abc[canadian_target] \n",
        "\n",
        "data_2_columns.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkO86_V_8YFc"
      },
      "outputs": [],
      "source": [
        "# data has NAs\n",
        "((data_12_columns == -1).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BRj_vzk8YFc"
      },
      "outputs": [],
      "source": [
        "# Drop these columns from the dataframe\n",
        "data_2_columns = data_2_columns.replace(-1,np.nan)\n",
        "data_2_columns.dropna(axis=0, how='any', inplace=True)\n",
        "data_2_columns.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_2_columns.columns"
      ],
      "metadata": {
        "id": "2W3MDR7ezo9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVtx1dyk8YFc"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "fig.add_trace(go.Scatter(x=data_abc['ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Креатинин, мкмоль/л'], \n",
        "                         y=data_abc[('ИСХОДНАЯ ЭХОКГ', 'ФВ ЛЖ')],\n",
        "                         marker_color=data_abc[('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Сердечно-сосудистая смерть')],\n",
        "                         mode='markers',\n",
        "                         text= data_abc[('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Сердечно-сосудистая смерть')]\n",
        "                    # mode='markers',\n",
        "                    # name='markers')\n",
        "))\n",
        "\n",
        "fig.update_traces(marker_size=10, selector=dict(type='scatter'))\n",
        "\n",
        "fig.update_layout(\n",
        "                  height=800, \n",
        "                  font_family=\"'Nunito', sans-serif\",\n",
        "                  # title={'text': \"Correlations between sales and other columns\", 'y':0.97, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},\n",
        "                  showlegend=True, \n",
        "                  margin=dict(l=40, r=10, t=60, b=60),\n",
        "                  xaxis_range=[-5,10]\n",
        "\n",
        "                  )\n",
        "\n",
        "# fig = px.scatter(data_abc, x=['ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Креатинин, мкмоль/л'], y=['ИСХОДНАЯ ЭХОКГ', 'ФВ ЛЖ'], color=['target', ''],\n",
        "#                 title=\"Automatic Labels Based on data_abc Frame Column Names\")\n",
        "fig.layout.template = 'plotly_dark'\n",
        "fig.show(renderer='colab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHUiOAGo8YFc"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = data_2_columns[data_2_columns.columns.drop('target')]\n",
        "target = data_2_columns.target\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_canadian_2_features_ABC = './HSE project/f2 optimised models/Canadian features/ABC dataset/2 features/'"
      ],
      "metadata": {
        "id": "URXOACyj8YFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDtqOZtD8YFc"
      },
      "source": [
        "##### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=path_canadian_2_features_ABC, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "UZYoGwI_8YFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI5ZcidR8YFd"
      },
      "source": [
        "##### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFC6KTCh8YFd"
      },
      "outputs": [],
      "source": [
        "metrics_table = metric_table(path=path_canadian_2_features_ABC)\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature selection"
      ],
      "metadata": {
        "id": "tSPSiu9n1-xz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOQnn0Ay2IPJ"
      },
      "outputs": [],
      "source": [
        "# Random Forest feature importances\n",
        "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
        "feature_importances = pd.DataFrame()\n",
        "\n",
        "randomforest_optimisation = pd.read_excel(f'{path_canadian_2_features_ABC}randomforest_optimisation.xlsx', header=[0])\n",
        "svm_optimisation = pd.read_excel(f'{path_canadian_2_features_ABC}svm_optimisation.xlsx', header=[0])\n",
        "LogisticRegression_optimisation = pd.read_excel(f'{path_canadian_2_features_ABC}LogisticRegression_optimisation.xlsx', header=[0])\n",
        "\n",
        "# feature_importances.columns = ['Feature']\n",
        "params = randomforest_optimisation[randomforest_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "params = ast.literal_eval(params[0])\n",
        "random_forest_model = RandomForestClassifier(**params)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "# \n",
        "# params = svm_optimisation[svm_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "# params = ast.literal_eval(params[0])\n",
        "# SVM_model = SVC(**params)\n",
        "# \n",
        "params = LogisticRegression_optimisation[LogisticRegression_optimisation['rank_test_score']==1][[\"params\"]].iloc[0]\n",
        "params = ast.literal_eval(params[0])\n",
        "LR_model = LogisticRegression(**params)\n",
        "LR_model.fit(X_train, y_train)\n",
        "\n",
        "feature_importances[\"Random Forest\"] = pd.Series(random_forest_model.feature_importances_)\n",
        "feature_importances[\"Logistic regression\"] = pd.Series(LR_model.coef_[0]).abs()\n",
        "# feature_importances[\"SVM\"] = pd.Series(SVM_model.coef_[0]).abs()\n",
        "\n",
        "\n",
        "feature_importances.index = list(X_train.columns)\n",
        "\n",
        "feature_importances = feature_importances.sort_values(\"Random Forest\", ascending=False)\n",
        "\n",
        "feature_importances.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[\"Random Forest\", \"Logistic regression\"])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = path_canadian_2_features_ABC)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "HWhYpQO32IPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vczt-rbTs__F"
      },
      "source": [
        "# **Target**: Death from heart desease"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = ('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Сердечно-сосудистая смерть')\n",
        "results_path = './HSE project/Graphics/cardiovascular death/'"
      ],
      "metadata": {
        "id": "Yj8rNPZR9SlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjRW-0s0jUiT"
      },
      "source": [
        "## Biomarkers A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN2GDi5ijUiU"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_a, header=[0], usecols=list(range(61,147)))\n",
        "y_train = pd.read_excel(link_train_death_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_death_a, header=[0], usecols=list(range(61,147)))\n",
        "y_test  = pd.read_excel(link_test_death_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Biomarkers A/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "id": "0hK_hlveLvXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJuEAXu1jUiU"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "DuAtSC0KEsVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf_4mjDOjUiX"
      },
      "source": [
        "### Metrics table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGGFjfb7jUiX"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "VPpsIY3FBP0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "JiwqUfdcBsGf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITqnhHHvQ62b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top feature optimisation and metrics"
      ],
      "metadata": {
        "id": "pbtSf8XdrNWq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_RNTmwWvoUd"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(col for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "Z3GRWS60gkNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZJOBxllBLkIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUSSSKoXvoUd"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = biomarkers_a.copy()\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "target = biomarkers_a.target\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipadgxNcZQlM"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/f2 optimised models/Biomarkers A/biomarkers top features/\""
      ],
      "metadata": {
        "id": "xxpO3gSVetIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJhA8Pw-WkW_"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "3oouMqlyJUKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u3EUjF1voUg"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1Pefs2zvoUg"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers A"
      ],
      "metadata": {
        "id": "LL__Xts2EqsP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkwBdD2REqsP"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_a, header=[0], usecols=list(range(1,147)))\n",
        "y_train = pd.read_excel(link_train_death_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_death_a, header=[0], usecols=list(range(1,147)))\n",
        "y_test  = pd.read_excel(link_test_death_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Biomarkers A + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "id": "xWekgmz0RVtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LibI_gdDEqsQ"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "yeGbB8PwEqsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofZ-pss6EqsQ"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWcwaaHrEqsR"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "2oR5nHwhBzZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "KLpP7Jl1EqsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "zNQDdWfoEqsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "xTRnsaarEqsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU4wlfa8EqsS"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfz764jgEqsS"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "vs-Vp_1SEqsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bn4iov8FEqsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHuy_SbEEqsT"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_a.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht2rrhNmEqsT"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/f2 optimised models/Biomarkers A + Clinical/top features/\""
      ],
      "metadata": {
        "id": "cyUCrrI1EqsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4E1U_dNEqsT"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "5dX1-K8xEqsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMAuj1gSEqsT"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tlvq-iuyEqsU"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features A"
      ],
      "metadata": {
        "id": "7jb9BOhnJU7n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JQSp2QPJe2e"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_a, header=[0], usecols=list(range(1,61)))\n",
        "y_train = pd.read_excel(link_train_death_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_death_a, header=[0], usecols=list(range(1,61)))\n",
        "y_test  = pd.read_excel(link_test_death_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Clinical A/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFcmFYMxTfLW",
        "outputId": "4d45aa7a-eb20-451c-8066-fde151c7eae2"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (150, 60)\n",
            "y_train shape:\t (150, 1)\n",
            "X_test shape:\t (49, 60)\n",
            "y_test shape:\t (49, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-KOlLjxPxnD"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "ldchmQ4lJ6Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITpM_qwYPxnG"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujGBpPDKPxnG"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "dxtuTFLYCBR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "a9HYD5VfPxnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time \n",
        "# df = feature_selection( \n",
        "#                         x_data = X_train,\n",
        "#                         y_data = y_train,\n",
        "#                         path = optimisation_path)\n",
        "# df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "7CfNvK3zgHZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "vc2ODcIji1Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUUYSucVPxnH"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9F9FxZgPxnH"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "wWLn9iUaPxnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "75Jc_BLkDbJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaUMHSZZPxnH"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_a.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK9bR1VhPxnH"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/f2 optimised models/Clinical A/top features/\""
      ],
      "metadata": {
        "id": "LqM9bO6Bi0D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdSsWDM0PxnH"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "86toJvSnKBI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW3hO_ttPxnJ"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HuoN0XlPxnJ"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarkers B"
      ],
      "metadata": {
        "id": "ZG1Y1R1-RlyD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSf0WeAl9IdR"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_b, header=[0], usecols=list(range(72,78)))\n",
        "y_train = pd.read_excel(link_train_death_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_death_b, header=[0], usecols=list(range(72,78)))\n",
        "y_test  = pd.read_excel(link_test_death_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Biomarkers B/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GUqlDpAUR3N",
        "outputId": "b83f5f4f-3805-46a8-eb76-6bc5520dbb53"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (94, 6)\n",
            "y_train shape:\t (94, 1)\n",
            "X_test shape:\t (30, 6)\n",
            "y_test shape:\t (30, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGAdF83zDhu1"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=4, \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "yrmX7S0wKOxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU7Qvjs8Dhu3"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5jIYFz-Dhu3"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "HXFijD6jCN8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "fd5kpAF1Dhu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "56ksNI1K7dO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# top_features = list(eval(col) for col in dataset.index[:10])\n",
        "# top_features"
      ],
      "metadata": {
        "id": "mdWhHq75ZBvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pzHf3dyZZGIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYX19sEMZyys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers B"
      ],
      "metadata": {
        "id": "Nbhf5zN7M6Hi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3helMZulO2S"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_b, header=[0], usecols=list(range(1,78)))\n",
        "y_train = pd.read_excel(link_train_death_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_death_b, header=[0], usecols=list(range(1,78)))\n",
        "y_test  = pd.read_excel(link_test_death_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Biomarkers B + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsKJLpkmVfnC",
        "outputId": "154bbc84-c306-4d06-c977-4727dd96e921"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (94, 77)\n",
            "y_train shape:\t (94, 1)\n",
            "X_test shape:\t (30, 77)\n",
            "y_test shape:\t (30, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIbsWOTvlO2T"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "Uca8J3R3KVVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3dfnG_1lO2V"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTG9vdhmlO2V"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "RGZhKcQUCakn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "rcYYMLDClO2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = clinical_and_biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "lrWWaOtJ1Pyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttSEvP4vlO2W"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUAU5fgvlO2W"
      },
      "source": [
        "#### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=0, index_col=[0])\n",
        "# top_features = [eval(col) for col in dataset[dataset['sum']>=4].index]\n",
        "# top_features "
      ],
      "metadata": {
        "id": "sUBkioAS_8Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "JsL7hUrCQT_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4zekOVi2QT_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LKETuR6lO2W"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_b.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.75,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsWmB5FPlO2W"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/f2 optimised models/Biomarkers B + Clinical/top features/\""
      ],
      "metadata": {
        "id": "yBA97BwYlO2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPGW_GKOlO2W"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "m3DmU4uUKaJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0fsvKlxlO2Y"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgliN5ixlO2Y"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features B"
      ],
      "metadata": {
        "id": "XUt4raJxFMqy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUSLIV3vFMqz"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_b, header=[0], usecols=list(range(1,72)))\n",
        "y_train = pd.read_excel(link_train_death_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_death_b, header=[0], usecols=list(range(1,72)))\n",
        "y_test  = pd.read_excel(link_test_death_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Clinical B/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4GkIBnBWcJ3",
        "outputId": "e5dfee34-3481-4dc9-9245-faa2f6cdda41"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (94, 71)\n",
            "y_train shape:\t (94, 1)\n",
            "X_test shape:\t (30, 71)\n",
            "y_test shape:\t (30, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv1ozWiZFMq0"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "huL5GtQ_FMq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ag6JbHdFMq1"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "298NelP4FMq1"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "iKJzLuCjCmWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "zwsrUvWnFMq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = clinical_and_biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "iZDpTZmYFMq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RVuCse8FMq3"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYlO4aWSFMq3"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=0, index_col=[0])\n",
        "# top_features = [eval(col) for col in dataset[dataset['sum']>=4].index]\n",
        "# top_features "
      ],
      "metadata": {
        "id": "HcKq1RmbFMq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "pPw313YAFMq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bYUcmDSoFMq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRXn44RmFMq3"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_b.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.75,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIqWzD4lFMq3"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/f2 optimised models/Biomarkers B + Clinical/top features/\""
      ],
      "metadata": {
        "id": "rkijcT3TFMq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr9b7RRzFMq4"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "Q1QMDysJFMq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbJeKYrBFMq4"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij9cU04VFMq4"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarkers C"
      ],
      "metadata": {
        "id": "hC7-grrBWkeX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwaq-NYJJWYs"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_c, header=[0], usecols=list(range(101,106)))\n",
        "y_train = pd.read_excel(link_train_death_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_death_c, header=[0], usecols=list(range(101,106)))\n",
        "y_test  = pd.read_excel(link_test_death_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Biomarkers C/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx1b65wKXMtm",
        "outputId": "1bb2c752-e4eb-40c5-e9e7-82d8f37a4a06"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (160, 5)\n",
            "y_train shape:\t (160, 1)\n",
            "X_test shape:\t (43, 5)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5F-TuVtJWYt"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=4, \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "yC1Mig9cJWYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0tG_YdwJWYt"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRr9H2WLJWYt"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "-upnv9wiC_q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "wUcQ9tz0JWYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "dDDiyGk4JWYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers C"
      ],
      "metadata": {
        "id": "zFakeaPyWbB0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLOFRa3PMOo7"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_c, header=[0], usecols=list(range(1,106)))\n",
        "y_train = pd.read_excel(link_train_death_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_death_c, header=[0], usecols=list(range(1,106)))\n",
        "y_test  = pd.read_excel(link_test_death_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Biomarkers C + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UncPzdanZOyj",
        "outputId": "8cb69deb-6925-4d8d-fe39-7afd285b6940"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (160, 105)\n",
            "y_train shape:\t (160, 1)\n",
            "X_test shape:\t (43, 105)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKE3ShplMOo-"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "Kq3hueBgMOo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKmGxR-gMOo-"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX4KRMuKMOo-"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "Zh2tppGKDGSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "mEYEyGIHMOo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = clinical_and_biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "5f5eb3nlMOo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features C"
      ],
      "metadata": {
        "id": "YhA65WfZAHUG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0eOnMBYAHUI"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_c, header=[0], usecols=list(range(1,101)))\n",
        "y_train = pd.read_excel(link_train_death_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_death_c, header=[0], usecols=list(range(1,101)))\n",
        "y_test  = pd.read_excel(link_test_death_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Clinical C/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "id": "mhygfAZxZykH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsPWmv8TAHUP"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "hxjKLDSNAHUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc9wOKPOAHUQ"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC5ut14aAHUQ"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "JDBso4V9DVhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "KfjGS5YUAHUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time \n",
        "# df = feature_selection(\n",
        "#                               # dataset = clinical_and_biomarkers_b,\n",
        "#                               x_data = X_train,\n",
        "#                               y_data = y_train,\n",
        "#                               path = optimisation_path)\n",
        "# df.tail(40)"
      ],
      "metadata": {
        "id": "Lve_S2EyAHUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features A-B-C"
      ],
      "metadata": {
        "id": "hzQMVlZ9m_PK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dVxxT6fm_PL"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_death_c, header=[0], usecols=list(range(1,57)))\n",
        "y_train = pd.read_excel(link_train_death_c, header=[0], usecols=[57])\n",
        "X_test  = pd.read_excel(link_test_death_c, header=[0], usecols=list(range(1,57)))\n",
        "y_test  = pd.read_excel(link_test_death_c, header=[0], usecols=[57])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/cardiovascular death/Clinical ABC/all clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "id": "ipPg0T4oaZCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZueutDS-m_PL"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "VofEC3aBKpyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPsG4R8em_PO"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsxwTM-vm_PO"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "fYS30ndgDZrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "NnHg8Zqrm_PO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = clinical_and_biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "SONcwJmrfZYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SREweqgjm_PP"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXtPx8yzm_PP"
      },
      "source": [
        "#### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "y2oqU4Izfnju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AgZa97L7f4F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[str(eval(feature)[1]) for feature in dataset.index[:10]]"
      ],
      "metadata": {
        "id": "rpUxF7e53zgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Importances', 'RandomForest']"
      ],
      "metadata": {
        "id": "0PMkWE0h4C70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "metric = ['Эксперимент','Статья']\n",
        "\n",
        "dataset['Importances', 'RandomForest'] = dataset['Importances', 'RandomForest']/dataset['Importances', 'RandomForest'].max()\n",
        "feats = [str(eval(feature)[1]) for feature in dataset.index[:15]]\n",
        "features=dataset.index\n",
        "# ensemble models\n",
        "# models=['Hard voting', 'Soft voting', 'Stacking', 'Bagging', 'adaBoosting']\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=i, x=feats, \n",
        "                             y=dataset['Importances', 'RandomForest'])])\n",
        "\n",
        "# add error whiskers from gridsearchCV\n",
        "# i\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Модели')\n",
        "fig.update_yaxes(title='', range=[0., 1.0])\n",
        "fig.update_layout(xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False})\n",
        "fig.update_layout(barmode='group', \n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"h\", title='Данные'), \n",
        "                  title=dict(text=f'Значения метрик для выбранных моделей', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "# if 1:\n",
        "#     fig.add_shape(type='line',\n",
        "#                     x0=-0.5,\n",
        "#                     y0=0.5,\n",
        "#                     x1=4.5,\n",
        "#                     y1=0.5,\n",
        "#                     line=dict(color='firebrick',  width=2, dash='dot'),\n",
        "#                     xref='x',\n",
        "#                     yref='y')   \n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "Q1tNdX3f3VWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LmNinYCm_PP"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_abc.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfHyZqTOm_PP"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/f2 optimised models/Clinical ABC/top features/\""
      ],
      "metadata": {
        "id": "u392nvpyf7o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcQPEXm7m_PP"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "KTrWYAH7K_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4S0QtBUm_PR"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JngrQIc7m_PR"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "aJjYfOfqfoy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scores of models"
      ],
      "metadata": {
        "id": "j8VQDVdLgWl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "metric = 'ROC_AUC'\n",
        "\n",
        "# list of paths\n",
        "paths = [ \n",
        "        './HSE project/Optimisation data/cardiovascular death/Biomarkers A/all biomarkers/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Biomarkers B/all biomarkers/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Clinical ABC/all clinical/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Biomarkers C + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Clinical A/all biomarkers and clinical/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Clinical B/all biomarkers and clinical/',\n",
        "        './HSE project/Optimisation data/cardiovascular death/Clinical C/all biomarkers and clinical/',\n",
        "        ]\n",
        "\n",
        "# create datframe for scores\n",
        "datasets = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "datasets_mean = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "datasets_std = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}metrics_table.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    datasets[datasets.columns[i]] = list(table.loc[:, ('Scores on the test set', metric)].values.round(3)) \n",
        "    if metric == 'F2':\n",
        "        datasets_mean[datasets_mean.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3)) \n",
        "        datasets_std[datasets_std.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3)) \n",
        "\n",
        "# list of models\n",
        "# standart models\n",
        "models=['RandomForest', 'SVM', 'Logistic Regression', 'KNN', 'CatBoost']\n",
        "# ensemble models\n",
        "# models=['Hard voting', 'Soft voting', 'Stacking', 'Bagging', 'adaBoosting']\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=column, x=models, y=datasets[column]) for column in datasets.columns ])\n",
        "\n",
        "# add error whiskers from gridsearchCV\n",
        "if metric == 'F2':\n",
        "    fig.add_traces([go.Box(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                          #  xaxis=\"x1\",  \n",
        "                           \n",
        "                           marker=dict(color=\"black\"), \n",
        "                           showlegend = False) for column in datasets.columns])\n",
        "    fig.update_traces(\n",
        "    selector=dict(type=\"box\"), # update only boxes\n",
        "    boxpoints=\"all\", # show points\n",
        "    pointpos=0, # centered\n",
        "    jitter=0, # no jitter\n",
        "    line_color=\"rgba(255,255,255,0)\", # hide box lines\n",
        "    fillcolor=\"rgba(255,255,255,0)\", # hide box fill\n",
        "    \n",
        "    )\n",
        "    fig.update_layout(boxmode=\"group\",)\n",
        "\n",
        "    fig.add_traces([go.Bar(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                           xaxis=\"x2\",  \n",
        "                           error_y=dict(type='data',  \n",
        "                                        array=datasets_std[column], \n",
        "                                        color=\"rgba(0,0,0,1)\",\n",
        "                                        thickness=1), \n",
        "                           marker=dict(opacity=0,\n",
        "                                      #  color=\"rgba(255,255,255,0)\"\n",
        "                                       ), \n",
        "                           showlegend = False) for column in datasets.columns])  \n",
        "    \n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Models')\n",
        "fig.update_yaxes(title='Score', range=[0., 1.0])\n",
        "fig.update_layout(xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False})\n",
        "fig.update_layout(barmode='group', \n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Datasets'), \n",
        "                  title=dict(text=f'{metric} values', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "if metric == 'ROC_AUC':\n",
        "    fig.add_shape(type='line',\n",
        "                    x0=-0.5,\n",
        "                    y0=0.5,\n",
        "                    x1=4.5,\n",
        "                    y1=0.5,\n",
        "                    line=dict(color='firebrick',  width=2, dash='dot'),\n",
        "                    xref='x',\n",
        "                    yref='y')   \n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "YDc2nfiJfrXA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "9d381de0-67cd-4711-ad2b-d4346736c8bc"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.9.0.min.js\"></script>                <div id=\"ad45b962-5447-411e-a681-2f954796d1d7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ad45b962-5447-411e-a681-2f954796d1d7\")) {                    Plotly.newPlot(                        \"ad45b962-5447-411e-a681-2f954796d1d7\",                        [{\"name\":\"biomarkers A\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.611,0.363,0.635,0.628,0.653],\"type\":\"bar\"},{\"name\":\"biomarkers B\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.847,0.431,0.667,0.493,0.333],\"type\":\"bar\"},{\"name\":\"biomarkers C\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[1.0,0.25,0.906,0.453,0.938],\"type\":\"bar\"},{\"name\":\"Clinical+biomarkers ABC\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.909,0.911,0.906,0.789,0.89],\"type\":\"bar\"},{\"name\":\"Clinical+biomarkers A\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.741,0.701,0.637,0.6,0.661],\"type\":\"bar\"},{\"name\":\"Clinical+biomarkers B\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.722,0.847,0.764,0.694,0.611],\"type\":\"bar\"},{\"name\":\"Clinical+biomarkers C\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.812,0.062,0.531,0.469,0.844],\"type\":\"bar\"},{\"name\":\"Clinical A\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.693,0.8,0.76,0.72,0.728],\"type\":\"bar\"},{\"name\":\"Clinical B\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.847,0.597,0.736,0.514,0.764],\"type\":\"bar\"},{\"name\":\"Clinical C\",\"x\":[\"RandomForest\",\"SVM\",\"Logistic Regression\",\"KNN\",\"CatBoost\"],\"y\":[0.875,0.906,0.812,0.484,0.781],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"title\":{\"text\":\"Score\"},\"range\":[0.0,1.0]},\"xaxis2\":{\"overlaying\":\"x\",\"range\":[-0.515,4.515],\"showticklabels\":false},\"legend\":{\"orientation\":\"v\",\"title\":{\"text\":\"Datasets\"}},\"title\":{\"text\":\"ROC_AUC values\",\"x\":0.5},\"margin\":{\"l\":60,\"r\":20,\"t\":60,\"b\":40},\"barmode\":\"group\",\"bargap\":0.3,\"bargroupgap\":0.3,\"shapes\":[{\"line\":{\"color\":\"firebrick\",\"dash\":\"dot\",\"width\":2},\"type\":\"line\",\"x0\":-0.5,\"x1\":4.5,\"xref\":\"x\",\"y0\":0.5,\"y1\":0.5,\"yref\":\"y\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ad45b962-5447-411e-a681-2f954796d1d7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare with Top 10"
      ],
      "metadata": {
        "id": "M7HeLvnhhegB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "# ROC_AUC F1 F2\n",
        "metric = 'F2'\n",
        "\n",
        "# list of paths\n",
        "paths = [\n",
        "        './HSE project/f2 optimised models/Biomarkers A/all biomarkers/',\n",
        "        './HSE project/f2 optimised models/Biomarkers B/all biomarkers/',\n",
        "        './HSE project/f2 optimised models/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/f2 optimised models/Clinical ABC/all clinical/',\n",
        "        './HSE project/f2 optimised models/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/f2 optimised models/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/f2 optimised models/Biomarkers C + Clinical/all biomarkers and clinical/'\n",
        "        ]\n",
        "\n",
        "# list of paths of top 10\n",
        "paths_top = [\n",
        "        './HSE project/f2 optimised models/Biomarkers A/biomarkers top features/',\n",
        "        './HSE project/f2 optimised models/Biomarkers B/biomarkers top features/',\n",
        "        './HSE project/f2 optimised models/Biomarkers C/biomarkers top features/',\n",
        "        './HSE project/f2 optimised models/Clinical ABC/top features/',\n",
        "        './HSE project/f2 optimised models/Biomarkers A + Clinical/top features/',\n",
        "        './HSE project/f2 optimised models/Biomarkers B + Clinical/top features/',\n",
        "        './HSE project/f2 optimised models/Biomarkers C + Clinical/top features/'\n",
        "        ]\n",
        "\n",
        "# create datframe for scores\n",
        "datasets = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "datasets_mean = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "datasets_std = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}metrics_table.xlsx', header=[0,1], index_col=[0]) \n",
        "    table_top = pd.read_excel(f'{paths_top[i]}metrics_table.xlsx', header=[0,1], index_col=[0])\n",
        "    datasets[datasets.columns[i]] = list(table.loc[:, ('Scores on the test set', metric)].values.round(3)) + \\\n",
        "                                    list(table_top.loc[:, ('Scores on the test set', metric)].values.round(3))\n",
        "    if metric == 'F2':\n",
        "        datasets_mean[datasets_mean.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3)) + list(table_top.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3))\n",
        "        datasets_std[datasets_std.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3)) + list(table_top.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3))\n",
        "\n",
        "# list of models\n",
        "# standart models\n",
        "models=['RandomForest', 'SVM', 'Logistic Regression', 'KNN', 'CatBoost'] + ['RandomForest top 10', 'SVM top 10', 'Logistic Regression top 10', 'KNN top 10', 'CatBoost top 10']\n",
        "\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=column, x=models, y=datasets[column]) for column in datasets.columns ])\n",
        "\n",
        "# add error whiskers from gridsearchCV\n",
        "if metric == 'F2':\n",
        "    fig.add_traces([go.Box(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                          #  xaxis=\"x1\",  \n",
        "                           \n",
        "                           marker=dict(color=\"black\"), \n",
        "                           showlegend = False) for column in datasets.columns])\n",
        "    fig.update_traces(\n",
        "    selector=dict(type=\"box\"), # update only boxes\n",
        "    boxpoints=\"all\", # show points\n",
        "    pointpos=0, # centered\n",
        "    jitter=0, # no jitter\n",
        "    line_color=\"rgba(255,255,255,0)\", # hide box lines\n",
        "    fillcolor=\"rgba(255,255,255,0)\", # hide box fill\n",
        "    \n",
        "    )\n",
        "    fig.update_layout(boxmode=\"group\",)\n",
        "\n",
        "    fig.add_traces([go.Bar(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                           xaxis=\"x2\",  \n",
        "                           error_y=dict(type='data',  \n",
        "                                        array=datasets_std[column], \n",
        "                                        color=\"rgba(0,0,0,1)\",\n",
        "                                        thickness=1), \n",
        "                           marker=dict(opacity=0,\n",
        "                                      #  color=\"rgba(255,255,255,0)\"\n",
        "                                       ), \n",
        "                           showlegend = False) for column in datasets.columns])  \n",
        "    \n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Models')\n",
        "fig.update_yaxes(title='Score', range=[0., 1.0])\n",
        "fig.update_layout(barmode='group', \n",
        "                  xaxis2={\"overlaying\": \"x\", \"range\": [-0.525, 9.525], \"showticklabels\": False},\n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Datasets'), \n",
        "                  title=dict(text=f'{metric} score', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "if metric == 'ROC_AUC':\n",
        "    fig.add_shape(type='line',\n",
        "                    x0=-0.5,\n",
        "                    y0=0.5,\n",
        "                    x1=9.5,\n",
        "                    y1=0.5,\n",
        "                    line=dict(color='firebrick',  width=2, dash='dot'),\n",
        "                    xref='x',\n",
        "                    yref='y')   \n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "yAbqFDunhkb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "-iGBTQ6Oz2nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = pd.DataFrame(columns=['features', \n",
        "                                #  'biomarkers A',\n",
        "                                #  'biomarkers B',\n",
        "                                #  'biomarkers C',\n",
        "                                 'Clinical+biomarkers ABC',\n",
        "                                 'Clinical+biomarkers A',\n",
        "                                 'Clinical+biomarkers B',\n",
        "                                #  'Clinical+biomarkers C',\n",
        "                                 ])\n",
        "# list of paths\n",
        "paths = [\n",
        "        # './HSE project/f2 optimised models/Biomarkers A/all biomarkers/',\n",
        "        # './HSE project/f2 optimised models/Biomarkers B/all biomarkers/',\n",
        "        # './HSE project/f2 optimised models/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/f2 optimised models/Clinical ABC/all clinical/',\n",
        "        './HSE project/f2 optimised models/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/f2 optimised models/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        # './HSE project/f2 optimised models/Biomarkers C + Clinical/all biomarkers and clinical/'\n",
        "        ]\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "top_features = []\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}feature_selection_dataset.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    table.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "    # if i < 3: \n",
        "    #     top_features = top_features+list(str(col) for col in table.index[:10])\n",
        "    # else:    \n",
        "    top_features = top_features+list(eval(col)[1] for col in table.index[:10])\n",
        "\n",
        "features['features'] = list(set(top_features))\n",
        "features.index = list(set(top_features))\n",
        "features.fillna(0, inplace=True)\n",
        "\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}feature_selection_dataset.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    table.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "    # if i < 3: \n",
        "    #     features.loc[list(str(col) for col in table.index[:10]), features.columns[i+1]] = 1\n",
        "    # else:    \n",
        "        # top_features = top_features+list(eval(col) for col in table.index[:10])   \n",
        "    features.loc[list(eval(col)[1] for col in table.index[:10]), features.columns[i+1]] = 1 \n",
        "\n",
        "features['features'] = features.iloc[:,1:].apply((lambda x: x.sum()), axis=1)\n",
        "features.sort_values(ascending=False,  inplace=True, by=(\"features\"))\n",
        "features.columns = ['sum'] + list(features.columns[1:])\n",
        "features.to_excel('./HSE project/f2 optimised models/feature_selection.xlsx')\n",
        "features"
      ],
      "metadata": {
        "id": "UBk_Tiwgz-k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Target**: Revascularization"
      ],
      "metadata": {
        "id": "a1LaQi0MhpOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = ('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Повторная реваскуляризация') revascularization"
      ],
      "metadata": {
        "id": "DWV33qmkh516"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarkers A"
      ],
      "metadata": {
        "id": "Iyl8n1NaiDd0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSIi67ddDmFp"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_a, header=[0], usecols=list(range(61,147)))\n",
        "y_train = pd.read_excel(link_train_revascularization_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_revascularization_a, header=[0], usecols=list(range(61,147)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Biomarkers A/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it272Lr_F6t5",
        "outputId": "9377bbaf-f108-4770-e9cd-f9831c39f0aa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (122, 86)\n",
            "y_train shape:\t (122, 1)\n",
            "X_test shape:\t (33, 86)\n",
            "y_test shape:\t (33, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjlFV5-1DmFq"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "40cle3QMDmFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvh5TFLoDmFq"
      },
      "source": [
        "### Metrics table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV7NOycVDmFq"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "rhcYoungDnet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "0gkmcwXqDmFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                              # dataset = biomarkers_a,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "oMAoZTs2DmFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "445WxgzkEiH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top feature optimisation and metrics"
      ],
      "metadata": {
        "id": "cEP-FapsDmFt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wyKJWOSDmFt"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(col for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "nZ2plv5MDmFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IOz1cOuqDmFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP5cWuK2DmFt"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = biomarkers_a.copy()\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "target = biomarkers_a.target\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJllSPJNDmFt"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/revascularization/Biomarkers A/biomarkers top features/\""
      ],
      "metadata": {
        "id": "KPsqHKnVEsvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgtWsfFWDmFt"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "U-Qjy9MtDmFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xPpLYoKDmFt"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhCsC6iuDmFt"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers A"
      ],
      "metadata": {
        "id": "tLyqUfKjHLa8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cN_7dSnHLa8"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_a, header=[0], usecols=list(range(1,147)))\n",
        "y_train = pd.read_excel(link_train_revascularization_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_revascularization_a, header=[0], usecols=list(range(1,147)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Biomarkers A + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CcCtPibHFHZ",
        "outputId": "7f2f7e6b-4367-4a66-9582-1103187d0c74"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (122, 146)\n",
            "y_train shape:\t (122, 1)\n",
            "X_test shape:\t (33, 146)\n",
            "y_test shape:\t (33, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX3gIIn9HLa_"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "INfM3FY5HLa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osEwlKAPHLa_"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aJP7OkQHLbA"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "zVkqT4KeEAfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "MuzfENlBHLbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "tS8cJTxoHLbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "S0_e4jsCHLbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFyQWqF6HLbB"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ_eFjqJHLbB"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "elTpFN6dHLbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v9wx9pTJHLbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v8xe0EIHLbC"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_a.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx4bQ-5dHLbC"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/revascularization/Biomarkers A + Clinical/top features/\""
      ],
      "metadata": {
        "id": "4Yo73zKEHLbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baI0ePQnHLbC"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "kHnjybBuHLbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj5ZIslJHLbD"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtq3yKu3HLbD"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features A"
      ],
      "metadata": {
        "id": "22wZkKV_hxhY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koSRM1E_VNwh"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_a, header=[0], usecols=list(range(1,61)))\n",
        "y_train = pd.read_excel(link_train_revascularization_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_revascularization_a, header=[0], usecols=list(range(1,61)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Clinical A/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiH8ErpTHrxI",
        "outputId": "69d92e01-482f-4a7a-ff35-1a842b557a5d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (122, 60)\n",
            "y_train shape:\t (122, 1)\n",
            "X_test shape:\t (33, 60)\n",
            "y_test shape:\t (33, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYBpTka_VNwi"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "9mMZhSL1VNwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeSlHFw5VNwi"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8b7Qiw-VNwj"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "whu-QJWZELNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "VDEGEYGUVNwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "g3UVWx-mVNwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "zezossttVNwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1e7ubmRVNwk"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkZusG8AVNwk"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "q1_5cIJ_VNwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vDEecELaVNwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtlYQjWVVNwk"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_a.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "733DKnUbVNwl"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/revascularization/Biomarkers A + Clinical/top features/\""
      ],
      "metadata": {
        "id": "rpLKUvo2VNwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pMp-9r8VNwl"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "VlSoVUdXVNwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JquFvXJGVNwm"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeieS6QgVNwm"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarkers B"
      ],
      "metadata": {
        "id": "eDR572Jkh_-I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgxmzAheFnNM"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_b, header=[0], usecols=list(range(72,78)))\n",
        "y_train = pd.read_excel(link_train_revascularization_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_revascularization_b, header=[0], usecols=list(range(72,78)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Biomarkers B/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viYpZf85uOBg",
        "outputId": "1af103bc-5742-40c2-ad8d-4e1a6cea536f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (86, 6)\n",
            "y_train shape:\t (86, 1)\n",
            "X_test shape:\t (29, 6)\n",
            "y_test shape:\t (29, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ2_44RkFnNO"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=4, \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "PPpj-57XFnNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uy8bVdOFnNO"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6z49oeiFnNO"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "4SYwOXJ1EQyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "tjtKCqfmFnNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "pqEuJu4bFnNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# top_features = list(eval(col) for col in dataset.index[:10])\n",
        "# top_features"
      ],
      "metadata": {
        "id": "V62zz_zMFnNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XP8YW7b_FnNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers B"
      ],
      "metadata": {
        "id": "M-ycVKk6iG5H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E20WBJ36t3yV"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_b, header=[0], usecols=list(range(1,78)))\n",
        "y_train = pd.read_excel(link_train_revascularization_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_revascularization_b, header=[0], usecols=list(range(1,78)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Biomarkers B + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ykn2VhVurY3",
        "outputId": "8448ec6e-254d-497d-bd4d-7f5bfbf50244"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (86, 77)\n",
            "y_train shape:\t (86, 1)\n",
            "X_test shape:\t (29, 77)\n",
            "y_test shape:\t (29, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS_thgARt3yX"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "nN24b-Tpt3yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgDdU-vGt3yY"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlEBsCSgt3yY"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "LSl2xkYFEXR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "MuryU5NBt3yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "7xKeYJLMt3yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "76LHWC_Yt3yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c4rioMPt3yZ"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-WCobgnt3yZ"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "kFWqiWkQt3ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Md7n-g3Pt3ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjOZER9Mt3ya"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_b.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44ifw-ZBt3ya"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/revascularization/Biomarkers B + Clinical/top features/\""
      ],
      "metadata": {
        "id": "99RxrGxft3ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuCMYA7Yt3ya"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "7nTAODSpt3ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm0se0Put3ya"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYky1LFOt3yb"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0F4MrdjqHgIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features B"
      ],
      "metadata": {
        "id": "rhd1GR3oHh75"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akbdy35ZHh76"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_b, header=[0], usecols=list(range(1,72)))\n",
        "y_train = pd.read_excel(link_train_revascularization_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_revascularization_b, header=[0], usecols=list(range(1,72)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Clinical B/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18b3_S5CvIy9",
        "outputId": "1026835d-09bb-4852-8ca6-af0a474f6d61"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (86, 71)\n",
            "y_train shape:\t (86, 1)\n",
            "X_test shape:\t (29, 71)\n",
            "y_test shape:\t (29, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SkPQYiAHh78"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "4rjsHSXoHh78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtQef2IVHh79"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruwrgNPdHh79"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "XfpdBayWEb2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "AuLNx9xUHh79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "bkr8QHr7Hh79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "eD46bKNMHh7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p5ovf0rHh7-"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjbqXGYeHh7-"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "04bzGYntHh7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Qhjb-klHh7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnPp4rW9Hh7_"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_b.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAGLDVEvHh7_"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/revascularization/Biomarkers B + Clinical/top features/\""
      ],
      "metadata": {
        "id": "7EEFOnAbHh7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44I07UmeHh7_"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "4LjLEihKHh7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpRP1d43Hh7_"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPifAz3BHh8A"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarkers C"
      ],
      "metadata": {
        "id": "lAelg0QRiBxf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI27ZEhCGvhu"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_c, header=[0], usecols=list(range(101,106)))\n",
        "y_train = pd.read_excel(link_train_revascularization_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_revascularization_c, header=[0], usecols=list(range(101,106)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Biomarkers C/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS_jARD3vf7r",
        "outputId": "0446e0d3-9e6c-456a-85f7-d8ab7eb3d7ce"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (146, 5)\n",
            "y_train shape:\t (146, 1)\n",
            "X_test shape:\t (43, 5)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN8oUEWGGvhw"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=4, \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "mz8c4Q_9Gvhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-bYPgLkGvhw"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEFHmhIDGvhw"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "wYzi_YU6ElZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "bPWPglBlGvhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "QwRcuIeGGvhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers C"
      ],
      "metadata": {
        "id": "a9QyhUgaiIA_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg1bieaGu4pO"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_c, header=[0], usecols=list(range(1,106)))\n",
        "y_train = pd.read_excel(link_train_revascularization_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_revascularization_c, header=[0], usecols=list(range(1,106)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Biomarkers C + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oruNJmRNv5ix",
        "outputId": "64807440-6e07-469b-cd63-6fb9507d4e5b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (146, 105)\n",
            "y_train shape:\t (146, 1)\n",
            "X_test shape:\t (43, 105)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Dn4cstu4pQ"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "1oTICACqu4pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hokb4iA_u4pR"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv66X-yCu4pR"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "s0_brRdYErUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "Lv2cbOTmu4pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "8OXCieuyu4pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "Sul3dGPsu4pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5g9KWdwu4pS"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUg-yEOOu4pS"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "XkfMF_P-u4pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ll41-C_ku4pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x5rKG7vu4pS"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_c.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugOSJAMUu4pS"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path_top_features = \"./HSE project/revascularization/Biomarkers C + Clinical/top features/\""
      ],
      "metadata": {
        "id": "M26zJQeNu4pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z8Uu1o_u4pT"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path_top_features, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "1XOKP5ZHu4pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ9ruwDAu4pT"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UgAIlQTu4pT"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path_top_features)\n",
        "metrics_table.to_excel(f'{optimisation_path_top_features}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AiuC97iuHtfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features C"
      ],
      "metadata": {
        "id": "5dCTZq_mHuER"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbYGqwmFHuER"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_c, header=[0], usecols=list(range(1,101)))\n",
        "y_train = pd.read_excel(link_train_revascularization_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_revascularization_c, header=[0], usecols=list(range(1,101)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Clinical C/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bki7yHhwSpo",
        "outputId": "d9884526-0575-47b2-bb2f-f5afe4fb1f80"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (146, 100)\n",
            "y_train shape:\t (146, 1)\n",
            "X_test shape:\t (43, 100)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gabP4R1HHuEZ"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "XSIxkiVCHuEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Kxbp4UHuEb"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIUkVFmWHuEb"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "lwmcT8qjEzCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "WTmAwxUEHuEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "MSEMZWq9HuEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "BsxKuFOfHuEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrtHvWZKHuEe"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6hC40wzHuEe"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "Q53qYjctHuEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EJVEboudHuEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpwUCj3RHuEf"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_c.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sq6e0tKaHuEg"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path_top_features = \"./HSE project/revascularization/Biomarkers C + Clinical/top features/\""
      ],
      "metadata": {
        "id": "1NOAuBoPHuEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcCKOIC9HuEh"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path_top_features, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "ucXsa8-SHuEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyEVu5O7HuEi"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xujuDi0JHuEj"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path_top_features)\n",
        "metrics_table.to_excel(f'{optimisation_path_top_features}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features A-B-C"
      ],
      "metadata": {
        "id": "ufJ7HSDDU5vh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wrmikGl7lI-"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_revascularization_c, header=[0], usecols=list(range(1,57)))\n",
        "y_train = pd.read_excel(link_train_revascularization_c, header=[0], usecols=[57])\n",
        "X_test  = pd.read_excel(link_test_revascularization_c, header=[0], usecols=list(range(1,57)))\n",
        "y_test  = pd.read_excel(link_test_revascularization_c, header=[0], usecols=[57])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/revascularization/Clinical ABC/all clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkkpapkRwo7c",
        "outputId": "7d7c37d4-e82b-4b00-f0d2-8bea61cb5cb2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (146, 56)\n",
            "y_train shape:\t (146, 1)\n",
            "X_test shape:\t (43, 56)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iylPtZFs7lJA"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "zT4IGjNG7lJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKu1JV_w7lJA"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOxy-xqs7lJA"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "svgtc24TE5e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "9rRvidNG7lJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = clinical_and_biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "4y55ZeTn7lJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbpOZGO_7lJB"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--qZMos-7lJB"
      },
      "source": [
        "#### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "slKFBogx7lJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yqIG_VHo7lJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "metric = ['Эксперимент','Статья']\n",
        "\n",
        "dataset['Importances', 'RandomForest'] = dataset['Importances', 'RandomForest']/dataset['Importances', 'RandomForest'].max()\n",
        "feats = [str(eval(feature)[1]) for feature in dataset.index[:15]]\n",
        "features=dataset.index\n",
        "# ensemble models\n",
        "# models=['Hard voting', 'Soft voting', 'Stacking', 'Bagging', 'adaBoosting']\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=i, x=feats, \n",
        "                             y=dataset['Importances', 'RandomForest'])])\n",
        "\n",
        "# add error whiskers from gridsearchCV\n",
        "# i\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Модели')\n",
        "fig.update_yaxes(title='', range=[0., 1.0])\n",
        "fig.update_layout(xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False})\n",
        "fig.update_layout(barmode='group', \n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"h\", title='Данные'), \n",
        "                  title=dict(text=f'Значения метрик для выбранных моделей', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "# if 1:\n",
        "#     fig.add_shape(type='line',\n",
        "#                     x0=-0.5,\n",
        "#                     y0=0.5,\n",
        "#                     x1=4.5,\n",
        "#                     y1=0.5,\n",
        "#                     line=dict(color='firebrick',  width=2, dash='dot'),\n",
        "#                     xref='x',\n",
        "#                     yref='y')   \n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "ix4X2nmd5tcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZWyrt0-7lJC"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_abc.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De4pLhLC7lJC"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/revascularization/Clinical ABC/top features/\""
      ],
      "metadata": {
        "id": "YAfQBfqt7lJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0nZTsdl7lJC"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score=my_f2_scorer(), \n",
        "       catboost_score='F:beta=2', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "sgCxWkaY7lJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV5g96mZ7lJD"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i8dnh377lJD"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "63ye_HuYozcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scores of models"
      ],
      "metadata": {
        "id": "C5a2h4EaozcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "# F2 F1 ROC_AUC\n",
        "metric = 'ROC_AUC'\n",
        "# list of paths\n",
        "paths = [\n",
        "        './HSE project/revascularization/Biomarkers A/all biomarkers/',\n",
        "        './HSE project/revascularization/Biomarkers B/all biomarkers/',\n",
        "        './HSE project/revascularization/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/revascularization/Clinical ABC/all clinical/',\n",
        "        './HSE project/revascularization/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/revascularization/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/revascularization/Biomarkers C + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/revascularization/Clinical A/all biomarkers and clinical/',\n",
        "        './HSE project/revascularization/Clinical B/all biomarkers and clinical/',\n",
        "        './HSE project/revascularization/Clinical C/all biomarkers and clinical/',\n",
        "        ]\n",
        "\n",
        "# create datframe for scores\n",
        "datasets = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "datasets_mean = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "datasets_std = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}metrics_table.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    datasets[datasets.columns[i]] = list(table.loc[:, ('Scores on the test set', metric)].values.round(3)) \n",
        "    if metric == 'F2':\n",
        "        datasets_mean[datasets_mean.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3)) \n",
        "        datasets_std[datasets_std.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3)) \n",
        "\n",
        "# list of models\n",
        "# standart models\n",
        "models=['RandomForest', 'SVM', 'Logistic Regression', 'KNN', 'CatBoost']\n",
        "# ensemble models\n",
        "# models=['Hard voting', 'Soft voting', 'Stacking', 'Bagging', 'adaBoosting']\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=column, x=models, y=datasets[column]) for column in datasets.columns])\n",
        "    \n",
        "# add error whiskers from gridsearchCV\n",
        "if metric == 'F2':\n",
        "    fig.add_traces([go.Box(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                          #  xaxis=\"x1\",  \n",
        "                           \n",
        "                           marker=dict(color=\"black\"), \n",
        "                           showlegend = False) for column in datasets.columns])\n",
        "    fig.update_traces(\n",
        "    selector=dict(type=\"box\"), # update only boxes\n",
        "    boxpoints=\"all\", # show points\n",
        "    pointpos=0, # centered\n",
        "    jitter=0, # no jitter\n",
        "    line_color=\"rgba(255,255,255,0)\", # hide box lines\n",
        "    fillcolor=\"rgba(255,255,255,0)\", # hide box fill\n",
        "    \n",
        "    )\n",
        "    fig.update_layout(boxmode=\"group\",)\n",
        "\n",
        "    fig.add_traces([go.Bar(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                           xaxis=\"x2\",  \n",
        "                           error_y=dict(type='data',  \n",
        "                                        array=datasets_std[column], \n",
        "                                        color=\"rgba(0,0,0,1)\",\n",
        "                                        thickness=1), \n",
        "                           marker=dict(opacity=0,\n",
        "                                      #  color=\"rgba(255,255,255,0)\"\n",
        "                                       ), \n",
        "                           showlegend = False) for column in datasets.columns])  \n",
        "    \n",
        "\n",
        "fig.update_xaxes(title='Models')\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', \n",
        "                  xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False},\n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Datasets'), \n",
        "                  title=dict(text=f'{metric} score', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "fig.update_yaxes(title='Score', range=[0., 1.0])\n",
        "\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "if metric == 'ROC_AUC':\n",
        "    fig.add_shape(type='line',\n",
        "                    x0=-0.5,\n",
        "                    y0=0.5,\n",
        "                    x1=4.5,\n",
        "                    y1=0.5,\n",
        "                    line=dict(color='firebrick',  width=2, dash='dot'),\n",
        "                    xref='x',\n",
        "                    yref='y')   \n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "VG0PRqlUozcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare with Top 10"
      ],
      "metadata": {
        "id": "AbDGNCtJozcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "# ROC_AUC F1 F2\n",
        "metric = 'ROC_AUC'\n",
        "\n",
        "# list of paths\n",
        "paths = [\n",
        "        './HSE project/revascularization/Biomarkers A/all biomarkers/',\n",
        "        './HSE project/revascularization/Biomarkers B/all biomarkers/',\n",
        "        './HSE project/revascularization/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/revascularization/Clinical ABC/all clinical/',\n",
        "        './HSE project/revascularization/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/revascularization/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/revascularization/Biomarkers C + Clinical/all biomarkers and clinical/'\n",
        "        ]\n",
        "\n",
        "# list of paths of top 10\n",
        "paths_top = [\n",
        "        './HSE project/revascularization/Biomarkers A/biomarkers top features/',\n",
        "        './HSE project/revascularization/Biomarkers B/biomarkers top features/',\n",
        "        './HSE project/revascularization/Biomarkers C/biomarkers top features/',\n",
        "        './HSE project/revascularization/Clinical ABC/top features/',\n",
        "        './HSE project/revascularization/Biomarkers A + Clinical/top features/',\n",
        "        './HSE project/revascularization/Biomarkers B + Clinical/top features/',\n",
        "        './HSE project/revascularization/Biomarkers C + Clinical/top features/'\n",
        "        ]\n",
        "\n",
        "# create datframe for scores\n",
        "datasets = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "datasets_mean = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "datasets_std = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}metrics_table.xlsx', header=[0,1], index_col=[0]) \n",
        "    table_top = pd.read_excel(f'{paths_top[i]}metrics_table.xlsx', header=[0,1], index_col=[0])\n",
        "    datasets[datasets.columns[i]] = list(table.loc[:, ('Scores on the test set', metric)].values.round(3)) + \\\n",
        "                                    list(table_top.loc[:, ('Scores on the test set', metric)].values.round(3))\n",
        "    if metric == 'F2':\n",
        "        datasets_mean[datasets_mean.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3)) + list(table_top.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3))\n",
        "        datasets_std[datasets_std.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3)) + list(table_top.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3))\n",
        "\n",
        "\n",
        "# list of models\n",
        "# standart models\n",
        "models=['RandomForest', 'SVM', 'Logistic Regression', 'KNN', 'CatBoost'] + ['RandomForest top 10', 'SVM top 10', 'Logistic Regression top 10', 'KNN top 10', 'CatBoost top 10']\n",
        "\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=column, x=models, y=datasets[column]) for column in datasets.columns ])\n",
        "\n",
        "# add error whiskers from gridsearchCV\n",
        "if metric == 'F2':\n",
        "    fig.add_traces([go.Box(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                          #  xaxis=\"x1\",  \n",
        "                           \n",
        "                           marker=dict(color=\"black\"), \n",
        "                           showlegend = False) for column in datasets.columns])\n",
        "    fig.update_traces(\n",
        "    selector=dict(type=\"box\"), # update only boxes\n",
        "    boxpoints=\"all\", # show points\n",
        "    pointpos=0, # centered\n",
        "    jitter=0, # no jitter\n",
        "    line_color=\"rgba(255,255,255,0)\", # hide box lines\n",
        "    fillcolor=\"rgba(255,255,255,0)\", # hide box fill\n",
        "    \n",
        "    )\n",
        "    fig.update_layout(boxmode=\"group\",)\n",
        "\n",
        "    fig.add_traces([go.Bar(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                           xaxis=\"x2\",  \n",
        "                           error_y=dict(type='data',  \n",
        "                                        array=datasets_std[column], \n",
        "                                        color=\"rgba(0,0,0,1)\",\n",
        "                                        thickness=1), \n",
        "                           marker=dict(opacity=0,\n",
        "                                      #  color=\"rgba(255,255,255,0)\"\n",
        "                                       ), \n",
        "                           showlegend = False) for column in datasets.columns])  \n",
        "    \n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Models')\n",
        "fig.update_yaxes(title='Score', range=[0., 1.0])\n",
        "fig.update_layout(barmode='group', \n",
        "                  xaxis2={\"overlaying\": \"x\", \"range\": [-0.525, 9.525], \"showticklabels\": False},\n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Datasets'), \n",
        "                  title=dict(text=f'{metric} score', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "if metric == 'ROC_AUC':\n",
        "    fig.add_shape(type='line',\n",
        "                    x0=-0.5,\n",
        "                    y0=0.5,\n",
        "                    x1=9.5,\n",
        "                    y1=0.5,\n",
        "                    line=dict(color='firebrick',  width=2, dash='dot'),\n",
        "                    xref='x',\n",
        "                    yref='y')   \n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "LgbW90ivozcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "XF3CtFMVZoqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = pd.DataFrame(columns=['features', \n",
        "                                 'biomarkers A',\n",
        "                                #  'biomarkers B',\n",
        "                                #  'biomarkers C',\n",
        "                                 'Clinical+biomarkers ABC',\n",
        "                                 'Clinical+biomarkers A',\n",
        "                                #  'Clinical+biomarkers B',\n",
        "                                #  'Clinical+biomarkers C',\n",
        "                                 ])\n",
        "# list of paths\n",
        "paths = [\n",
        "        './HSE project/revascularization/Biomarkers A/all biomarkers/',\n",
        "        # './HSE project/revascularization/Biomarkers B/all biomarkers/',\n",
        "        # './HSE project/revascularization/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/revascularization/Clinical ABC/all clinical/',\n",
        "        './HSE project/revascularization/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        # './HSE project/revascularization/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        # './HSE project/revascularization/Biomarkers C + Clinical/all biomarkers and clinical/'\n",
        "        ]\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "top_features = []\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}feature_selection_dataset.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    table.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "    if i < 1: \n",
        "        top_features = top_features+list(str(col) for col in table.index[:10])\n",
        "    else:    \n",
        "        top_features = top_features+list(eval(col)[1] for col in table.index[:10])\n",
        "\n",
        "features['features'] = list(set(top_features))\n",
        "features.index = list(set(top_features))\n",
        "features.fillna(0, inplace=True)\n",
        "\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}feature_selection_dataset.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    table.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "    if i < 1: \n",
        "        features.loc[list(str(col) for col in table.index[:10]), features.columns[i+1]] = 1\n",
        "    else:    \n",
        "        # top_features = top_features+list(eval(col) for col in table.index[:10])   \n",
        "        features.loc[list(eval(col)[1] for col in table.index[:10]), features.columns[i+1]] = 1 \n",
        "\n",
        "features['features'] = features.iloc[:,1:].apply((lambda x: x.sum()), axis=1)\n",
        "features.sort_values(ascending=False,  inplace=True, by=(\"features\"))\n",
        "features.columns = ['sum'] + list(features.columns[1:])\n",
        "features.to_excel('./HSE project/revascularization/feature_selection.xlsx')\n",
        "features"
      ],
      "metadata": {
        "id": "uU35k4_OZrdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Target**: Combined"
      ],
      "metadata": {
        "id": "9tUjLrEUHhor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarkers A"
      ],
      "metadata": {
        "id": "9r3NLu19Hhor"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXIC5RG9Hhor"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_a, header=[0], usecols=list(range(61,147)))\n",
        "y_train = pd.read_excel(link_train_combined_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_combined_a, header=[0], usecols=list(range(61,147)))\n",
        "y_test  = pd.read_excel(link_test_combined_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Biomarkers A/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcZZGB8XG36n",
        "outputId": "97d6b008-9fc5-4f4b-88b6-17b3bf7419c7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (192, 86)\n",
            "y_train shape:\t (192, 1)\n",
            "X_test shape:\t (50, 86)\n",
            "y_test shape:\t (50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((100*(target.value_counts()[1]) / (target.value_counts().sum())).round(2), '% of positive target')"
      ],
      "metadata": {
        "id": "wP8_NyTdHhos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/combined/Biomarkers A/all biomarkers/\""
      ],
      "metadata": {
        "id": "JRak5-L2Hhos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THsDPzONHhos"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', #my_f2_scorer() 'f1'\n",
        "       catboost_score='F:beta=1', #'F:beta=2' 'F:beta=1'\n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "4_dVij5hHhos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7amsf_qoHhos"
      },
      "source": [
        "### Metrics table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFQ6XFMCHhos"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "1XvnlD09879d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "IWTyqYF5Hhot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                              # dataset = biomarkers_a,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "QsQpYjnnHhot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "vz0WOBrpHhot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top feature optimisation and metrics"
      ],
      "metadata": {
        "id": "mmMpeqlSHhot"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNymIA6iHhot"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(col for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "1Mydav8FHhot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SouhC1g_Hhou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6wsOKYYHhou"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = biomarkers_a.copy()\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "target = biomarkers_a.target\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEIxR0DZHhou"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/combined/Biomarkers A/biomarkers top features/\""
      ],
      "metadata": {
        "id": "6JLJUcogHhou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvNe-6GUHhou"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', #my_f2_scorer()\n",
        "       catboost_score='F:beta=1', #'F:beta=2'\n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "yxiYuTmxHhou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uysoPZdAHhou"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ltWnQmRHhou"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "# metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers A"
      ],
      "metadata": {
        "id": "cwFgMKRaHhou"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx1WxjBuHhou"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_a, header=[0], usecols=list(range(1,147)))\n",
        "y_train = pd.read_excel(link_train_combined_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_combined_a, header=[0], usecols=list(range(1,147)))\n",
        "y_test  = pd.read_excel(link_test_combined_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Biomarkers A + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHdGaK2aHTa5",
        "outputId": "232d7692-a95e-46da-93fc-6b873a3dcddf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (192, 146)\n",
            "y_train shape:\t (192, 1)\n",
            "X_test shape:\t (50, 146)\n",
            "y_test shape:\t (50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBycYCOoHhov"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "LmvEcENLHhov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnYfYpYIHhov"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT4BoHANHhov"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "667DiMh4FN5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "DyrKqGfQHhov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "ClXHw1JwHhov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "aFny2eWiHhov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Whx3QMHHhov"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vKsSXiRHhov"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "XfHcCyHsHhov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nKyrIdg2Hhov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg7MzyNqHhov"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_a.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2YGaKN9Hhov"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/combined/Biomarkers A + Clinical/top features/\""
      ],
      "metadata": {
        "id": "ONSvNEPaHhov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sixw6r9MHhow"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "132SeTkvHhow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOtDKjB6Hhow"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9ayyt6SHhow"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features A"
      ],
      "metadata": {
        "id": "bhB8YS22H7hq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqMZxjZZH7hr"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_a, header=[0], usecols=list(range(1,61)))\n",
        "y_train = pd.read_excel(link_train_combined_a, header=[0], usecols=[147])\n",
        "X_test  = pd.read_excel(link_test_combined_a, header=[0], usecols=list(range(1,61)))\n",
        "y_test  = pd.read_excel(link_test_combined_a, header=[0], usecols=[147])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Clinical A/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPKbHf1st4gD",
        "outputId": "24f80f8a-aed1-4b84-fcf2-68c689b184b4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (192, 60)\n",
            "y_train shape:\t (192, 1)\n",
            "X_test shape:\t (50, 60)\n",
            "y_test shape:\t (50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/combined/Clinical A/all biomarkers and clinical/\""
      ],
      "metadata": {
        "id": "5O6BaUfZH7hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPs1oYvgH7hs"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "SLLtBKWWH7ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvP2_-NWH7ht"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YjwnWx_H7hu"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "6tcFaowrFVuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "K2Uv-PbtH7hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "4fdGaLD3H7hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "6kcHQuuPH7hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGvXlGI6H7hw"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-LBWmRnH7hw"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "IpmKG3foH7hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OzAIcXlzH7hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ-SU1lRH7hx"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_a.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdzgY7xCH7hx"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/combined/Biomarkers A + Clinical/top features/\""
      ],
      "metadata": {
        "id": "KB-SyRFiH7hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tZl9jLDH7hy"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "d86IU5cEH7hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQOb2Dn6H7h0"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0Z4xsROH7h0"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarkers B"
      ],
      "metadata": {
        "id": "gyMVZ3OVHhow"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOre6rUgHhow"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_b, header=[0], usecols=list(range(72,78)))\n",
        "y_train = pd.read_excel(link_train_combined_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_combined_b, header=[0], usecols=list(range(72,78)))\n",
        "y_test  = pd.read_excel(link_test_combined_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Biomarkers B/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df5i4aXvucz0",
        "outputId": "a0cccb23-7319-4107-faa5-e3ce35de5791"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (86, 6)\n",
            "y_train shape:\t (86, 1)\n",
            "X_test shape:\t (32, 6)\n",
            "y_test shape:\t (32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTHM67IyHhox"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=4, \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "7h6lGIQLHhox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W-6q5ImHhox"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb0b_W3hHhox"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "yeCpT1x2FaXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "LW2jJSJXHhox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "KxGzB749Hhox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top_features\n",
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# top_features = list(eval(col) for col in dataset.index[:10])\n",
        "# top_features"
      ],
      "metadata": {
        "id": "-8rtZEPzHhox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cnp8O75oHhox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers B"
      ],
      "metadata": {
        "id": "cCGPKj4oHhox"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtpjx4_EHhox"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_b, header=[0], usecols=list(range(1,78)))\n",
        "y_train = pd.read_excel(link_train_combined_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_combined_b, header=[0], usecols=list(range(1,78)))\n",
        "y_test  = pd.read_excel(link_test_combined_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Biomarkers B + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfDaejyKu5vn",
        "outputId": "9b366795-6c5b-4a22-86ae-9f816a71ea0f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (86, 77)\n",
            "y_train shape:\t (86, 1)\n",
            "X_test shape:\t (32, 77)\n",
            "y_test shape:\t (32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SNhMRF6Hhoy"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "B6CfabgWHhoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndR2wR6LHhoy"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBr9WVVzHhoy"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "2SNHP1_7FgZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "E_DCy2KuHhoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "_PPkSJr_Hhoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "OsDtx73PHhoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNAnY5ukHhoy"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTPV2eVSHhoy"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "DgwEZ_N4Hhoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uxjnWqO3Hhoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcyS115LHhoy"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_b.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ce4LdRnHhoy"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/combined/Biomarkers B + Clinical/top features/\""
      ],
      "metadata": {
        "id": "rxPMCt-fHhoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We4p1HmTHhoz"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "RJknlj5eHhoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPxHGK6uHhoz"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy4MzLhXHhoz"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUJMG0eQIB3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features B"
      ],
      "metadata": {
        "id": "Ys3p3e0YICJk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWXYoKZPICJl"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_b, header=[0], usecols=list(range(1,72)))\n",
        "y_train = pd.read_excel(link_train_combined_b, header=[0], usecols=[78])\n",
        "X_test  = pd.read_excel(link_test_combined_b, header=[0], usecols=list(range(1,72)))\n",
        "y_test  = pd.read_excel(link_test_combined_b, header=[0], usecols=[78])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Clinical B/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yFn0-NRvRxd",
        "outputId": "eae03dc8-c02c-4574-9475-2daee5bc1952"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (86, 71)\n",
            "y_train shape:\t (86, 1)\n",
            "X_test shape:\t (32, 71)\n",
            "y_test shape:\t (32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJevfWBKICJm"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "Ypj2ICMRICJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg7Aj9hoICJo"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0CwCDaeICJo"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "lCwXhsaGFnKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "A6qlyId_ICJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "DHqo43VLICJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "PMHi6Hw9ICJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rWB06fCICJp"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRju0C--ICJp"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "WZ03owKsICJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LuCTVyk9ICJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iaCbmWAICJp"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_b.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-Rx7Ng4ICJq"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/combined/Biomarkers B + Clinical/top features/\""
      ],
      "metadata": {
        "id": "WJWgwVrzICJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YucbxZraICJq"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "earcnGWhICJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xCquP_vICJq"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p5mqfDCICJq"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biomarkers C"
      ],
      "metadata": {
        "id": "6BMlbxmAHhoz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPVRRPtHHhoz"
      },
      "source": [
        "### Subset\n",
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_c, header=[0], usecols=list(range(101,106)))\n",
        "y_train = pd.read_excel(link_train_combined_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_combined_c, header=[0], usecols=list(range(101,106)))\n",
        "y_test  = pd.read_excel(link_test_combined_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Biomarkers C/all biomarkers/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjkVd46DvoQ5",
        "outputId": "eebe4500-fe03-456a-8ed1-5cb85845d41a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (120, 5)\n",
            "y_train shape:\t (120, 1)\n",
            "X_test shape:\t (43, 5)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElW6G2HQHhoz"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=4, \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "BPTKPDcpHhoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5-KkhHxHho0"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnL03l9YHho0"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=True)"
      ],
      "metadata": {
        "id": "L2PpdbD9GAbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "Jvj6e17tHho0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "0x7K-0szHho0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features + Biomarkers C"
      ],
      "metadata": {
        "id": "ZYln1C1fHho0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGhKqRuPHho0"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_c, header=[0], usecols=list(range(1,106)))\n",
        "y_train = pd.read_excel(link_train_combined_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_combined_c, header=[0], usecols=list(range(1,106)))\n",
        "y_test  = pd.read_excel(link_test_combined_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Biomarkers C + Clinical/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_PFElhcwFgL",
        "outputId": "e289cce4-77a8-408c-d1ff-7ea029167ab7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (120, 105)\n",
            "y_train shape:\t (120, 1)\n",
            "X_test shape:\t (43, 105)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXL2067cHho0"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "Rjd_GODoHho0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUmvLIGTHho1"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzVt3RjLHho1"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "WklIjXiiFtvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "rp4loIL3Hho1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "nDj-YTDsHho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "WFhg4egbHho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoPdVn8JHho1"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0rfnWrnHho1"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "0S6GgXqZHho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VWW_Ljc-Hho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NbmbAzeHho1"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_c.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhtT0Gg5Hho1"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path_top_features = \"./HSE project/combined/Biomarkers C + Clinical/top features/\""
      ],
      "metadata": {
        "id": "_OGNQGtkHho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DamIzTfRHho1"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path_top_features, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "98EmQG5qHho1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ueKOrxHho2"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzsQ_RctHho2"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path_top_features)\n",
        "metrics_table.to_excel(f'{optimisation_path_top_features}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfR2-A8nIKTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features C"
      ],
      "metadata": {
        "id": "qe_CQ_zuILBI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqP1K8duILBJ"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_c, header=[0], usecols=list(range(1,101)))\n",
        "y_train = pd.read_excel(link_train_combined_c, header=[0], usecols=[106])\n",
        "X_test  = pd.read_excel(link_test_combined_c, header=[0], usecols=list(range(1,101)))\n",
        "y_test  = pd.read_excel(link_test_combined_c, header=[0], usecols=[106])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Clinical C/all biomarkers and clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EQGyQJWwKuX",
        "outputId": "fe1a2c3a-7688-4760-fd88-20b5cb107d45"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (120, 100)\n",
            "y_train shape:\t (120, 1)\n",
            "X_test shape:\t (43, 100)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59tED96TILBN"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "MF2L9z6UILBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHLCBf8YILBP"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZCAhOLQILBP"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "NBEcECehF4fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "WjG0SjGAILBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection( \n",
        "                        x_data = X_train,\n",
        "                        y_data = y_train,\n",
        "                        path = optimisation_path)\n",
        "df[df['sum'] >= 5]"
      ],
      "metadata": {
        "id": "JaPWfP8NILBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1])\n",
        "df.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "# visualise the table\n",
        "df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Importances\",\"RandomForest\"), (\"Importances\",\"CatBoost\"), (\"Importances\",\"Logistic\")])\\\n",
        "                   .set_precision(3)"
      ],
      "metadata": {
        "id": "NdhZQSpiILBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD339U2UILBU"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI8RF_hZILBW"
      },
      "source": [
        "### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "5KDhMi4EILBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LxmfV0DMILBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMHnX9BoILBa"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_and_biomarkers_c.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH8tAvy6ILBb"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path_top_features = \"./HSE project/combined/Biomarkers C + Clinical/top features/\""
      ],
      "metadata": {
        "id": "dhonFZonILBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g13p4DBaILBc"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path_top_features, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "CPgNuyx9ILBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zraujJLmILBc"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn1YYmMyILBc"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path_top_features)\n",
        "metrics_table.to_excel(f'{optimisation_path_top_features}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical features A-B-C"
      ],
      "metadata": {
        "id": "HhTmeKCuHho2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbOT0H2iHho2"
      },
      "source": [
        "#### Subset\n",
        "#### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset from Github repo and read as excel file\n",
        "\n",
        "# download train and test subsets\n",
        "X_train = pd.read_excel(link_train_combined_c, header=[0], usecols=list(range(1,57)))\n",
        "y_train = pd.read_excel(link_train_combined_c, header=[0], usecols=[57])\n",
        "X_test  = pd.read_excel(link_test_combined_c, header=[0], usecols=list(range(1,57)))\n",
        "y_test  = pd.read_excel(link_test_combined_c, header=[0], usecols=[57])\n",
        "\n",
        "# create path for saving results\n",
        "optimisation_path = \"./HSE project/Optimisation data/combined/Clinical ABC/all clinical/\"\n",
        "\n",
        "# print subsets parameters\n",
        "print('X_train shape:\\t', X_train.shape)\n",
        "print('y_train shape:\\t', y_train.shape)\n",
        "print('X_test shape:\\t', X_test.shape)\n",
        "print('y_test shape:\\t', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl6geSHpwj9A",
        "outputId": "465f2f04-2483-4acc-fa99-9a10869d5262"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:\t (120, 56)\n",
            "y_train shape:\t (120, 1)\n",
            "X_test shape:\t (43, 56)\n",
            "y_test shape:\t (43, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UifoW5_FHho2"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "cuJVJK74Hho2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNSwdImvHho2"
      },
      "source": [
        "### Metrics tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcQP4KE3Hho2"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = random_forest_importances(path = optimisation_path, n_features = 20, biomarkers=False)"
      ],
      "metadata": {
        "id": "qE07Go0gGGcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "BPY0qiMIHho3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "df = feature_selection(\n",
        "                              # dataset = clinical_and_biomarkers_b,\n",
        "                              x_data = X_train,\n",
        "                              y_data = y_train,\n",
        "                              path = optimisation_path)\n",
        "df.tail(40)"
      ],
      "metadata": {
        "id": "wJDy-Q5KHho3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0j9OkZFHho3"
      },
      "source": [
        "### Top feature optimisation and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV9RTnHKHho3"
      },
      "source": [
        "#### subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(f'{optimisation_path}feature_selection_dataset.xlsx', header=[0,1], index_col=[0])\n",
        "dataset.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "top_features = list(eval(col) for col in dataset.index[:10])\n",
        "top_features"
      ],
      "metadata": {
        "id": "cY9UhPE0Hho3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(dataset.index[:20], dataset[(\"Importances\",\"RandomForest\")][:20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NUmI9UPjHho3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inOFQ3rGHho3"
      },
      "outputs": [],
      "source": [
        "# divide into taget and features\n",
        "dataset = clinical_abc.copy()\n",
        "target = dataset.target\n",
        "dataset.drop(columns='target', inplace=True)\n",
        "dataset = dataset[top_features]\n",
        "\n",
        "# make 4 subsets for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    dataset,\n",
        "                                                    target,\n",
        "                                                    train_size = 0.8,\n",
        "                                                    random_state=20,\n",
        "                                                    shuffle=True\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C___tjBJHho3"
      },
      "outputs": [],
      "source": [
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimisation_path = \"./HSE project/combined/Clinical ABC/top features/\""
      ],
      "metadata": {
        "id": "OQSrDoFTHho3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMEkGEI2Hho3"
      },
      "source": [
        "### Hyper-parameter optimisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning(\n",
        "       score='f1', \n",
        "       catboost_score='F:beta=1', \n",
        "       cross_validation=StratifiedKFold(5), \n",
        "       path=optimisation_path, \n",
        "       logistic_regression=True, \n",
        "       knn=True, \n",
        "       random_forest=True, \n",
        "       svm=True, \n",
        "       catboost=True );  clear_output()"
      ],
      "metadata": {
        "id": "6ttHzhnKHho3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8N30wqfHho3"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KnVNO_wHho3"
      },
      "outputs": [],
      "source": [
        "# download optimisation tables and execute the code\n",
        "\n",
        "metrics_table = metric_table(path=optimisation_path)\n",
        "metrics_table.to_excel(f'{optimisation_path}metrics_table.xlsx')\n",
        "# visualise the table\n",
        "metrics_table.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\\\n",
        "                   .set_properties(**{'text-align': 'center'})\\\n",
        "                   .background_gradient(cmap='coolwarm', subset=[(\"Scores on the test set\",\"F2\"), (\"F2 score, train set, cv=5\",\"mean\"), (\"Scores on the test set\",\"F1\"), (\"Scores on the test set\",\"ROC_AUC\")])\\\n",
        "                   .set_precision(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "R1s2EVPZ02vG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scores of models"
      ],
      "metadata": {
        "id": "K3oyJuxd02vH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "# F2 F1 ROC_AUC\n",
        "metric = 'F2'\n",
        "# list of paths\n",
        "paths = [\n",
        "        './HSE project/combined/Biomarkers A/all biomarkers/',\n",
        "        './HSE project/combined/Biomarkers B/all biomarkers/',\n",
        "        './HSE project/combined/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/combined/Clinical ABC/all clinical/',\n",
        "        './HSE project/combined/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/combined/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/combined/Biomarkers C + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/combined/Clinical A/all biomarkers and clinical/',\n",
        "        './HSE project/combined/Clinical B/all biomarkers and clinical/',\n",
        "        './HSE project/combined/Clinical C/all biomarkers and clinical/',\n",
        "        ]\n",
        "\n",
        "# create datframe for scores\n",
        "datasets = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "datasets_mean = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "datasets_std = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C', 'Clinical A','Clinical B','Clinical C'])\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}metrics_table.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    datasets[datasets.columns[i]] = list(table.loc[:, ('Scores on the test set', metric)].values.round(3)) \n",
        "    if metric == 'F2':\n",
        "        datasets_mean[datasets_mean.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3)) \n",
        "        datasets_std[datasets_std.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3)) \n",
        "\n",
        "# list of models\n",
        "# standart models\n",
        "models=['RandomForest', 'SVM', 'Logistic Regression', 'KNN', 'CatBoost']\n",
        "# ensemble models\n",
        "# models=['Hard voting', 'Soft voting', 'Stacking', 'Bagging', 'adaBoosting']\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=column, x=models, y=datasets[column]) for column in datasets.columns])\n",
        "    \n",
        "# add error whiskers from gridsearchCV\n",
        "if metric == 'F2':\n",
        "    fig.add_traces([go.Box(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                          #  xaxis=\"x1\",  \n",
        "                           \n",
        "                           marker=dict(color=\"black\"), \n",
        "                           showlegend = False) for column in datasets.columns])\n",
        "    fig.update_traces(\n",
        "    selector=dict(type=\"box\"), # update only boxes\n",
        "    boxpoints=\"all\", # show points\n",
        "    pointpos=0, # centered\n",
        "    jitter=0, # no jitter\n",
        "    line_color=\"rgba(255,255,255,0)\", # hide box lines\n",
        "    fillcolor=\"rgba(255,255,255,0)\", # hide box fill\n",
        "    \n",
        "    )\n",
        "    fig.update_layout(boxmode=\"group\",)\n",
        "\n",
        "    fig.add_traces([go.Bar(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                           xaxis=\"x2\",  \n",
        "                           error_y=dict(type='data',  \n",
        "                                        array=datasets_std[column], \n",
        "                                        color=\"rgba(0,0,0,1)\",\n",
        "                                        thickness=1), \n",
        "                           marker=dict(opacity=0,\n",
        "                                      #  color=\"rgba(255,255,255,0)\"\n",
        "                                       ), \n",
        "                           showlegend = False) for column in datasets.columns])  \n",
        "    \n",
        "\n",
        "fig.update_xaxes(title='Models')\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', \n",
        "                  xaxis2={\"overlaying\": \"x\", \"range\": [-0.515, 4.515], \"showticklabels\": False},\n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Datasets'), \n",
        "                  title=dict(text=f'{metric} score', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "fig.update_yaxes(title='Score', range=[0., 1.0])\n",
        "\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "if metric == 'ROC_AUC':\n",
        "    fig.add_shape(type='line',\n",
        "                    x0=-0.5,\n",
        "                    y0=0.5,\n",
        "                    x1=4.5,\n",
        "                    y1=0.5,\n",
        "                    line=dict(color='firebrick',  width=2, dash='dot'),\n",
        "                    xref='x',\n",
        "                    yref='y')   \n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "qEv-hbOk02vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare with Top 10"
      ],
      "metadata": {
        "id": "HPvHw2EF02vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what metric to evaluate\n",
        "# ROC_AUC F1 F2\n",
        "metric = 'F2'\n",
        "\n",
        "# list of paths\n",
        "paths = [\n",
        "        './HSE project/combined/Biomarkers A/all biomarkers/',\n",
        "        './HSE project/combined/Biomarkers B/all biomarkers/',\n",
        "        # './HSE project/combined/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/combined/Clinical ABC/all clinical/',\n",
        "        './HSE project/combined/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/combined/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        './HSE project/combined/Biomarkers C + Clinical/all biomarkers and clinical/'\n",
        "        ]\n",
        "\n",
        "# list of paths of top 10\n",
        "paths_top = [\n",
        "        './HSE project/combined/Biomarkers A/biomarkers top features/',\n",
        "        './HSE project/combined/Biomarkers B/biomarkers top features/',\n",
        "        # './HSE project/combined/Biomarkers C/biomarkers top features/',\n",
        "        './HSE project/combined/Clinical ABC/top features/',\n",
        "        './HSE project/combined/Biomarkers A + Clinical/top features/',\n",
        "        './HSE project/combined/Biomarkers B + Clinical/top features/',\n",
        "        './HSE project/combined/Biomarkers C + Clinical/top features/'\n",
        "        ]\n",
        "\n",
        "# create datframe for scores\n",
        "datasets = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "datasets_mean = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "datasets_std = pd.DataFrame(columns=['biomarkers A','biomarkers B','biomarkers C','Clinical+biomarkers ABC','Clinical+biomarkers A','Clinical+biomarkers B','Clinical+biomarkers C'])\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}metrics_table.xlsx', header=[0,1], index_col=[0]) \n",
        "    table_top = pd.read_excel(f'{paths_top[i]}metrics_table.xlsx', header=[0,1], index_col=[0])\n",
        "    datasets[datasets.columns[i]] = list(table.loc[:, ('Scores on the test set', metric)].values.round(3)) + \\\n",
        "                                    list(table_top.loc[:, ('Scores on the test set', metric)].values.round(3))\n",
        "    if metric == 'F2':\n",
        "        datasets_mean[datasets_mean.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3)) + list(table_top.loc[:, ('F2 score, train set, cv=5', 'mean')].values.round(3))\n",
        "        datasets_std[datasets_std.columns[i]] = list(table.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3)) + list(table_top.loc[:, ('F2 score, train set, cv=5', 'std')].values.round(3))\n",
        "\n",
        "\n",
        "# list of models\n",
        "# standart models\n",
        "models=['RandomForest', 'SVM', 'Logistic Regression', 'KNN', 'CatBoost'] + ['RandomForest top 10', 'SVM top 10', 'Logistic Regression top 10', 'KNN top 10', 'CatBoost top 10']\n",
        "\n",
        "\n",
        "# create the graph\n",
        "fig = go.Figure(data=[go.Bar(name=column, x=models, y=datasets[column]) for column in datasets.columns ])\n",
        "\n",
        "# add error whiskers from gridsearchCV\n",
        "if metric == 'F2':\n",
        "    fig.add_traces([go.Box(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                          #  xaxis=\"x1\",  \n",
        "                           \n",
        "                           marker=dict(color=\"black\"), \n",
        "                           showlegend = False) for column in datasets.columns])\n",
        "    fig.update_traces(\n",
        "    selector=dict(type=\"box\"), # update only boxes\n",
        "    boxpoints=\"all\", # show points\n",
        "    pointpos=0, # centered\n",
        "    jitter=0, # no jitter\n",
        "    line_color=\"rgba(255,255,255,0)\", # hide box lines\n",
        "    fillcolor=\"rgba(255,255,255,0)\", # hide box fill\n",
        "    \n",
        "    )\n",
        "    fig.update_layout(boxmode=\"group\",)\n",
        "\n",
        "    fig.add_traces([go.Bar(name=column, x=models, \n",
        "                           y=datasets_mean[column], \n",
        "                           xaxis=\"x2\",  \n",
        "                           error_y=dict(type='data',  \n",
        "                                        array=datasets_std[column], \n",
        "                                        color=\"rgba(0,0,0,1)\",\n",
        "                                        thickness=1), \n",
        "                           marker=dict(opacity=0,\n",
        "                                      #  color=\"rgba(255,255,255,0)\"\n",
        "                                       ), \n",
        "                           showlegend = False) for column in datasets.columns])  \n",
        "    \n",
        "# Change the bar mode\n",
        "fig.update_xaxes(title='Models')\n",
        "fig.update_yaxes(title='Score', range=[0., 1.0])\n",
        "fig.update_layout(barmode='group', \n",
        "                  xaxis2={\"overlaying\": \"x\", \"range\": [-0.525, 9.525], \"showticklabels\": False},\n",
        "                  bargap=0.30,\n",
        "                  bargroupgap=0.3,\n",
        "                  legend=dict(orientation=\"v\", title='Datasets'), \n",
        "                  title=dict(text=f'{metric} score', x=0.5,),\n",
        "                  margin=dict(l=60, r=20, t=60, b=40),)\n",
        "\n",
        "# add dotted line for ROC AUC = 0.5\n",
        "if metric == 'ROC_AUC':\n",
        "    fig.add_shape(type='line',\n",
        "                    x0=-0.5,\n",
        "                    y0=0.5,\n",
        "                    x1=9.5,\n",
        "                    y1=0.5,\n",
        "                    line=dict(color='firebrick',  width=2, dash='dot'),\n",
        "                    xref='x',\n",
        "                    yref='y')   \n",
        "\n",
        "fig.show(renderer='colab')"
      ],
      "metadata": {
        "id": "xFtbW_1a02vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection"
      ],
      "metadata": {
        "id": "0rpBjeQa02vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = pd.DataFrame(columns=['features', \n",
        "                                 'biomarkers A',\n",
        "                                #  'biomarkers B',\n",
        "                                #  'biomarkers C',\n",
        "                                 'Clinical+biomarkers ABC',\n",
        "                                 'Clinical+biomarkers A',\n",
        "                                #  'Clinical+biomarkers B',\n",
        "                                #  'Clinical+biomarkers C',\n",
        "                                 ])\n",
        "# list of paths\n",
        "paths = [\n",
        "        './HSE project/revascularization/Biomarkers A/all biomarkers/',\n",
        "        # './HSE project/revascularization/Biomarkers B/all biomarkers/',\n",
        "        # './HSE project/revascularization/Biomarkers C/all biomarkers/',\n",
        "        './HSE project/revascularization/Clinical ABC/all clinical/',\n",
        "        './HSE project/revascularization/Biomarkers A + Clinical/all biomarkers and clinical/',\n",
        "        # './HSE project/revascularization/Biomarkers B + Clinical/all biomarkers and clinical/',\n",
        "        # './HSE project/revascularization/Biomarkers C + Clinical/all biomarkers and clinical/'\n",
        "        ]\n",
        "\n",
        "# get dataframe with with scores of models from different datasets\n",
        "top_features = []\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}feature_selection_dataset.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    table.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "    if i < 1: \n",
        "        top_features = top_features+list(str(col) for col in table.index[:10])\n",
        "    else:    \n",
        "        top_features = top_features+list(eval(col)[1] for col in table.index[:10])\n",
        "\n",
        "features['features'] = list(set(top_features))\n",
        "features.index = list(set(top_features))\n",
        "features.fillna(0, inplace=True)\n",
        "\n",
        "for i in range(len(paths)):\n",
        "    table = pd.read_excel(f'{paths[i]}feature_selection_dataset.xlsx', header=[0,1], index_col=[0]) #ensemble: advanced_models_metrics, standart: metrics_table\n",
        "    table.sort_values(by=(\"Importances\",\"RandomForest\"), axis=0, ascending=False, inplace=True)\n",
        "    if i < 1: \n",
        "        features.loc[list(str(col) for col in table.index[:10]), features.columns[i+1]] = 1\n",
        "    else:    \n",
        "        # top_features = top_features+list(eval(col) for col in table.index[:10])   \n",
        "        features.loc[list(eval(col)[1] for col in table.index[:10]), features.columns[i+1]] = 1 \n",
        "\n",
        "features['features'] = features.iloc[:,1:].apply((lambda x: x.sum()), axis=1)\n",
        "features.sort_values(ascending=False,  inplace=True, by=(\"features\"))\n",
        "features.columns = ['sum'] + list(features.columns[1:])\n",
        "features.to_excel('./HSE project/revascularization/feature_selection.xlsx')\n",
        "features"
      ],
      "metadata": {
        "id": "XjaiOzgn02vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "JrMovCODYyZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [Guidelines and quality criteria for artificial intelligence-based prediction models in healthcare: a scoping review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8748878/pdf/41746_2021_Article_549.pdf)\n",
        "\n",
        "- ✅ [Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5#citeas)\n",
        "\n",
        "- ✅ [Machine learning-based prediction of adverse events\n",
        "following an acute coronary syndrome (PRAISE): a modelling\n",
        "study of pooled datasets](https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)32519-8/fulltext)\n",
        "\n",
        "- ✅ [Critical appraisal of artificial intelligence-based prediction models for cardiovascular disease](https://watermark.silverchair.com/ehac238.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAtQwggLQBgkqhkiG9w0BBwagggLBMIICvQIBADCCArYGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMSvd0U0E66pd-sc_vAgEQgIICh_0OOn38okwwjvtHKZZRS6iesoJ0VuLm_qXiAJTeVb_83xAfB7oneCMsGdP7SkYUZPlcO3UtImKRROpfFzoAH87-TvQu04QMni8-YL47A9k13em0EMsLU86rv0fjaSmxgG-hPnAe7eRJaEDf1ckm-YBNx65aPTx1UC8yW3YO0gDra3ROrfsyl2UariiUse8hZ5S-I2WvFx0gic__qBLni02hEetj0dt-mInD7DxKqGuk28AuNOCDlF9Q1Tfj7oSyk6_1aNHJJ9XklpOJgzsKn-j4yusaYkapojnZzcNzBGcx6tTWYDn-YFcevxsYSc_uKlSUl40oTPl5Gwp-gAyxaLx9bFRuCDA6bxfPsNjgLQR0Eo4QxBuMD5h8FR6H6hEkZ1heaEpiWvZHqwTbEMddl1L1EgD2w-L-ng1YHbegVuZLa-Noll9OWfYSsVZf330LvUYMnTSu3FxrJ72voWUNhS3xzpTvkaeTqIkQgRU5Q75TfoKpMWfefufVgDshQhRM0ww1qRImd34Faql0RyBAKOPXG_HaucEkyXb60GCd6-0yjP5Mjbq-TML0Y9pnKIvmf9wXcTw-DJTcMT97fzWbp_psY70J02wEjvHPxfkOyEl9TiA08sI24GqKHAZuSU_M5R2dGN5W7qGuN_A-TbFKvO3FyMDOgV89BtJXHk8wVYpR-f2uppZydQydht_KTHlkV8hbYf0StZGbCXLb-fk38yZ6rerF9dTXfT6PtrYdlBYrVW65ZRn1HbxhoA0LBI0f5z8gpiqQjnyxSzrX-e9FYtOfOPu-i-IfGTLMFELowQ3IXkTup2Ee1dvT0sosTfoC5Q6x6d8nubiZFtw_SLYg21vF1XH2Gw9d)\n",
        "\n",
        "- [Interpretation of machine learning predictions for patient outcomes in electronic health records](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7153071/pdf/3200408.pdf)\n",
        "- [Minimum sample size for external validation of a clinical prediction model with a binary outcome](https://pubmed.ncbi.nlm.nih.gov/34031906/)\n",
        "- [Machine learning of clinical variables and coronary artery calcium scoring for the prediction of obstructive coronary artery disease on coronary computed tomography angiography: analysis from the CONFIRM registry](https://pubmed.ncbi.nlm.nih.gov/31513271/)\n",
        "- [Reflection on modern methods: when worlds collide-prediction, machine learning and causal inference](https://pubmed.ncbi.nlm.nih.gov/31298274/)\n",
        "- General Cardiovascular Risk Profile for Use in Primary Care\n",
        "\n",
        "### Feature importance\n",
        "\n",
        "- ✅ [Feature Importance May Be Lying To You](https://towardsdatascience.com/feature-importance-may-be-lying-to-you-3247cafa7ee7)\n",
        "- [Different Measures of Feature Importance Behave Differently](https://hippocampus-garden.com/feature_importance/)\n",
        "- [Explaining Feature Importance by example of a Random Forest](https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e)\n",
        "- [Interpret Logistic Regression Coefficients (For Beginners)](https://quantifyinghealth.com/interpret-logistic-regression-coefficients/)\n",
        "\n",
        "- [FAQ: HOW DO I INTERPRET ODDS RATIOS IN LOGISTIC REGRESSION?](https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/#:~:text=A%20logistic%20regression%20model%20allows,relationship%20with%20the%20predictor%20variables.)\n",
        "\n",
        "### Imputation\n",
        "I decided to use kNN imputation b/c it was easy to implement using sklearn package and it was much better than other simpler imputers. However, there are also two types of complex imputers that might be reasonable to use (MICE and datawig)\n",
        "- [6 Different Ways to Compensate for Missing Values In a Dataset (Data Imputation with examples)](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779)\n",
        "- [sklearn](https://scikit-learn.org/stable/modules/impute.html)\n",
        "- [kNN Imputation for Missing Values in Machine Learning](https://machinelearningmastery.com/knn-imputation-for-missing-values-in-machine-learning/)\n",
        "\n",
        "\n",
        "### Understanding model predictions\n",
        "\n",
        "\n",
        "In paper \"Critical appraisal of artificial intelligence-based prediction models for cardiovascular disease\" it was mentioned the use of LIME and SHAP\n",
        "  \n",
        "##### LIME \n",
        "- [“Why Should I Trust You?” Explaining the Predictions of Any Classifier - paper about LIME](https://arxiv.org/pdf/1602.04938.pdf)\n",
        "\n",
        "- [Understanding model predictions with LIME](https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b)\n",
        "- [Understanding how LIME explains predictions](https://towardsdatascience.com/understanding-how-lime-explains-predictions-d404e5d1829c)\n",
        "- ✅ [How to explain ML models and feature importance with LIME?](https://analyticsindiamag.com/how-to-explain-ml-models-and-feature-importance-with-lime/)\n",
        "- ✅ [Local Interpretable Model-Agnostic Explanations (LIME): An Introduction](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)\n",
        "- ✅ [Explanations (LIME)](https://ema.drwhy.ai/LIME.html)  \n",
        "##### SHAP   \n",
        "- ✅ [SHAP Values Explained Exactly How You Wished Someone Explained to You](https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30)\n",
        "-[Using SHAP Values to Explain How Your Machine Learning Model Works](https://towardsdatascience.com/using-shap-values-to-explain-how-your-machine-learning-model-works-732b3f40e137)\n",
        "-[I have to find out what approximations they use to calculate Shapley values for all features, considering $2^n$ complexity]()\n",
        "-[How to define fairness to detect and prevent discriminatory outcomes in Machine Learning](https://towardsdatascience.com/how-to-define-fairness-to-detect-and-prevent-discriminatory-outcomes-in-machine-learning-ef23fd408ef2)\n",
        "\n",
        "### Fairness\n",
        "- ✅ [A Tutorial on Fairness in Machine Learning](https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb)\n",
        "- [sklego documentation](https://scikit-lego.readthedocs.io/en/latest/fairness.html)\n",
        "- ✅ [Equality and fairness measures in classification models](https://www.auditingalgorithms.net/EqualityAndFairness.html)\n",
        "- [Fairness Definitions Explained - должна быть понятная и полезная статья](http://fairware.cs.umass.edu/papers/Verma.pdf)\n",
        "- [CS 294: Fairness in Machine Learning](https://fairmlclass.github.io/)\n",
        "- []()\n",
        "\n",
        "### Feature seletion\n",
        "- ✅ [Deep-dive on ML techniques for feature selection in Python - Part 1](https://towardsdatascience.com/deep-dive-on-ml-techniques-for-feature-selection-in-python-part-1-3574269d5c69)\n",
        "- ✅ [Deep-dive on ML techniques for feature selection in Python - Part 2](https://towardsdatascience.com/deep-dive-on-ml-techniques-for-feature-selection-in-python-part-2-c258f8a2ac43)\n",
        "- ✅ [Deep-dive on ML techniques for feature selection in Python - Part 3](https://towardsdatascience.com/deep-dive-on-ml-techniques-for-feature-selection-in-python-part-3-de2a7593247f)\n",
        "- ✅ [How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)\n",
        "- ✅ [Understanding ANOVA-F for feature selection in Python](https://datascience.stackexchange.com/questions/74465/how-to-understand-anova-f-for-feature-selection-in-python-sklearn-selectkbest-w#answer-74486)\n",
        "- [sklearn: Feature selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "- ✅ [What are variable importance rankings useful for?](https://stats.stackexchange.com/questions/202277/what-are-variable-importance-rankings-useful-for#question-header)\n",
        "- ✅ [feature importance is a slippery concept](https://stats.stackexchange.com/questions/202221/for-linear-classifiers-do-larger-coefficients-imply-more-important-features/202853#answer-202853)\n",
        "- ✅ [Why lasso for feature selection?](https://stats.stackexchange.com/questions/367155/why-lasso-for-feature-selection#question-header)\n",
        "- [Boruta SHAP: A Tool for Feature Selection Every Data Scientist Should Know](https://towardsdatascience.com/boruta-shap-an-amazing-tool-for-feature-selection-every-data-scientist-should-know-33a5f01285c0#:~:text=The%20idea%20of%20the%20Boruta,importance%20of%20the%20shadow%20features.)\n",
        "- ✅ [Intuitions on L1 and L2 Regularisation](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261)\n",
        "- [L0 Norm, L1 Norm, L2 Norm & L-Infinity Norm](https://montjoile.medium.com/l0-norm-l1-norm-l2-norm-l-infinity-norm-7a7d18a4f40c#:~:text=L1%20Norm%20is%20the%20sum,the%20vector%20are%20weighted%20equally.)\n",
        "- []()\n",
        "- []()\n",
        "\n",
        "### Advanced predictions\n",
        "- [Ensemble methods: bagging, boosting and stacking](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)\n",
        "- [sklearn: Ensemble methods](https://scikit-learn.org/stable/modules/ensemble.html)\n",
        "- [A Deep Dive into Stacking Ensemble Machine Learning — Part I](https://towardsdatascience.com/a-deep-dive-into-stacking-ensemble-machine-learning-part-i-10476b2ade3)\n",
        "- [Cтекинг (Stacking) и блендинг (Blending)](https://dyakonov.org/2017/03/10/c%D1%82%D0%B5%D0%BA%D0%B8%D0%BD%D0%B3-stacking-%D0%B8-%D0%B1%D0%BB%D0%B5%D0%BD%D0%B4%D0%B8%D0%BD%D0%B3-blending/)\n",
        "- []()\n",
        "- []()\n",
        "\n",
        "\n",
        "### Clustering\n",
        "- [Overview of Clustering Algorithms](https://towardsdatascience.com/overview-of-clustering-algorithms-27e979e3724d)\n",
        "- []()\n",
        "- []()"
      ],
      "metadata": {
        "id": "U45FZ6naZBxC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UYl9_BR6X-5J",
        "iRs5NRVjixfu",
        "h4F2kAoHJH9r",
        "iZrQzUijWZH2",
        "-92bxcziIACL",
        "V9nyREL7-Zr5",
        "uPU8e9CAXz9J",
        "NTdcAmUi_tnD",
        "2JVY3GdXH9uP",
        "pjVVWxp_4xga",
        "4Nh1Ta98A_Bc",
        "S0OXRcJ_7cKY",
        "_BlCpf3p7stQ",
        "6bATJ4DDKaKp",
        "qSYGBNL4f6Rw",
        "S3SyRKrLf6Rw",
        "AnhVbxEIf6Rw",
        "FPC8slHFf6Rx",
        "KAMMIzVij6Yt",
        "2092R4RxkAgb",
        "Rat4FoRJkdvR",
        "RqFM--obkdvR",
        "K8lC-Qi_zExR",
        "I3gPu4fCATm5",
        "VMCjdLZW8YFb",
        "QLnKvVCF8YFb",
        "EkTDZHjB1gjh",
        "FpHRlEF-8YFc",
        "dRU5ofWf8YFc",
        "qDtqOZtD8YFc",
        "gI5ZcidR8YFd",
        "tSPSiu9n1-xz",
        "Vczt-rbTs__F",
        "QjRW-0s0jUiT",
        "BN2GDi5ijUiU",
        "iJuEAXu1jUiU",
        "pf_4mjDOjUiX",
        "JiwqUfdcBsGf",
        "pbtSf8XdrNWq",
        "d_RNTmwWvoUd",
        "EJhA8Pw-WkW_",
        "7u3EUjF1voUg",
        "LL__Xts2EqsP",
        "hkwBdD2REqsP",
        "LibI_gdDEqsQ",
        "ofZ-pss6EqsQ",
        "KLpP7Jl1EqsS",
        "JU4wlfa8EqsS",
        "Zfz764jgEqsS",
        "-4E1U_dNEqsT",
        "mMAuj1gSEqsT",
        "7jb9BOhnJU7n",
        "7JQSp2QPJe2e",
        "u-KOlLjxPxnD",
        "ITpM_qwYPxnG",
        "a9HYD5VfPxnG",
        "fUUYSucVPxnH",
        "r9F9FxZgPxnH",
        "qdSsWDM0PxnH",
        "yW3hO_ttPxnJ",
        "ZG1Y1R1-RlyD",
        "zSf0WeAl9IdR",
        "bGAdF83zDhu1",
        "YU7Qvjs8Dhu3",
        "fd5kpAF1Dhu3",
        "Nbhf5zN7M6Hi",
        "z3helMZulO2S",
        "FIbsWOTvlO2T",
        "b3dfnG_1lO2V",
        "rcYYMLDClO2V",
        "ttSEvP4vlO2W",
        "IUAU5fgvlO2W",
        "hPGW_GKOlO2W",
        "f0fsvKlxlO2Y",
        "XUt4raJxFMqy",
        "bUSLIV3vFMqz",
        "Lv1ozWiZFMq0",
        "0Ag6JbHdFMq1",
        "zwsrUvWnFMq2",
        "6RVuCse8FMq3",
        "kYlO4aWSFMq3",
        "sr9b7RRzFMq4",
        "pbJeKYrBFMq4",
        "hC7-grrBWkeX",
        "kwaq-NYJJWYs",
        "z5F-TuVtJWYt",
        "F0tG_YdwJWYt",
        "wUcQ9tz0JWYu",
        "zFakeaPyWbB0",
        "jLOFRa3PMOo7",
        "WKE3ShplMOo-",
        "JKmGxR-gMOo-",
        "mEYEyGIHMOo-",
        "YhA65WfZAHUG",
        "B0eOnMBYAHUI",
        "KsPWmv8TAHUP",
        "kc9wOKPOAHUQ",
        "KfjGS5YUAHUR",
        "hzQMVlZ9m_PK",
        "1dVxxT6fm_PL",
        "ZueutDS-m_PL",
        "HPsG4R8em_PO",
        "NnHg8Zqrm_PO",
        "SREweqgjm_PP",
        "dXtPx8yzm_PP",
        "EcQPEXm7m_PP",
        "F4S0QtBUm_PR",
        "aJjYfOfqfoy9",
        "j8VQDVdLgWl-",
        "M7HeLvnhhegB",
        "-iGBTQ6Oz2nE",
        "a1LaQi0MhpOV",
        "Iyl8n1NaiDd0",
        "jSIi67ddDmFp",
        "rjlFV5-1DmFq",
        "jvh5TFLoDmFq",
        "0gkmcwXqDmFr",
        "cEP-FapsDmFt",
        "3wyKJWOSDmFt",
        "IgtWsfFWDmFt",
        "0xPpLYoKDmFt",
        "tLyqUfKjHLa8",
        "8cN_7dSnHLa8",
        "AX3gIIn9HLa_",
        "osEwlKAPHLa_",
        "MuzfENlBHLbA",
        "LFyQWqF6HLbB",
        "kZ_eFjqJHLbB",
        "baI0ePQnHLbC",
        "fj5ZIslJHLbD",
        "22wZkKV_hxhY",
        "koSRM1E_VNwh",
        "BYBpTka_VNwi",
        "oeSlHFw5VNwi",
        "VDEGEYGUVNwj",
        "m1e7ubmRVNwk",
        "OkZusG8AVNwk",
        "_pMp-9r8VNwl",
        "JquFvXJGVNwm",
        "eDR572Jkh_-I",
        "fgxmzAheFnNM",
        "tQ2_44RkFnNO",
        "3uy8bVdOFnNO",
        "tjtKCqfmFnNP",
        "M-ycVKk6iG5H",
        "E20WBJ36t3yV",
        "gS_thgARt3yX",
        "ZgDdU-vGt3yY",
        "MuryU5NBt3yZ",
        "4c4rioMPt3yZ",
        "C-WCobgnt3yZ",
        "zuCMYA7Yt3ya",
        "zm0se0Put3ya",
        "rhd1GR3oHh75",
        "akbdy35ZHh76",
        "0SkPQYiAHh78",
        "YtQef2IVHh79",
        "AuLNx9xUHh79",
        "8p5ovf0rHh7-",
        "vjbqXGYeHh7-",
        "44I07UmeHh7_",
        "PpRP1d43Hh7_",
        "lAelg0QRiBxf",
        "xI27ZEhCGvhu",
        "hN8oUEWGGvhw",
        "f-bYPgLkGvhw",
        "bPWPglBlGvhx",
        "a9QyhUgaiIA_",
        "Fg1bieaGu4pO",
        "13Dn4cstu4pQ",
        "Hokb4iA_u4pR",
        "Lv2cbOTmu4pR",
        "-5g9KWdwu4pS",
        "sUg-yEOOu4pS",
        "0Z8Uu1o_u4pT",
        "oZ9ruwDAu4pT",
        "5dCTZq_mHuER",
        "CbYGqwmFHuER",
        "gabP4R1HHuEZ",
        "s0Kxbp4UHuEb",
        "WTmAwxUEHuEd",
        "qrtHvWZKHuEe",
        "E6hC40wzHuEe",
        "YcCKOIC9HuEh",
        "eyEVu5O7HuEi",
        "ufJ7HSDDU5vh",
        "1wrmikGl7lI-",
        "iylPtZFs7lJA",
        "nKu1JV_w7lJA",
        "9rRvidNG7lJB",
        "VbpOZGO_7lJB",
        "--qZMos-7lJB",
        "Z0nZTsdl7lJC",
        "aV5g96mZ7lJD",
        "63ye_HuYozcF",
        "C5a2h4EaozcG",
        "AbDGNCtJozcH",
        "XF3CtFMVZoqu",
        "9tUjLrEUHhor",
        "9r3NLu19Hhor",
        "TXIC5RG9Hhor",
        "THsDPzONHhos",
        "7amsf_qoHhos",
        "IWTyqYF5Hhot",
        "mmMpeqlSHhot",
        "WNymIA6iHhot",
        "HvNe-6GUHhou",
        "uysoPZdAHhou",
        "cwFgMKRaHhou",
        "fx1WxjBuHhou",
        "oBycYCOoHhov",
        "bnYfYpYIHhov",
        "DyrKqGfQHhov",
        "5Whx3QMHHhov",
        "_vKsSXiRHhov",
        "sixw6r9MHhow",
        "IOtDKjB6Hhow",
        "bhB8YS22H7hq",
        "XqMZxjZZH7hr",
        "BPs1oYvgH7hs",
        "mvP2_-NWH7ht",
        "K2Uv-PbtH7hv",
        "vGvXlGI6H7hw",
        "I-LBWmRnH7hw",
        "6tZl9jLDH7hy",
        "aQOb2Dn6H7h0",
        "gyMVZ3OVHhow",
        "qOre6rUgHhow",
        "jTHM67IyHhox",
        "5W-6q5ImHhox",
        "LW2jJSJXHhox",
        "cCGPKj4oHhox",
        "Gtpjx4_EHhox",
        "9SNhMRF6Hhoy",
        "ndR2wR6LHhoy",
        "E_DCy2KuHhoy",
        "bNAnY5ukHhoy",
        "TTPV2eVSHhoy",
        "We4p1HmTHhoz",
        "gPxHGK6uHhoz",
        "Ys3p3e0YICJk",
        "jWXYoKZPICJl",
        "KJevfWBKICJm",
        "fg7Aj9hoICJo",
        "A6qlyId_ICJp",
        "6rWB06fCICJp",
        "zRju0C--ICJp",
        "YucbxZraICJq",
        "5xCquP_vICJq",
        "6BMlbxmAHhoz",
        "LPVRRPtHHhoz",
        "ElW6G2HQHhoz",
        "H5-KkhHxHho0",
        "Jvj6e17tHho0",
        "ZYln1C1fHho0",
        "IGhKqRuPHho0",
        "SXL2067cHho0",
        "nUmvLIGTHho1",
        "rp4loIL3Hho1",
        "JoPdVn8JHho1",
        "a0rfnWrnHho1",
        "DamIzTfRHho1",
        "p6ueKOrxHho2",
        "qe_CQ_zuILBI",
        "TqP1K8duILBJ",
        "59tED96TILBN",
        "hHLCBf8YILBP",
        "WjG0SjGAILBR",
        "qD339U2UILBU",
        "MI8RF_hZILBW",
        "g13p4DBaILBc",
        "zraujJLmILBc",
        "HhTmeKCuHho2",
        "lbOT0H2iHho2",
        "UifoW5_FHho2",
        "rNSwdImvHho2",
        "BPY0qiMIHho3",
        "-0j9OkZFHho3",
        "nV9RTnHKHho3",
        "OMEkGEI2Hho3",
        "_8N30wqfHho3",
        "R1s2EVPZ02vG",
        "K3oyJuxd02vH",
        "HPvHw2EF02vI",
        "0rpBjeQa02vK",
        "JrMovCODYyZ2",
        "U45FZ6naZBxC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}