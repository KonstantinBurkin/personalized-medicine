{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iRs5NRVjixfu",
        "eECgjEgma5Tp",
        "Rji8hFffa9sY",
        "EzQUKc3Edx-y",
        "3ifjgUqCfC7d",
        "m6IHFMFcSNSJ",
        "g1UIFvT3CglE",
        "xnBvhswvCm8o",
        "d_gIMEzTCnS1",
        "9WkKTxA6snkG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRs5NRVjixfu"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "x1oNqjsSH7qq"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install catboost\n",
        "# !pip install mrmr_selection\n",
        "# !pip install imblearn\n",
        "# !pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "pDFuCcbfGwB8"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from google.colab import output\n",
        "\n",
        "from pandas import DatetimeIndex as dt\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "# from google.colab import files\n",
        "import IPython\n",
        "from IPython.display import HTML, display\n",
        "# from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# hyper-parameters optimisation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import matthews_corrcoef as mcc\n",
        "from sklearn.metrics import f1_score as f1\n",
        "from sklearn.metrics import accuracy_score as accuracy\n",
        "from sklearn.metrics import precision_score as TP_rate                          \n",
        "from sklearn.metrics import roc_auc_score as roc_auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import recall_score as recall\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import make_scorer,fbeta_score\n",
        "\n",
        "# classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostRegressor, RandomForestRegressor, GradientBoostingClassifier, StackingClassifier, VotingClassifier #\n",
        "from sklearn.tree import DecisionTreeClassifier     #\n",
        "from sklearn.svm import SVC                                    # both linear and radial classification\n",
        "from sklearn.neighbors import KNeighborsClassifier             # k=3\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "import catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "# statistics\n",
        "from scipy.stats import shapiro\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# imputations\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "# now you can import normally from sklearn.impute\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.base import clone\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "# feature selection\n",
        "from sklearn.feature_selection import chi2, mutual_info_classif, f_classif, SelectKBest, RFE, RFECV, SequentialFeatureSelector\n",
        "from scipy.stats import kendalltau, spearmanr\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from mrmr import mrmr_classif\n",
        "\n",
        "# to conver string to dict\n",
        "import ast\n",
        "\n",
        "# Interpretability\n",
        " # !pip install interpret\n",
        "from interpret.blackbox import LimeTabular\n",
        "from interpret import set_visualize_provider\n",
        "from interpret.provider import InlineProvider\n",
        "set_visualize_provider(InlineProvider())\n",
        "from interpret import show\n",
        "\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from __future__ import print_function\n",
        "\n",
        "# ignore warnings when graphs are plotted\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9S7ey6ONpI7j"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install ipython-autotime\n",
        "\n",
        "# %load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data tranformation"
      ],
      "metadata": {
        "id": "Fd_K7om5asA4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5K5DK0zggBc"
      },
      "source": [
        "Letter with data: [here](https://mail.yandex.ru/?win=176&clid=1985545-207&uid=112725799#message/179862510118127643)\n",
        "- [Difference between Standard scaler and MinMaxScaler](https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler)\n",
        "- [sklearn: Compare the effect of different scalers on data with outliers](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)\n",
        "- [How to Use StandardScaler and MinMaxScaler Transforms in Python](https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/)\n",
        "\n",
        "Robust scaler is less sensitive to outliers -> might perform better  \n",
        "Although, for non-normal distribution of variables Normalisation methods (MinMaxScaler) are recommended"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset A"
      ],
      "metadata": {
        "id": "eECgjEgma5Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download Dataset A from Github repo and read as excel file\n",
        "\n",
        "\n",
        "link_a = 'https://github.com/KonstantinBurkin/personalized-medicine/blob/master/Data/cardio_a_updated.xlsx?raw=true'\n",
        "data_a = pd.read_excel(link_a ,header=[0,1], index_col=0)\n",
        "print('data_a raw shape: ', data_a.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztl_VKdlSLik",
        "outputId": "2bdb77b7-4246-41c8-89f0-869ccde10345"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_a raw shape:  (263, 252)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correcting data_a\n",
        "\n",
        "\n",
        "# replace NAs with -1\n",
        "data_a = data_a.fillna(-1)\n",
        "data_a = data_a.replace(' ',-1)\n",
        "\n",
        "# Modify 'Пол' feature: covert all string to lower format and convert to 0 and 1\n",
        "data_a['АНТРОПОФИЗИОМЕТРИЯ', 'Пол'] = data_a['АНТРОПОФИЗИОМЕТРИЯ', 'Пол'].str.lower().replace(['м','ж'],[0,1])\n",
        "\n",
        "# correct date typos\n",
        "data_a['АНТРОПОФИЗИОМЕТРИЯ', 'Дата госпитализации'][154] = '2013-03-22 00:00:00'\n",
        "data_a['АНТРОПОФИЗИОМЕТРИЯ', 'Дата госпитализации'][129] = '2013-01-17 00:00:00'\n",
        "data_a['АНТРОПОФИЗИОМЕТРИЯ', 'Дата госпитализации'] = pd.to_datetime(data_a['АНТРОПОФИЗИОМЕТРИЯ', 'Дата госпитализации'], format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Replace typos or non-numeric data with '-1'\n",
        "data_a[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия ХБП по KDOQI /ERA')] = \\\n",
        "data_a[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия ХБП по KDOQI /ERA')].replace(\n",
        "    [\"С2\", \"С1\", \"с2\", \"с1\", \"С3а\", \"с3а\", \"C2\", \"с3б\", \"C1\", \"С3б\", \"С4\", \"С3\", \"3А\", \"с4\", \"с5\", \"С3b\", \"ОПН!\"], \\\n",
        "    [\"c2\", \"c1\", \"c2\", \"c1\", \"c3a\", \"c3a\", \"c2\", \"c3b\", \"c1\", \"c3b\", \"c4\", \"c3\", \"c3a\", \"c4\", \"c5\", \"c3b\", \"опн!\"] )\n",
        "data_a[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия ХБП по KDOQI /ERA')] = \\\n",
        "data_a[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия ХБП по KDOQI /ERA')].replace(\n",
        "    ['c2', 'c1', 'c3a', 'c3b', 'c4', 'c3', 0, 2, 'c5', 'опн!'], [0,  1,  2,  3,  4,  5,  6,  7,  8,  9] ).astype(int)\n",
        "# ---------------\n",
        "data_a[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия по KDOQI/ERA')] = \\\n",
        "data_a[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия по KDOQI/ERA')].replace(\n",
        "    [-1, 'С2', 'с2', 'С1', 0, 'c2', 'с1', 'С3а', 'C2', 'C1', 'С4', 'с3б', 'С3b', 'С3А', 'с4', 'C3б', 'C3а', 'С3б'],\n",
        "    [-1, 'c2', 'c2', 'c1', 0, 'c2', 'c1', 'c3a', 'c2', 'c1', 'c4', 'c3b', 'c3b', 'c3a', 'c4', 'c3b', 'c3a', 'c3b'] )\n",
        "data_a[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия по KDOQI/ERA')] = \\\n",
        "data_a[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия по KDOQI/ERA')].replace(\n",
        "    [-1, 'c2', 'c1', 'c3a', 'c3b', 0, 'c4'], [-1, 1, 2, 3, 4, 0, 5] ).astype(int)\n",
        "# ---------------\n",
        "data_a[('Хроническая сердечная недостаточность', 'НК')] = \\\n",
        "data_a[('Хроническая сердечная недостаточность', 'НК')].replace([-1, 1, '2а', 0, '2А', '2Б', 2, '2б'], [-1, 1, 3, 0, 3, 4, 2, 4]).astype(int)\n",
        "# ---------------\n",
        "data_a.rename({'Повторная реваскуляризация (ЧКВ/АКШ)': 'Повторная реваскуляризация'}, axis=1, inplace=True)\n",
        "data_a[('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Повторная реваскуляризация')].replace(to_replace=['ЧКВ',\n",
        "                           'АКШ',\n",
        "                           '1899-12-29 00:00:00', \n",
        "                           'ЧКВ ',\n",
        "                           'АКШ ', \n",
        "                           '2018-07-30 00:00:00', \n",
        "                           '2019-04-15 00:00:00', \n",
        "                           '2020-08-30 00:00:00'], \n",
        "               value=1, \n",
        "               inplace=True)\n",
        "data_a[('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Повторная реваскуляризация')].replace(to_replace=['0'], value=0, inplace=True)\n",
        "\n",
        "# Features with nulls: manually chose non-categorical columns with '0' and replace with '-1' \n",
        "# nulls = [col for col in data_a.columns[:90] if (len((data_a[col].unique())) > 12) and (data_a[col] == 0).sum() > 0] ; data_a[nulls]\n",
        "data_a[('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'ЛПНП, ммоль/л')] = data_a[('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'ЛПНП, ммоль/л')].replace([0],[-1]) \n",
        "data_a[('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Билирубин, мкмоль/л')] = data_a[('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Билирубин, мкмоль/л')].replace([0],[-1]) "
      ],
      "metadata": {
        "id": "WY9GWtLWSg3h"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find columns\n",
        "\n",
        "\n",
        "hyperlipidemia = pd.DataFrame(columns=pd.MultiIndex.from_product([['ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ'], ['Хсобщ, ммоль/л']]))\n",
        "hyperlipidemia[('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ'), ('Хсобщ, ммоль/л')] = data_a[('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Хсобщ, ммоль/л')]\n",
        "\n",
        "\n",
        "# drop features that were obtained at first discharge and biomarkers \n",
        "# columns must have no more than threshold=20% of NAs\n",
        "threshold = 0.2\n",
        "columns_with_useful_data = list(data_a.columns[:2]) + list(data_a.columns[3:77]) + list(data_a.columns[148:237])\n",
        "cols_with_NAs = [col for col in columns_with_useful_data if (data_a[col] == -1).sum() > threshold*data_a.shape[0]]\n",
        "data_a.drop(columns=cols_with_NAs, inplace=True)       \n",
        "\n",
        "\n",
        "# find all the necessary columns\n",
        "# define continuous and categorical groups\n",
        "clinical_and_biomarkers = list(data_a.columns[:2]) + list(data_a.columns[3:61]) + list(data_a.columns[132:218])\n",
        "continuous_cols = [col for col in clinical_and_biomarkers if (len((data_a[col].unique())) >= 7)]\n",
        "categorical = [col for col in clinical_and_biomarkers if (len((data_a[col].unique())) < 7)]\n",
        "clinical_and_biomarkers_and_hyperlipidemia = clinical_and_biomarkers + [('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Хсобщ, ммоль/л')]"
      ],
      "metadata": {
        "id": "hpuxOzzBbAeg"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('data_a raw shape: ', data_a.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8O2xRIoGpdJ",
        "outputId": "c6fc0d46-820c-4604-bf53-e0c6a882ae93"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_a raw shape:  (263, 233)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Make imputation\n",
        "\n",
        "# # replace -1 values with NA\n",
        "# data_a[clinical_and_biomarkers] = data_a[clinical_and_biomarkers].replace(-1, np.nan)\n",
        "\n",
        "# # Impute NAs with IterativeImputer (estimator - RandomForestRegressor)\n",
        "# impute_estimator = RandomForestRegressor(n_estimators=50,\n",
        "#                                          max_depth=5,\n",
        "#                                          n_jobs=-1,\n",
        "#                                          random_state=0)\n",
        "# imputer = IterativeImputer(random_state=0,\n",
        "#                            estimator=impute_estimator, \n",
        "#                            max_iter=25)\n",
        "# data_a[clinical_and_biomarkers] = imputer.fit_transform(data_a[clinical_and_biomarkers])\n",
        "\n",
        "# # Round values for categorical data - so that there will be no new categories\n",
        "# data_a[categorical] = data_a[categorical].values.round()\n",
        "\n",
        "# save this column for Lancet dataset\n",
        "hyperlipidemia = hyperlipidemia.replace(-1, np.nan)"
      ],
      "metadata": {
        "id": "XrqG7EbOjeIO"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For subsets\n",
        "\n",
        "\n",
        "biomarkers_a_columns = list(data_a.columns[132:218])\n",
        "clinical_and_biomarkers_a_columns = list(data_a.columns[:2]) + list(data_a.columns[3:61]) + list(data_a.columns[132:218])\n",
        "clinical_a_columns = list(data_a.columns[:2]) + list(data_a.columns[3:61])"
      ],
      "metadata": {
        "id": "No88VtSBiISb"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_a[biomarkers_a_columns].head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "W-UFN4vRkFsd",
        "outputId": "b762bc42-08cf-49c9-c5fe-3fc1f2d00d2a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      БИОМАРКЕРЫ БЛОК А                                                       \\\n",
              "№ п/п      TnI-1, нг/мл TnI-2, нг/мл TnI-3, нг/мл TnI-4, нг/мл CKMB-1, нг/мл   \n",
              "1                  7.56         13.0        2.310        -1.00          21.5   \n",
              "2                  5.17         10.3        0.304         0.66          28.2   \n",
              "\n",
              "                                                                         ...  \\\n",
              "№ п/п CKMB-2, нг/мл CKMB-3, нг/мл CKMB-4, нг/мл MG-1, нг/мл MG-2, нг/мл  ...   \n",
              "1              3.14          6.71          -1.0       460.6      164.20  ...   \n",
              "2              0.50          3.85           7.5       421.3       56.21  ...   \n",
              "\n",
              "                                                                              \\\n",
              "№ п/п АЧТВ-3, с АЧТВ-4, с АТ3-1, % АТ3-2, % АТ3-3, % АТ3-4, % FW-1,%  FW-2,%   \n",
              "1          31.2      -1.0   100.72    86.59   116.31    -1.00  120.0  120.00   \n",
              "2          34.0      36.1   100.55   101.63   127.76    99.58  120.0  115.99   \n",
              "\n",
              "                     \n",
              "№ п/п FW-3,% FW-4,%  \n",
              "1        293   -1.0  \n",
              "2         90   94.0  \n",
              "\n",
              "[2 rows x 86 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"21\" halign=\"left\">БИОМАРКЕРЫ БЛОК А</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>№ п/п</th>\n",
              "      <th>TnI-1, нг/мл</th>\n",
              "      <th>TnI-2, нг/мл</th>\n",
              "      <th>TnI-3, нг/мл</th>\n",
              "      <th>TnI-4, нг/мл</th>\n",
              "      <th>CKMB-1, нг/мл</th>\n",
              "      <th>CKMB-2, нг/мл</th>\n",
              "      <th>CKMB-3, нг/мл</th>\n",
              "      <th>CKMB-4, нг/мл</th>\n",
              "      <th>MG-1, нг/мл</th>\n",
              "      <th>MG-2, нг/мл</th>\n",
              "      <th>...</th>\n",
              "      <th>АЧТВ-3, с</th>\n",
              "      <th>АЧТВ-4, с</th>\n",
              "      <th>АТ3-1, %</th>\n",
              "      <th>АТ3-2, %</th>\n",
              "      <th>АТ3-3, %</th>\n",
              "      <th>АТ3-4, %</th>\n",
              "      <th>FW-1,%</th>\n",
              "      <th>FW-2,%</th>\n",
              "      <th>FW-3,%</th>\n",
              "      <th>FW-4,%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.56</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.310</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>21.5</td>\n",
              "      <td>3.14</td>\n",
              "      <td>6.71</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>460.6</td>\n",
              "      <td>164.20</td>\n",
              "      <td>...</td>\n",
              "      <td>31.2</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>100.72</td>\n",
              "      <td>86.59</td>\n",
              "      <td>116.31</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>120.0</td>\n",
              "      <td>120.00</td>\n",
              "      <td>293</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.17</td>\n",
              "      <td>10.3</td>\n",
              "      <td>0.304</td>\n",
              "      <td>0.66</td>\n",
              "      <td>28.2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>3.85</td>\n",
              "      <td>7.5</td>\n",
              "      <td>421.3</td>\n",
              "      <td>56.21</td>\n",
              "      <td>...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>36.1</td>\n",
              "      <td>100.55</td>\n",
              "      <td>101.63</td>\n",
              "      <td>127.76</td>\n",
              "      <td>99.58</td>\n",
              "      <td>120.0</td>\n",
              "      <td>115.99</td>\n",
              "      <td>90</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 86 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a[clinical_and_biomarkers_a_columns].head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "BmGRO6bUkN1y",
        "outputId": "1589ba44-395c-4354-8624-ca6bc6b45d9e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      АНТРОПОФИЗИОМЕТРИЯ                                                       \\\n",
              "№ п/п                Пол Возраст  Рост  Вес        ИМТ S тела систол. АД  ЧСС   \n",
              "1                      0      75  1.64   80  29.744200   1.88        190   90   \n",
              "2                      0      49  1.76  130  41.967975   2.41        140  100   \n",
              "\n",
              "              ХАРАКТЕРИСТИКА ОИМ             ... БИОМАРКЕРЫ БЛОК А            \\\n",
              "№ п/п Давность болевого синдрома Cегмент ST  ...         АЧТВ-3, с АЧТВ-4, с   \n",
              "1                              2          1  ...              31.2      -1.0   \n",
              "2                              2          1  ...              34.0      36.1   \n",
              "\n",
              "                                                                        \n",
              "№ п/п АТ3-1, % АТ3-2, % АТ3-3, % АТ3-4, % FW-1,%  FW-2,% FW-3,% FW-4,%  \n",
              "1       100.72    86.59   116.31    -1.00  120.0  120.00    293   -1.0  \n",
              "2       100.55   101.63   127.76    99.58  120.0  115.99     90   94.0  \n",
              "\n",
              "[2 rows x 146 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">АНТРОПОФИЗИОМЕТРИЯ</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ХАРАКТЕРИСТИКА ОИМ</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"10\" halign=\"left\">БИОМАРКЕРЫ БЛОК А</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>№ п/п</th>\n",
              "      <th>Пол</th>\n",
              "      <th>Возраст</th>\n",
              "      <th>Рост</th>\n",
              "      <th>Вес</th>\n",
              "      <th>ИМТ</th>\n",
              "      <th>S тела</th>\n",
              "      <th>систол. АД</th>\n",
              "      <th>ЧСС</th>\n",
              "      <th>Давность болевого синдрома</th>\n",
              "      <th>Cегмент ST</th>\n",
              "      <th>...</th>\n",
              "      <th>АЧТВ-3, с</th>\n",
              "      <th>АЧТВ-4, с</th>\n",
              "      <th>АТ3-1, %</th>\n",
              "      <th>АТ3-2, %</th>\n",
              "      <th>АТ3-3, %</th>\n",
              "      <th>АТ3-4, %</th>\n",
              "      <th>FW-1,%</th>\n",
              "      <th>FW-2,%</th>\n",
              "      <th>FW-3,%</th>\n",
              "      <th>FW-4,%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>1.64</td>\n",
              "      <td>80</td>\n",
              "      <td>29.744200</td>\n",
              "      <td>1.88</td>\n",
              "      <td>190</td>\n",
              "      <td>90</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>31.2</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>100.72</td>\n",
              "      <td>86.59</td>\n",
              "      <td>116.31</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>120.0</td>\n",
              "      <td>120.00</td>\n",
              "      <td>293</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>1.76</td>\n",
              "      <td>130</td>\n",
              "      <td>41.967975</td>\n",
              "      <td>2.41</td>\n",
              "      <td>140</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>36.1</td>\n",
              "      <td>100.55</td>\n",
              "      <td>101.63</td>\n",
              "      <td>127.76</td>\n",
              "      <td>99.58</td>\n",
              "      <td>120.0</td>\n",
              "      <td>115.99</td>\n",
              "      <td>90</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 146 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a[clinical_a_columns].head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "Mq95k1TNkPJs",
        "outputId": "a7b59671-d0de-476d-a977-c001e961c69e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      АНТРОПОФИЗИОМЕТРИЯ                                                       \\\n",
              "№ п/п                Пол Возраст  Рост  Вес        ИМТ S тела систол. АД  ЧСС   \n",
              "1                      0      75  1.64   80  29.744200   1.88        190   90   \n",
              "2                      0      49  1.76  130  41.967975   2.41        140  100   \n",
              "\n",
              "              ХАРАКТЕРИСТИКА ОИМ             ... ИСХОДНАЯ ЭХОКГ          \\\n",
              "№ п/п Давность болевого синдрома Cегмент ST  ...          ФВ ЛЖ ТМЖП ЛЖ   \n",
              "1                              2          1  ...      55.147059     1.3   \n",
              "2                              2          1  ...      54.304636     1.4   \n",
              "\n",
              "                                                                     \n",
              "№ п/п ТЗС ЛЖ  ММ ЛЖ иММ ЛЖ   ЛП РМК Аневризма ЛЖ Тромбоз ЛЖ ИНЛС ЛЖ  \n",
              "1       1.20  271.5  144.4  4.2   1            0          0   0.000  \n",
              "2       1.13  301.6  125.1  4.1   1            0          0   1.125  \n",
              "\n",
              "[2 rows x 60 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">АНТРОПОФИЗИОМЕТРИЯ</th>\n",
              "      <th colspan=\"2\" halign=\"left\">ХАРАКТЕРИСТИКА ОИМ</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"10\" halign=\"left\">ИСХОДНАЯ ЭХОКГ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>№ п/п</th>\n",
              "      <th>Пол</th>\n",
              "      <th>Возраст</th>\n",
              "      <th>Рост</th>\n",
              "      <th>Вес</th>\n",
              "      <th>ИМТ</th>\n",
              "      <th>S тела</th>\n",
              "      <th>систол. АД</th>\n",
              "      <th>ЧСС</th>\n",
              "      <th>Давность болевого синдрома</th>\n",
              "      <th>Cегмент ST</th>\n",
              "      <th>...</th>\n",
              "      <th>ФВ ЛЖ</th>\n",
              "      <th>ТМЖП ЛЖ</th>\n",
              "      <th>ТЗС ЛЖ</th>\n",
              "      <th>ММ ЛЖ</th>\n",
              "      <th>иММ ЛЖ</th>\n",
              "      <th>ЛП</th>\n",
              "      <th>РМК</th>\n",
              "      <th>Аневризма ЛЖ</th>\n",
              "      <th>Тромбоз ЛЖ</th>\n",
              "      <th>ИНЛС ЛЖ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>1.64</td>\n",
              "      <td>80</td>\n",
              "      <td>29.744200</td>\n",
              "      <td>1.88</td>\n",
              "      <td>190</td>\n",
              "      <td>90</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>55.147059</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1.20</td>\n",
              "      <td>271.5</td>\n",
              "      <td>144.4</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>1.76</td>\n",
              "      <td>130</td>\n",
              "      <td>41.967975</td>\n",
              "      <td>2.41</td>\n",
              "      <td>140</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>54.304636</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.13</td>\n",
              "      <td>301.6</td>\n",
              "      <td>125.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 60 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset B"
      ],
      "metadata": {
        "id": "Rji8hFffa9sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read cardio_b_updated.xlsx\n",
        "data_b = pd.read_excel('./HSE project/Data/cardio_b_updated.xlsx',header=[0,1])\n",
        "# drop index column\n",
        "data_b.drop(columns=('Unnamed: 0_level_0','№ п/п'), inplace=True)\n",
        "# replace NAs with -1\n",
        "data_b = data_b.fillna(-1)\n",
        "data_b = data_b.replace(' ',-1)\n",
        "# Modify 'Пол' feature: covert all string to lower format and convert to 0 and 1\n",
        "data_b['АНТРОПОФИЗИОМЕТРИЯ', 'Пол'] = data_b['АНТРОПОФИЗИОМЕТРИЯ', 'Пол'].str.lower().replace(['м','ж'],[0,1])\n",
        "\n",
        "\n",
        "# Replace typos or non-numeric data with '-1'\n",
        "data_b[('ИСХОДНАЯ ЭХОКГ', 'РМК')] = data_b[('ИСХОДНАЯ ЭХОКГ', 'РМК')].replace('1-2', -1).astype(int)\n",
        "# ---------------\n",
        "data_b[('КОРОНАРОАНГИОГРАФИЯ И РЕВАСКУЛЯРИЗАЦИЯ МИОКАРДА', 'TIMI в ИЗА')] = \\\n",
        "data_b[('КОРОНАРОАНГИОГРАФИЯ И РЕВАСКУЛЯРИЗАЦИЯ МИОКАРДА', 'TIMI в ИЗА')].replace(['0-I', '0-1', '1-2'], [4, 5, 6]).astype(int)\n",
        "# ---------------\n",
        "data_b[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия ХБП по KDOQI /ERA')] = \\\n",
        "data_b[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия ХБП по KDOQI /ERA')].replace(\n",
        "    [\"С2\", \"С1\", \"с2\", \"с1\", \"С3а\", \"с3а\", \"C2\", \"с3б\", \"C1\", \"С3б\", \"С4\", \"С3\", \"3А\", \"с4\", \"с5\", \"С3b\", \"ОПН!\"], \\\n",
        "    [\"c2\", \"c1\", \"c2\", \"c1\", \"c3a\", \"c3a\", \"c2\", \"c3b\", \"c1\", \"c3b\", \"c4\", \"c3\", \"3a\", \"c4\", \"c5\", \"c3b\", \"опн!\"] )\n",
        "data_b[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия ХБП по KDOQI /ERA')] = \\\n",
        "data_b[('СОПУТСТВУЮЩИЕ ЗАБОЛЕВАНИЯ И СОСТОЯНИЯ', 'Стадия ХБП по KDOQI /ERA')].replace(\n",
        "    ['c2', 'c1', 'c3a', 'c3b', 'c4', 'c3', 0, 2, '3a', 'c5', 'опн!'], [0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10] ).astype(int)\n",
        "# ---------------\n",
        "data_b[('ЭХОКГ (ИСХОД)', 'ТМЖП ЛЖ')] = \\\n",
        "data_b[('ЭХОКГ (ИСХОД)', 'ТМЖП ЛЖ')].replace(['1,1-1,0-0,8', '1,0 - 1,5', '1,3; 0,8'], -1).astype(float)\n",
        "# ---------------\n",
        "data_b[('ПОВТОРНАЯ ЭХОКГ', 'ЛП')] = \\\n",
        "data_b[('ПОВТОРНАЯ ЭХОКГ', 'ЛП')].replace(['С2'], -1).astype(float)\n",
        "# ---------------\n",
        "data_b[('ПОВТОРНАЯ ЭХОКГ', 'ТМЖП ЛЖ')] = \\\n",
        "data_b[('ПОВТОРНАЯ ЭХОКГ', 'ТМЖП ЛЖ')].replace(['1,1-1.0-0,7'], -1).astype(float)\n",
        "# ---------------\n",
        "data_b.replace(to_replace=['ЧКВ',\n",
        "                           'АКШ',\n",
        "                           '1899-12-29 00:00:00', \n",
        "                           'ЧКВ ',\n",
        "                           'АКШ ', \n",
        "                           pd.to_datetime('2018-07-30 00:00:00', format='%Y-%m-%d %H:%M:%S'),\n",
        "                           pd.to_datetime('2019-04-15 00:00:00', format='%Y-%m-%d %H:%M:%S'),\n",
        "                           pd.to_datetime('2020-08-30 00:00:00', format='%Y-%m-%d %H:%M:%S'),\n",
        "                           ], \n",
        "               value=1, \n",
        "               inplace=True)\n",
        "data_b[('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Повторная реваскуляризация')].replace(to_replace=['0'], value=0, inplace=True)\n",
        "\n",
        "# Features with nulls: manually chose non-categorical columns with '0' and replace with '-1' \n",
        "# nulls = [col for col in data_b.columns[:90] if (len((data_b[col].unique())) > 12) and (data_b[col] == 0).sum() > 0] ; data_b[nulls]\n",
        "data_b[('ИСХОДНАЯ ЭХОКГ', 'ИНЛС ЛЖ')] = data_b[('ИСХОДНАЯ ЭХОКГ', 'ИНЛС ЛЖ')].replace([0],[-1]) \n",
        "\n",
        "\n",
        "# drop features that were obtained at first discharge and biomarkers that have more than 20% of NAs\n",
        "cols_with_NAs = [col for col in (list(data_b.columns[:2]) + list(data_b.columns[3:84])) \\\n",
        "                        if (data_b[col] == -1).sum() > 0.2*data_b.shape[0]] # there are more than 20% of NAs in some biomarkers\n",
        "data_b.drop(columns=cols_with_NAs, inplace=True)\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "clinical_and_biomarkers = list(data_b.columns[:2]) + list(data_b.columns[3:72]) + list(data_b.columns[214:])\n",
        "continuous_cols = [col for col in clinical_and_biomarkers if (len((data_b[col].unique())) >= 7)]\n",
        "categorical = [col for col in clinical_and_biomarkers if (len((data_b[col].unique())) < 7)]\n",
        "\n",
        "data_b[clinical_and_biomarkers] = data_b[clinical_and_biomarkers].replace(-1, np.nan)\n",
        "\n",
        "# Impute NAs with IterativeImputer (estimator - RandomForestRegressor)\n",
        "impute_estimator = RandomForestRegressor( n_estimators=50,\n",
        "                                          max_depth=5,\n",
        "                                          n_jobs=-1,\n",
        "                                          random_state=0)\n",
        "imputer=  IterativeImputer(\n",
        "                           random_state=0,\n",
        "                           estimator=impute_estimator, \n",
        "                           max_iter=25)\n",
        "data_b[clinical_and_biomarkers] = imputer.fit_transform(data_b[clinical_and_biomarkers])\n",
        "\n",
        "# Round values for categorical data - so that there will be no new categories\n",
        "data_b[categorical] = data_b[categorical].values.round()"
      ],
      "metadata": {
        "id": "wRV3SF90a_7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For subsets\n",
        "biomarkers_b_columns = list(data_b.columns[214:])\n",
        "clinical_and_biomarkers_b_columns = list(data_b.columns[:2]) + list(data_b.columns[3:72]) + list(data_b.columns[214:])\n",
        "clinical_b_columns = list(data_b.columns[:2]) + list(data_b.columns[3:72])"
      ],
      "metadata": {
        "id": "hy9P61cNyGbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset C"
      ],
      "metadata": {
        "id": "EzQUKc3Edx-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read cardio_b_updated.xlsx\n",
        "data_c = pd.read_excel('./HSE project/Data/Блок С обезлич.xlsx',header=[0,1])\n",
        "# drop index column\n",
        "data_c.drop(columns=('Unnamed: 0_level_0','№ п/п'), inplace=True)\n",
        "# replace NAs with -1\n",
        "data_c = data_c.fillna(-1)\n",
        "data_c = data_c.replace(' ',-1)\n",
        "# data_c.columns[(data_c.dtypes == object).values]\n",
        "# Modify 'Пол' feature: covert all string to lower format and convert to 0 and 1\n",
        "data_c['АНТРОПОФИЗИОМЕТРИЯ', 'Пол'] = data_c['АНТРОПОФИЗИОМЕТРИЯ', 'Пол'].replace([1, 2],[0,1])\n",
        "# Reencrypt psychological scales\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Ситуативная тревожность Спилберга (баллы)'].replace(range(31), 0, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Ситуативная тревожность Спилберга (баллы)'].replace(range(31, 46), 1, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Ситуативная тревожность Спилберга (баллы)'].replace(range(46,100), 2, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Личная тревожность Спилберга (баллы)'].replace(range(31), 0, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Личная тревожность Спилберга (баллы)'].replace(range(31, 46), 1, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Личная тревожность Спилберга (баллы)'].replace(range(46,100), 2, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Опросник депрессии Бека (баллы)'].replace(range(10), 0, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Опросник депрессии Бека (баллы)'].replace(range(10, 20), 1, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Опросник депрессии Бека (баллы)'].replace(range(20,100), 2, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Шкала AUDIT (баллы)'].replace(range(16), 0, inplace=True)\n",
        "data_c['ПСИХОСОЦИАЛЬНЫЕ ФАКТОРЫ', 'Шкала AUDIT (баллы)'].replace(range(16, 100), 1, inplace=True)\n",
        "\n",
        "# date_c = pd.to_datetime(data_c['АНТРОПОФИЗИОМЕТРИЯ', 'Дата госпитализации'], format='%Y-%m-%d %H:%M:%S')\n",
        "date_c = pd.to_datetime(data_c['АНТРОПОФИЗИОМЕТРИЯ', 'Дата госпитализации'], format='%Y-%m-%d %H:%M:%S')\n",
        "data_c.drop(columns=[('АНТРОПОФИЗИОМЕТРИЯ', 'Дата рождения'), ('АНТРОПОФИЗИОМЕТРИЯ', 'Дата госпитализации')], inplace=True)\n",
        "data_c.drop(columns=['ПЛАНОВАЯ ТЕРАПИЯ ПРИ ВЫПИСКЕ', 'ГОСПИТАЛЬНАЯ ТЕРАПИЯ'], inplace=True)\n",
        "# cols with features from first discharge and biomarkers\n",
        "cols_of_interest = list(data_c.columns[:153]) + list(data_c.columns[419:424])\n",
        "\n",
        "# drop features that were obtained at first discharge and biomarkers that have more than 20% of NAs\n",
        "cols_with_NAs = [col for col in cols_of_interest[:-5] if (data_c[col] == -1).sum() > 0.2*data_c.shape[0]]\n",
        "cols_of_interest = [col for col in cols_of_interest if col not in cols_with_NAs]\n",
        "continuous_cols = [col for col in cols_of_interest if (len((data_c[col].unique())) >= 7)]\n",
        "categorical = [col for col in cols_of_interest if (len((data_c[col].unique())) < 7)]\n",
        "\n",
        "data_c[cols_of_interest] = data_c[cols_of_interest].replace(-1, np.nan)\n",
        "\n",
        "\n",
        "# Impute NAs with IterativeImputer (estimator - RandomForestRegressor)\n",
        "impute_estimator = RandomForestRegressor( n_estimators=50,\n",
        "                                          max_depth=5,\n",
        "                                          n_jobs=-1,\n",
        "                                          random_state=0)\n",
        "imputer=  IterativeImputer(\n",
        "                           random_state=0,\n",
        "                           estimator=impute_estimator, \n",
        "                           max_iter=25)\n",
        "data_c[cols_of_interest] = imputer.fit_transform(data_c[cols_of_interest])\n",
        "\n",
        "# Round values for categorical data - so that there will be no new categories\n",
        "data_c[categorical] = data_c[categorical].values.round()"
      ],
      "metadata": {
        "id": "sUCK37pXeJVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For subsets\n",
        "biomarkers_c_columns = cols_of_interest[-5:]\n",
        "clinical_c_columns = cols_of_interest[:-5]\n",
        "clinical_and_biomarkers_c_columns = clinical_c_columns + biomarkers_c_columns"
      ],
      "metadata": {
        "id": "htsUAHbsnBmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Сombined Dataset ABC"
      ],
      "metadata": {
        "id": "3ifjgUqCfC7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge clinicals of all three datasets\n",
        "data_abc = pd.concat([data_a, data_b, data_c], axis=0)\n",
        "data_abc.dropna(axis=1, inplace=True)\n",
        "\n",
        "cols_of_interest = list(data_abc.columns)[:56]"
      ],
      "metadata": {
        "id": "lZhoGHHqfUx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For subsets\n",
        "clinical_abc_columns = cols_of_interest"
      ],
      "metadata": {
        "id": "MB5KrAmSDu8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lancet Dataset ABC"
      ],
      "metadata": {
        "id": "m6IHFMFcSNSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_a_and_hyperlipidemia = data_a.copy()\n",
        "data_a_and_hyperlipidemia[('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ'), ('Хсобщ, ммоль/л')] = hyperlipidemia\n",
        "\n",
        "# Impute NAs with IterativeImputer (estimator - RandomForestRegressor)\n",
        "impute_estimator = RandomForestRegressor( n_estimators=50,\n",
        "                                          max_depth=5,\n",
        "                                          n_jobs=-1,\n",
        "                                          random_state=0)\n",
        "imputer=  IterativeImputer(\n",
        "                           random_state=0,\n",
        "                           estimator=impute_estimator, \n",
        "                           max_iter=25)\n",
        "\n",
        "\n",
        "data_a_and_hyperlipidemia[clinical_and_biomarkers_a_columns + [('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Хсобщ, ммоль/л')]] = \\\n",
        "                                    imputer.fit_transform(data_a_and_hyperlipidemia[clinical_and_biomarkers_a_columns + [('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Хсобщ, ммоль/л')]])\n",
        "\n",
        "data_abc_lancet = pd.concat([data_a_and_hyperlipidemia, data_b, data_c], axis=0)\n",
        "data_abc_lancet.dropna(axis=1, inplace=True)\n",
        "\n",
        "cols_of_interest = list(data_abc_lancet.columns)[:56]\n",
        "cols_of_interest.append(('ЛАБОРАТОРНЫЕ ПОКАЗАТЕЛИ', 'Хсобщ, ммоль/л'))"
      ],
      "metadata": {
        "id": "aoME8QkwSN_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For subsets\n",
        "clinical_abc_columns_lancet = cols_of_interest"
      ],
      "metadata": {
        "id": "ViaZ4TzlztyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cardiovascular death"
      ],
      "metadata": {
        "id": "p6D6fu7ECWvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset A"
      ],
      "metadata": {
        "id": "g1UIFvT3CglE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 20\n",
        "target = ('КОНЕЧНЫЕ ИСХОДЫ НАБЛЮДЕНИЯ', 'Сердечно-сосудистая смерть')\n",
        "path = \"./HSE project/Preprocessed Data/cardiovascular death/\""
      ],
      "metadata": {
        "id": "NNpss1vEJJQR"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add target columnt and drop patients with -1 in the outcome\n",
        "features = clinical_and_biomarkers_a_columns + [target]\n",
        "dataframe = data_a[features].copy()\n",
        "dataframe[target] = \\\n",
        "dataframe[target].replace(-1, np.nan)\n",
        "dataframe.dropna(axis=0, how='any', inplace=True)\n",
        "dataframe.replace(-1, np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "t28Et-9rCi-Y"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide dataset into train and test\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "train_test_split(dataframe[clinical_and_biomarkers_a_columns], \n",
        "                 dataframe[target], \n",
        "                 test_size=0.25, \n",
        "                 random_state=random_state, \n",
        "                 shuffle=True)"
      ],
      "metadata": {
        "id": "YLGHy2L4Fb6w"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make imputation\n",
        "\n",
        "# Impute NAs with IterativeImputer (estimator - RandomForestRegressor)\n",
        "impute_estimator = RandomForestRegressor(n_estimators=50,\n",
        "                                         max_depth=5,\n",
        "                                         n_jobs=-1,\n",
        "                                         random_state=random_state)\n",
        "imputer = IterativeImputer(random_state=random_state,\n",
        "                           estimator=impute_estimator, \n",
        "                           max_iter=25)\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Round values for categorical data - so that there will be no new categories\n",
        "categorical = [dataframe.columns.get_loc(col) for col in dataframe.columns[:-1] if len(dataframe[col].unique()) <= 7]\n",
        "X_train[:, categorical] = X_train[:, categorical].round()\n",
        "X_test[:, categorical] = X_test[:, categorical].round()"
      ],
      "metadata": {
        "id": "zMCM5B8OJLYP"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit SMOTE on train part\n",
        "smote = SMOTENC(categorical_features = [dataframe.columns.get_loc(col) for col in dataframe.columns[:-1] if len(dataframe[col].unique()) <= 7],\n",
        "                sampling_strategy='minority',\n",
        "                n_jobs=-1,\n",
        "                random_state=random_state)\n",
        "X_sm, y_sm = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "LvtSJPiOHcel"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imputed = pd.DataFrame(data=X_sm, \n",
        "                             columns=clinical_and_biomarkers_a_columns)\n",
        "train_imputed[target] = y_sm\n",
        "\n",
        "train_imputed.to_excel(f'{path}train_a.xlsx')\n"
      ],
      "metadata": {
        "id": "cgyD-KSaLfTY"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset B"
      ],
      "metadata": {
        "id": "xnBvhswvCm8o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQ78pki1Cm8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset C"
      ],
      "metadata": {
        "id": "d_gIMEzTCnS1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PEI88zS4CnS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling"
      ],
      "metadata": {
        "id": "9WkKTxA6snkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define scaler \n",
        "scaler = RobustScaler() \n",
        "\n",
        "# Scaling of dataset A\n",
        "continuous_cols = [col for col in clinical_and_biomarkers_a_columns if (len((data_a[col].unique())) >= 7)]\n",
        "data_a[continuous_cols] = scaler.fit_transform(data_a[continuous_cols])\n",
        "\n",
        "# Scaling of dataset B\n",
        "continuous_cols = [col for col in clinical_and_biomarkers_b_columns if (len((data_b[col].unique())) >= 7)]\n",
        "data_b[continuous_cols] = scaler.fit_transform(data_b[continuous_cols])\n",
        "\n",
        "# Scaling of dataset C\n",
        "continuous_cols = [col for col in clinical_and_biomarkers_c_columns if (len((data_c[col].unique())) >= 7)]\n",
        "data_c[continuous_cols] = scaler.fit_transform(data_c[continuous_cols])\n",
        "\n",
        "# Scaling of dataset ABC\n",
        "continuous_cols = [col for col in clinical_abc_columns if (len((data_abc[col].unique())) >= 7)]\n",
        "data_abc[continuous_cols] = scaler.fit_transform(data_abc[continuous_cols])\n",
        "\n",
        "# Scaling of dataset Lancet\n",
        "continuous_cols = [col for col in clinical_abc_columns_lancet if (len((data_abc_lancet[col].unique())) >= 7)]\n",
        "data_abc_lancet[continuous_cols] = scaler.fit_transform(data_abc_lancet[continuous_cols])"
      ],
      "metadata": {
        "id": "NQhNYfV5spqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}