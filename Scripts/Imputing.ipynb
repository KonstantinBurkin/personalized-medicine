{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom classes\n",
    "from Imputing import Imputing\n",
    "\n",
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import plotly\n",
    "\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import precision_score as TP_rate                          \n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import make_scorer,fbeta_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostRegressor, RandomForestRegressor, GradientBoostingClassifier, StackingClassifier, VotingClassifier #\n",
    "from sklearn.tree import DecisionTreeClassifier     #\n",
    "from sklearn.svm import SVC                                    # both linear and radial classification\n",
    "from sklearn.neighbors import KNeighborsClassifier             # k=3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import catboost\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# imputations\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import clone\n",
    "\n",
    "import ast\n",
    "\n",
    "# ignore warnings when graphs are plotted\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preselected features and preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_features = list(map(tuple, pd.read_excel('../Raw data/Clinical features.xlsx', index_col=0, header=0).values))\n",
    "\n",
    "biomarkers_a = list(map(tuple, pd.read_excel('../Raw data/biomarkers_a.xlsx', index_col=0, header=0).values.tolist()))\n",
    "biomarkers_b = list(map(tuple, pd.read_excel('../Raw data/biomarkers_b.xlsx', index_col=0, header=0).values.tolist()))\n",
    "biomarkers_c = list(map(tuple, pd.read_excel('../Raw data/biomarkers_c.xlsx', index_col=0, header=0).values.tolist()))\n",
    "targets = list(map(tuple, pd.read_excel('../Raw data/targets_features.xlsx', index_col=0, header=0).values.tolist()))\n",
    "\n",
    "continuous = list(map(tuple, pd.read_excel('../Raw data/continuous_features.xlsx', index_col=0, header=0).values.tolist()))\n",
    "# all biomarkers were continuous except 'БСЖК' in data_b\n",
    "\n",
    "categorical = list(map(tuple, pd.read_excel('../Raw data/categorical_features.xlsx', index_col=0, header=0).values.tolist()))\n",
    "# include 'БСЖК' biomarkers from data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing preprocessed data\n",
    "test_a = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/test_a.xlsx', index_col=0, header=[0,1])\n",
    "train_a = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/train_a.xlsx', index_col=0, header=[0,1])\n",
    "test_b = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/test_b.xlsx', index_col=0, header=[0,1])\n",
    "train_b = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/train_b.xlsx', index_col=0, header=[0,1])\n",
    "test_c = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/test_c.xlsx', index_col=0, header=[0,1])\n",
    "train_c = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/train_c.xlsx', index_col=0, header=[0,1])\n",
    "test_d = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/test_d.xlsx', index_col=0, header=[0,1])\n",
    "train_d = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/train_d.xlsx', index_col=0, header=[0,1])\n",
    "test_abcd = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/test_abcd.xlsx', index_col=0, header=[0,1])\n",
    "train_abcd = pd.read_excel('../Preprocessed data/Combined target/Non-imputed data/train_abcd.xlsx', index_col=0, header=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = Imputing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute NAs with IterativeImputer (estimator - Random Forest Regressor)\n",
    "\n",
    "noncat_imputer = IterativeImputer(random_state=20, max_iter=25)\n",
    "\n",
    "impute_estimator = LogisticRegression(random_state=20)\n",
    "cat_imputer = IterativeImputer(\n",
    "    random_state=20, estimator=impute_estimator, max_iter=25, skip_complete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '../Preprocessed data/Combined target/Imputed data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:\t (142, 102)\n",
      "Train target:\n",
      " 1    72\n",
      "0    70\n",
      "Name: (target, combined), dtype: int64\n",
      "\n",
      "\n",
      "Test shape:\t (48, 102)\n",
      "Test target:\n",
      " 1    25\n",
      "0    23\n",
      "Name: (target, combined), dtype: int64"
     ]
    }
   ],
   "source": [
    "_, _ = imputation.process(\n",
    "\n",
    "    data={'train': train_a, 'test': test_a},\n",
    "    noncat_imputer=noncat_imputer, cat_imputer=cat_imputer,\n",
    "    target=('target', 'combined'),\n",
    "    path=results_path,\n",
    "    dataset_features=clinical_features + biomarkers_a,\n",
    "    download=False,\n",
    "    name='a',\n",
    "    categorical_cols=categorical,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:\t (67, 42)\n",
      "Train target:\n",
      " 0    51\n",
      "1    16\n",
      "Name: (target, combined), dtype: int64\n",
      "\n",
      "\n",
      "Test shape:\t (23, 42)\n",
      "Test target:\n",
      " 0    17\n",
      "1     6\n",
      "Name: (target, combined), dtype: int64"
     ]
    }
   ],
   "source": [
    "_, _ = imputation.process(\n",
    "\n",
    "    data={'train': train_b, 'test': test_b},\n",
    "    noncat_imputer=noncat_imputer, cat_imputer=cat_imputer,\n",
    "    target=('target', 'combined'),\n",
    "    path=results_path,\n",
    "    dataset_features=clinical_features + biomarkers_b,\n",
    "    download=False,\n",
    "    name='b',\n",
    "    categorical_cols=categorical + biomarkers_b[:2],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:\t (96, 41)\n",
      "Train target:\n",
      " 0    83\n",
      "1    13\n",
      "Name: (target, combined), dtype: int64\n",
      "\n",
      "\n",
      "Test shape:\t (32, 41)\n",
      "Test target:\n",
      " 0    27\n",
      "1     5\n",
      "Name: (target, combined), dtype: int64"
     ]
    }
   ],
   "source": [
    "_, _ = imputation.process(\n",
    "\n",
    "    data={'train': train_c, 'test': test_c},\n",
    "    noncat_imputer=noncat_imputer, cat_imputer=cat_imputer,\n",
    "    target=('target', 'combined'),\n",
    "    path=results_path,\n",
    "    dataset_features=clinical_features + biomarkers_c,\n",
    "    download=False,\n",
    "    name='c',\n",
    "    categorical_cols=categorical,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:\t (57, 36)\n",
      "Train target:\n",
      " 0    33\n",
      "1    24\n",
      "Name: (target, combined), dtype: int64\n",
      "\n",
      "\n",
      "Test shape:\t (19, 36)\n",
      "Test target:\n",
      " 0    11\n",
      "1     8\n",
      "Name: (target, combined), dtype: int64"
     ]
    }
   ],
   "source": [
    "_, _ = imputation.process(\n",
    "\n",
    "    data={'train': train_d, 'test': test_d},\n",
    "    noncat_imputer=noncat_imputer, cat_imputer=cat_imputer,\n",
    "    target=('target', 'combined'),\n",
    "    path=results_path,\n",
    "    dataset_features=clinical_features,\n",
    "    download=False,\n",
    "    name='d',\n",
    "    categorical_cols=categorical,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сombined Dataset ABCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:\t (363, 36)\n",
      "Train target:\n",
      " 0    236\n",
      "1    127\n",
      "Name: (target, combined), dtype: int64\n",
      "\n",
      "\n",
      "Test shape:\t (121, 36)\n",
      "Test target:\n",
      " 0    79\n",
      "1    42\n",
      "Name: (target, combined), dtype: int64"
     ]
    }
   ],
   "source": [
    "_, _ = imputation.process(\n",
    "\n",
    "    data={'train': train_abcd, 'test': test_abcd},\n",
    "    noncat_imputer=noncat_imputer, cat_imputer=cat_imputer,\n",
    "    target=('target', 'combined'),\n",
    "    path=results_path,\n",
    "    dataset_features=clinical_features,\n",
    "    download=False,\n",
    "    name='abcd',\n",
    "    categorical_cols=categorical,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a18d4bcf948680bb0435ffd9c45fc67248d199792deeb9caaf05cf1e6b71615"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
